{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UnSupervisedLearning_SyntheticData",
      "provenance": [],
      "collapsed_sections": [
        "rL9_uZwPcMz6",
        "_fgT0kD1gZm8",
        "EOrQHkUYT71O"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parthatom/UnsupervisedClassification/blob/master/UnSupervisedLearning_SyntheticData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTlw6uAYM_Dn",
        "colab_type": "text"
      },
      "source": [
        "# Essentials\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsfPnwyb82ob",
        "colab_type": "code",
        "outputId": "0480185a-5e9c-4ccc-d5d4-480c802ce738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QrOAcWVhbrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gini(array):\n",
        "    \"\"\"\n",
        "    Calculate the Gini coefficient of a numpy array.\n",
        "    \"\"\"\n",
        "    # based on bottom eq: http://www.statsdirect.com/help/content/image/stat0206_wmf.gif\n",
        "    # from: http://www.statsdirect.com/help/default.htm#nonparametric_methods/gini.htm\n",
        "    array = array.flatten() #all values are treated equally, arrays must be 1d\n",
        "    if np.amin(array) < 0:\n",
        "        array -= np.amin(array) #values cannot be negative\n",
        "    array += 0.0000001 #values cannot be 0\n",
        "    array = np.sort(array) #values must be sorted\n",
        "    index = np.arange(1,array.shape[0]+1) #index per array element\n",
        "    n = array.shape[0]#number of array elements\n",
        "    return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array))) #Gini coefficient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka_TF7yQBHCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tqdm\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_BcMQov4AP3",
        "colab_type": "text"
      },
      "source": [
        "# Unsupervised Learning on Synthetic Sparse and Uniform Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXtjNmzY5aOy",
        "colab_type": "text"
      },
      "source": [
        "## Importing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZRlBWNV5Y97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import sys\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from pathlib import Path\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "%matplotlib inline\n",
        "colors = ['y', 'r']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZE8wcSqnaMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def n_weight(x, db):\n",
        "  xp = np.matmul(np.transpose(x), x)\n",
        "  npow = xp * pow(10, -0.1*db)\n",
        "  return npow.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR3RQ12U23wS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
        "class Metrics():\n",
        "  def __init__(self):\n",
        "    self.nmi = normalized_mutual_info_score\n",
        "    self.ari = adjusted_rand_score\n",
        "\n",
        "\n",
        "  def acc(self, y_true, y_pred):\n",
        "      \"\"\"\n",
        "      Calculate clustering accuracy. Require scikit-learn installed\n",
        "      # Arguments\n",
        "          y: true labels, numpy.array with shape `(n_samples,)`\n",
        "          y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
        "      # Return\n",
        "          accuracy, in [0,1]\n",
        "      \"\"\"\n",
        "      y_true = y_true.astype(np.int64)\n",
        "      assert y_pred.size == y_true.size\n",
        "      D = max(y_pred.max(), y_true.max()) + 1\n",
        "      w = np.zeros((D, D), dtype=np.int64)\n",
        "      for i in range(y_pred.size):\n",
        "          w[y_pred[i], y_true[i]] += 1\n",
        "      from sklearn.utils.linear_assignment_ import linear_assignment\n",
        "      ind = linear_assignment(w.max() - w)\n",
        "      return sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqBVGrl46XC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import mixture\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from keras.utils import normalize\n",
        "import time\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import cv2\n",
        "metrics = Metrics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBsiOD7oJOf9",
        "colab_type": "code",
        "outputId": "8001fcc8-608f-4a4e-e142-f2a44c76ee58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "time.time()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1576493855.8468971"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDL0QDLG-rKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/drive/'My Drive'/Outputs/Synthetic_Unsupervised/Sorted/gini"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sIfwN-f9Q9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gmm_path = Path('/', 'content', 'drive', 'My Drive', 'Outputs','Synthetic_Unsupervised','Sorted', 'GMMs')\n",
        "kmeans_path = Path('/', 'content', 'drive','My Drive', 'Outputs', 'Synthetic_Unsupervised','Sorted','KMeans')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dUIOdj8Dp5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "synthetic_path = Path('/', 'content','drive', \"My Drive\", 'Outputs', 'Synthetic_Unsupervised','Sorted','gini')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIneMbFM4HF-",
        "colab_type": "text"
      },
      "source": [
        "## Data Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uCX93YqCYQ6",
        "colab_type": "code",
        "outputId": "fbddc466-cc6a-47ba-bda9-4eb7388af029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seed = 42\n",
        "torch.random.manual_seed(seed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f050fc8ded0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2463YkV-SL4",
        "colab_type": "text"
      },
      "source": [
        "### Sparse Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzXaW-P64GxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def Sparse(sparsity = 1, sensitivity = 1, db = 10):\n",
        "#   print(\"Creating Sparse data\")\n",
        "#   perm1 = torch.randperm(39)\n",
        "#   m =  torch.zeros((39,1))\n",
        "#   for j in range(sparsity):\n",
        "#     m[perm1[j].item()] = 1\n",
        "#   # weight = n_weight(m.numpy(), db)  \n",
        "#   weight = 1/sensitivity\n",
        "#   m = m/torch.sum(m)\n",
        "#   # m = nn.Softmax(dim = 0)(m)\n",
        "#   m, c = torch.sort(m, dim = 0)\n",
        "#   # print(\"initial \",gini(m.numpy()))\n",
        "#   X = m\n",
        "#   # print(X.shape)\n",
        "#   perm1 = torch.randperm(39)\n",
        "#   for i in range(5000):\n",
        "#     m =  torch.zeros((39,1))\n",
        "#     for j in range(sparsity):\n",
        "#       m[perm1[j].item()] = 1\n",
        "#     m = m/torch.sum(m)\n",
        "#     noise = torch.randn_like(m)\n",
        "#     # noise/=torch.max(noise)\n",
        "#     noisy_m = torch.abs(m + weight *noise)\n",
        "#     noisy_m/= torch.sum(noisy_m)\n",
        "#     # noisy_m = nn.Softmax(dim = 0)(noisy_m)\n",
        "#     noisy_m, c = torch.sort(noisy_m, dim = 0)\n",
        "#     X = torch.cat((X,noisy_m), dim = 1)\n",
        "#   X = X.T  \n",
        "#   return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTTyj_y7-ZcP",
        "colab_type": "text"
      },
      "source": [
        "### Uniform Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijz-aAxA8TwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def uniform(sparsity =1, sensitivity = 1, db = 10):\n",
        "#   print(\"Creating Uniform data\")\n",
        "#   perm1 = torch.randperm(39)\n",
        "#   u =  torch.ones((39,1))\n",
        "#   for j in range(sparsity-1):\n",
        "#     u[perm1[j].item()] = 0\n",
        "#   u = u/torch.sum(u)\n",
        "#   # u = nn.Softmax(dim = 0)(u)\n",
        "#   u, c = torch.sort(u, dim = 0)\n",
        "#   # print(\"initial\", gini(u.numpy()))\n",
        "#   weight = 1/sensitivity\n",
        "#   # weight = n_weight(u.numpy(), db=db)\n",
        "#   X = u\n",
        "#   for i in range(5000):\n",
        "#     perm1 = torch.randperm(39)\n",
        "#     u =  torch.ones((39,1))\n",
        "#     for j in range(sparsity-1):\n",
        "#       u[perm1[j].item()] = 0\n",
        "#     u = u/torch.sum(u)\n",
        "#     noise = torch.randn_like(u)\n",
        "#     # noise/= (torch.max(noise))\n",
        "#     noisy_u = torch.abs(u + weight*noise)\n",
        "#     noisy_u/= torch.sum(noisy_u)\n",
        "#     # noisy_u = nn.Softmax(dim = 0)(noisy_u)\n",
        "#     noisy_u, c = torch.sort(noisy_u, dim = 0)\n",
        "#     X = torch.cat((X,noisy_u), dim = 1)\n",
        "#   X = X.T\n",
        "#   return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VAkBqCgCiJk",
        "colab_type": "text"
      },
      "source": [
        "### Concat and Shuffle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkAaqsyn8oez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def synth_data(sparsity = 1, std =  0.01, sparse = True):\n",
        "  perm1 = torch.randperm(39)\n",
        "  if(sparse):\n",
        "    print(\"Creating Sparse Data\")\n",
        "    X = torch.zeros((1,39))\n",
        "    for i in range(sparsity):\n",
        "      X[0][int(perm1[i].item())] = 1\n",
        "  else:\n",
        "    print(\"Creating Uniform data\")\n",
        "    X = torch.ones((1, 39))\n",
        "    for i in range(sparsity-1):\n",
        "      X[0][int(perm1[i].item())] = 0\n",
        "  # X,c = torch.sort(X, dim = 0)\n",
        "  noise = torch.randn((5001,39))\n",
        "  noisy_X = X+ std*noise\n",
        "  noisy_X = torch.abs(noisy_X)\n",
        "  noisy_X = noisy_X/(torch.sum(noisy_X, dim = 1).view(-1,1))\n",
        "  noisy_X, c = torch.sort(noisy_X, dim = 1)\n",
        "  return noisy_X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r21xWhD7AHmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_data(sparsity = 1, std = 0.01):\n",
        "  un = synth_data(sparsity= sparsity, std = std, sparse = False)\n",
        "  sp = synth_data(sparsity = sparsity, std = std, sparse = True)\n",
        "  X = torch.cat((un,sp), dim = 0)\n",
        "  o = torch.ones((5001,1))\n",
        "  z = torch.zeros((5001,1))\n",
        "  labels = torch.cat((o,z), dim = 0)\n",
        "  perm = torch.randperm(10002)\n",
        "  X = X[perm]\n",
        "  labels = labels[perm]\n",
        "  return X, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-ZhpzZ6Bxkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def create_data(sparsity = 1, sensitivity = 1, db = 10):\n",
        "#   uni = uniform(sparsity = sparsity, sensitivity = sensitivity, db = db)\n",
        "#   sparse = Sparse(sparsity=sparsity, sensitivity = sensitivity, db = db)\n",
        "#   X = torch.cat((uni,sparse), dim = 0)\n",
        "#   perm = torch.randperm(10002)\n",
        "#   o = torch.ones((5001,1)) # Ones for uniform\n",
        "#   z = torch.zeros((5001,1)) # Zeros for Sparse\n",
        "#   labels = torch.cat((o,z), dim = 0)\n",
        "#   labels = labels[perm]\n",
        "#   X=X[perm]\n",
        "#   return X, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY26iofdCGwA",
        "colab_type": "code",
        "outputId": "ef5cdcf6-b383-44cf-cb83-63d061dd5acf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "a = create_data(sparsity = 1, std = 0.01)\n",
        "X = a[0]\n",
        "labels = a[1]\n",
        "# np.save(os.path.join(synthetic_path, 'X.npy'), X)\n",
        "# np.save(os.path.join(synthetic_path, 'y.npy'), labels)\n",
        "print(X.shape)\n",
        "print([(gini(X[i].numpy()),i) for i in range(600, 604)])\n",
        "print(X[600:604])\n",
        "labels[600:604]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Uniform data\n",
            "Creating Sparse Data\n",
            "torch.Size([10002, 39])\n",
            "[(0.006747550357785449, 600), (0.006538455482499899, 601), (0.8566153292129629, 602), (0.8495978218964907, 603)]\n",
            "tensor([[2.5101e-02, 2.5122e-02, 2.5164e-02, 2.5195e-02, 2.5202e-02, 2.5224e-02,\n",
            "         2.5290e-02, 2.5389e-02, 2.5424e-02, 2.5460e-02, 2.5490e-02, 2.5517e-02,\n",
            "         2.5521e-02, 2.5525e-02, 2.5529e-02, 2.5536e-02, 2.5539e-02, 2.5559e-02,\n",
            "         2.5608e-02, 2.5641e-02, 2.5663e-02, 2.5689e-02, 2.5694e-02, 2.5706e-02,\n",
            "         2.5730e-02, 2.5734e-02, 2.5748e-02, 2.5751e-02, 2.5766e-02, 2.5875e-02,\n",
            "         2.5909e-02, 2.5958e-02, 2.5961e-02, 2.5994e-02, 2.5996e-02, 2.6051e-02,\n",
            "         2.6193e-02, 2.6244e-02, 2.6301e-02],\n",
            "        [2.4976e-02, 2.5185e-02, 2.5185e-02, 2.5253e-02, 2.5328e-02, 2.5333e-02,\n",
            "         2.5339e-02, 2.5381e-02, 2.5420e-02, 2.5444e-02, 2.5466e-02, 2.5469e-02,\n",
            "         2.5494e-02, 2.5520e-02, 2.5522e-02, 2.5549e-02, 2.5570e-02, 2.5583e-02,\n",
            "         2.5598e-02, 2.5599e-02, 2.5639e-02, 2.5644e-02, 2.5667e-02, 2.5672e-02,\n",
            "         2.5710e-02, 2.5728e-02, 2.5745e-02, 2.5756e-02, 2.5812e-02, 2.5828e-02,\n",
            "         2.5886e-02, 2.5946e-02, 2.5986e-02, 2.6022e-02, 2.6051e-02, 2.6069e-02,\n",
            "         2.6083e-02, 2.6234e-02, 2.6309e-02],\n",
            "        [1.1074e-05, 2.2930e-05, 7.0314e-05, 1.9327e-04, 2.0320e-04, 1.1581e-03,\n",
            "         1.5101e-03, 1.5932e-03, 1.9550e-03, 2.0244e-03, 2.6764e-03, 2.7565e-03,\n",
            "         3.1352e-03, 3.4181e-03, 3.6218e-03, 3.7053e-03, 3.7977e-03, 4.4694e-03,\n",
            "         4.7270e-03, 5.0903e-03, 5.3562e-03, 5.7612e-03, 5.8416e-03, 5.9614e-03,\n",
            "         6.2670e-03, 6.3521e-03, 6.5789e-03, 7.2525e-03, 7.5145e-03, 7.6910e-03,\n",
            "         7.8138e-03, 8.1900e-03, 8.4222e-03, 8.4277e-03, 8.5899e-03, 1.0107e-02,\n",
            "         1.3395e-02, 1.3407e-02, 8.1093e-01],\n",
            "        [1.2995e-04, 1.6614e-04, 4.2698e-04, 7.8807e-04, 8.6056e-04, 1.0051e-03,\n",
            "         1.2560e-03, 1.3715e-03, 1.4382e-03, 1.7027e-03, 2.5464e-03, 2.8471e-03,\n",
            "         3.2330e-03, 3.3131e-03, 3.5922e-03, 4.0596e-03, 4.2281e-03, 4.9658e-03,\n",
            "         4.9662e-03, 5.2477e-03, 5.3036e-03, 5.3398e-03, 5.4363e-03, 5.4404e-03,\n",
            "         5.6643e-03, 5.8432e-03, 6.8266e-03, 7.2883e-03, 7.9250e-03, 8.6352e-03,\n",
            "         8.7667e-03, 1.0255e-02, 1.0639e-02, 1.2252e-02, 1.2451e-02, 1.5731e-02,\n",
            "         1.8871e-02, 1.9205e-02, 7.7998e-01]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [1.],\n",
              "        [0.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InTAohIZEH_o",
        "colab_type": "text"
      },
      "source": [
        "## GMMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnU_h-USdvhc",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIgmH8d77u3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "np.random.seed(10)\n",
        "import matplotlib.pyplot as plt\n",
        "cmap = plt.get_cmap('gnuplot')\n",
        "colors = ['y', 'r']\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSFa0XIW7zL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.engine.topology import Layer, InputSpec\n",
        "from keras.layers import Dense, Input, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD,Adam\n",
        "from keras import callbacks\n",
        "from keras.initializers import VarianceScaling\n",
        "from sklearn.cluster import KMeans\n",
        "metrics = Metrics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB_0pxxXAgX7",
        "colab_type": "code",
        "outputId": "267dbbdc-bf8e-4f78-da64-14e77168d834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoBcZI77714l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Autoencoder(dims, act='relu', init='glorot_uniform'):\n",
        "    \"\"\"\n",
        "    Fully connected auto-encoder model, symmetric.\n",
        "    Arguments:\n",
        "        dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n",
        "            The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n",
        "        act: activation, not applied to Input, Hidden and Output layers\n",
        "    return:\n",
        "        (ae_model, encoder_model), Model of autoencoder and model of encoder\n",
        "    \"\"\"\n",
        "    n_stacks = len(dims) - 1\n",
        "    # input\n",
        "    input_img = Input(shape=(dims[0],), name='input')\n",
        "    x = input_img\n",
        "    # internal layers in encoder\n",
        "    for i in range(n_stacks-1):\n",
        "        x = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "    # hidden layer\n",
        "    encoded = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(x)  # hidden layer, features are extracted from here\n",
        "\n",
        "    x = encoded\n",
        "    # internal layers in decoder\n",
        "    for i in range(n_stacks-1, 0, -1):\n",
        "        x = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "    # output\n",
        "    x = Dense(dims[0], kernel_initializer=init, name='decoder_0')(x)\n",
        "    decoded = x\n",
        "    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=encoded, name='encoder')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjB7pLAT785R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_clusters = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsBmZFJ88Bhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dims = [X.shape[-1], 500, 500, 2000, 2]\n",
        "init = VarianceScaling(scale=1. / 3., mode='fan_in',\n",
        "                           distribution='uniform')\n",
        "pretrain_optimizer = Adam(lr=0.001 )\n",
        "pretrain_epochs = 30\n",
        "batch_size = 256\n",
        "save_dir = synthetic_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SfxWCj7G_0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrs = [3e-5, 2.25e-5, 1.68e-5, 1.27e-5, 1e-5 ]\n",
        "batch_sizes = [64, 72, 82, 100, 113, 128]\n",
        "epochs = [5, 5, 10, 10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPolt4LFJBrk",
        "colab_type": "code",
        "outputId": "65ecf0e3-e26a-4b15-989b-3de59d39a354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(lrs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D0gGTnCI6M0",
        "colab_type": "code",
        "outputId": "c594ca2f-8d7c-4312-fd37-0abb71c38f73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_tuning = np.zeros((len(lrs), len(batch_sizes), len(epochs)))\n",
        "loss_tuning = np.zeros((len(lrs), len(batch_sizes), len(epochs)))\n",
        "accuracy_tuning.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 5, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csWgKs0kLdci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db = 9\n",
        "X = np.load(os.path.join(synthetic_path, f'X_sparsity_1_db_{db}.npy'))\n",
        "y = np.load(os.path.join(synthetic_path, f\"labels_sparsity_1_db_{db}.npy\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRBIZ_GkIXw-",
        "colab_type": "code",
        "outputId": "1ec4bf4a-2853-4e16-b8aa-15137ce2cf79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_list = []\n",
        "for i,lr in enumerate(lrs):\n",
        "  for j,batch_size in enumerate(batch_sizes):\n",
        "    autoencoder, encoder = Autoencoder(dims, init=init)\n",
        "    pretrain_optimizer = Adam(lr=lr)    \n",
        "    autoencoder.compile(optimizer=pretrain_optimizer, loss='mse')\n",
        "    \n",
        "    for k,pretrain_epochs in enumerate(epochs): \n",
        "      total_trained = 0     \n",
        "      b = autoencoder.fit(X, X, batch_size=batch_size, epochs=pretrain_epochs) #, callbacks=cb)\n",
        "      history_list.append(b)\n",
        "      loss_tuning[i][j][k] = (b.history['loss'])[-1]\n",
        "      autoencoder.save_weights(os.path.join(synthetic_path, f\"ae_sparsity_1_db_{db}_lr_{lr}_batch_size_{batch_size}_epochs_{pretrain_epochs+total_trained}.h5\"))\n",
        "      total_trained = pretrain_epochs\n",
        "      encoding = encoder.predict(X)      \n",
        "\n",
        "      kmeans = KMeans(n_clusters=2, n_init = 15).fit(encoding)\n",
        "      y_pred_ae_means = kmeans.labels_\n",
        "      del kmeans\n",
        "\n",
        "      accs_ae_means = metrics.acc(y.reshape(10002,), y_pred_ae_means.reshape(10002,))\n",
        "      print(\"accuracy\",lr,batch_size, pretrain_epochs, accs_ae_means)\n",
        "      accuracy_tuning[i][j][k] = accs_ae_means\n",
        "      del y_pred_ae_means, accs_ae_means\n",
        "    del autoencoder, encoder, pretrain_optimizer\n",
        "np.save(os.path.join(synthetic_path, f'accuracy_tuning_sparsity_1_db_{db}.npy'), accuracy_tuning)\n",
        "np.save(os.path.join(synthetic_path, f'loss_tuning_sparsity_1_db_{db}.npy'), loss_tuning)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 5s 539us/step - loss: 5.1476\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 2s 190us/step - loss: 1.9483\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 2s 189us/step - loss: 17.4199\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 2s 193us/step - loss: 2.9698\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 2s 190us/step - loss: 5.5499\n",
            "accuracy 0.001 64 5 0.5002999400119976\n",
            "Epoch 1/5\n",
            "  960/10002 [=>............................] - ETA: 1s - loss: 5.6777"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 193us/step - loss: 7.9502\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 2s 189us/step - loss: 2.8986\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 2s 192us/step - loss: 2.2998\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 2s 190us/step - loss: 6.2516\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 2s 186us/step - loss: 4.0056\n",
            "accuracy 0.001 64 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1024/10002 [==>...........................] - ETA: 1s - loss: 0.3172"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 186us/step - loss: 3.9855\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 2s 186us/step - loss: 8.2508\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 2s 189us/step - loss: 3.0167\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 2s 189us/step - loss: 3.0098\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 2s 186us/step - loss: 6.2881\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 2s 186us/step - loss: 2.9774\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 2s 187us/step - loss: 4.8679\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 2s 187us/step - loss: 4.3436\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 2s 185us/step - loss: 5.3614\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 2s 185us/step - loss: 2.4700\n",
            "accuracy 0.001 64 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1024/10002 [==>...........................] - ETA: 1s - loss: 0.0678"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 185us/step - loss: 2.1148\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 2s 181us/step - loss: 6.5122\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 2s 185us/step - loss: 11.6277\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 2s 183us/step - loss: 2.9783\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 2s 187us/step - loss: 5.5326\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 2s 185us/step - loss: 3.4699\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 2s 181us/step - loss: 3.1338\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 2s 182us/step - loss: 5.4475\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 2s 183us/step - loss: 2.2405\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 2s 185us/step - loss: 2.3303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.001 64 10 0.8563287342531494\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 5s 501us/step - loss: 3.5802\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 132us/step - loss: 2.7311\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 132us/step - loss: 1.3805\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 131us/step - loss: 1.6555\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 131us/step - loss: 4.0429\n",
            "accuracy 0.001 100 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 0.6069"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 129us/step - loss: 4.4131\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 125us/step - loss: 13.9886\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 124us/step - loss: 9.4652\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 121us/step - loss: 3.1341\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 122us/step - loss: 3.1563\n",
            "accuracy 0.001 100 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1600/10002 [===>..........................] - ETA: 1s - loss: 2.2544"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 124us/step - loss: 6.1908\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 123us/step - loss: 3.8082\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 120us/step - loss: 7.4347\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 121us/step - loss: 5.0317\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 122us/step - loss: 3.4087\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 120us/step - loss: 1.6146\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 120us/step - loss: 10.1643\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 122us/step - loss: 2.4883\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 122us/step - loss: 3.3685\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 120us/step - loss: 21.1108\n",
            "accuracy 0.001 100 10 0.5002999400119976\n",
            "Epoch 1/10\n",
            " 1600/10002 [===>..........................] - ETA: 0s - loss: 0.5773"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 120us/step - loss: 12.2358\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 122us/step - loss: 4.5933\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 120us/step - loss: 4.0563\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 121us/step - loss: 3.6605\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 120us/step - loss: 2.7908\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 120us/step - loss: 2.9345\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 121us/step - loss: 0.8993\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 123us/step - loss: 7.2143\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 122us/step - loss: 4.1528\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 120us/step - loss: 2.8620\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.001 100 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 5s 488us/step - loss: 4.1859\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 106us/step - loss: 2.8959\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 105us/step - loss: 2.4828\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 103us/step - loss: 1.2556\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 104us/step - loss: 1.5027\n",
            "accuracy 0.001 128 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 0.5220"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 104us/step - loss: 2.2750\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 104us/step - loss: 1.9106\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 104us/step - loss: 2.0959\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 106us/step - loss: 4.8123\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 105us/step - loss: 5.2234\n",
            "accuracy 0.001 128 5 0.5002999400119976\n",
            "Epoch 1/10\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 0.1544"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 106us/step - loss: 1.6976\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 104us/step - loss: 5.3932\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 102us/step - loss: 3.2467\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 103us/step - loss: 2.5767\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 102us/step - loss: 5.7876\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 101us/step - loss: 4.4006\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 101us/step - loss: 4.7237\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 100us/step - loss: 1.8495\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 97us/step - loss: 1.5437\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 97us/step - loss: 3.6781\n",
            "accuracy 0.001 128 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 0.5682"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 100us/step - loss: 2.3125\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 99us/step - loss: 4.0714\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 97us/step - loss: 5.3431\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 98us/step - loss: 2.0094\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 98us/step - loss: 6.4210\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 97us/step - loss: 5.5515\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 97us/step - loss: 5.6611\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 99us/step - loss: 6.7062\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 99us/step - loss: 3.1013\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 99us/step - loss: 6.5138\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.001 128 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 4s 447us/step - loss: 5.7861\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 4.1741\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 3.5293\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 4.1741\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 4.3002\n",
            "accuracy 0.001 256 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            " 3328/10002 [========>.....................] - ETA: 0s - loss: 1.8445"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 54us/step - loss: 1.5173\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 2.3341\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 2.8372\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 2.4370\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 1.4404\n",
            "accuracy 0.001 256 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 3328/10002 [========>.....................] - ETA: 0s - loss: 9.8680 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 55us/step - loss: 6.2144\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 54us/step - loss: 3.5365\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 3.1616\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 54us/step - loss: 2.3058\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 54us/step - loss: 1.3157\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 7.5054\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 54us/step - loss: 3.1785\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 52us/step - loss: 6.7023\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 9.3084\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 5.5210\n",
            "accuracy 0.001 256 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 3328/10002 [========>.....................] - ETA: 0s - loss: 1.6775"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 52us/step - loss: 4.0004\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 52us/step - loss: 5.3757\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 2.6588\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 2.2372\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 54us/step - loss: 2.7328\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 26.3517\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 54us/step - loss: 3.8042\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 3.4125\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 4.0881\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 2.1516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.001 256 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 4s 440us/step - loss: 3.1038\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 3.6060\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 1.7704\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 0s 30us/step - loss: 3.3429\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.8747\n",
            "accuracy 0.001 512 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            " 6656/10002 [==================>...........] - ETA: 0s - loss: 0.4619"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 30us/step - loss: 1.1304\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 0s 30us/step - loss: 2.5211\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 4.4737\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.3035\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 2.3376\n",
            "accuracy 0.001 512 5 0.5001999600079984\n",
            "Epoch 1/10\n",
            " 6656/10002 [==================>...........] - ETA: 0s - loss: 3.9036"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 30us/step - loss: 2.7227\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 2.4529\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 0s 30us/step - loss: 3.6247\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 0s 30us/step - loss: 1.7085\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 4.5984\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 0s 30us/step - loss: 2.9294\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 4.6362\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 2.3980\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 2.8366\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.7335\n",
            "accuracy 0.001 512 10 0.5002999400119976\n",
            "Epoch 1/10\n",
            " 4608/10002 [============>.................] - ETA: 0s - loss: 3.3092"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 31us/step - loss: 2.5691\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 0s 30us/step - loss: 6.2054\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 0s 30us/step - loss: 4.4079\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 2.6303\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 3.0116\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 0s 30us/step - loss: 2.8411\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 0s 30us/step - loss: 4.8035\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 2.3236\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 3.9155\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.9600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.001 512 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 6s 612us/step - loss: 3.0284\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 2s 200us/step - loss: 1.9513\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 2s 199us/step - loss: 0.6599\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 2s 198us/step - loss: 0.5142\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 2s 201us/step - loss: 0.7298\n",
            "accuracy 0.0001 64 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            "  960/10002 [=>............................] - ETA: 1s - loss: 0.1113"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 199us/step - loss: 0.3660\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 2s 201us/step - loss: 1.3083\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 2s 201us/step - loss: 0.8711\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 2s 203us/step - loss: 1.1234\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 2s 200us/step - loss: 1.6534\n",
            "accuracy 0.0001 64 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            "  960/10002 [=>............................] - ETA: 1s - loss: 0.3301"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 198us/step - loss: 1.7823\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 2s 196us/step - loss: 0.1383\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 2s 197us/step - loss: 0.1843\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 2s 197us/step - loss: 6.4776\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 2s 200us/step - loss: 0.1845\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 2s 196us/step - loss: 0.5713\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 2s 197us/step - loss: 1.4303\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 2s 199us/step - loss: 0.3186\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 2s 195us/step - loss: 0.2210\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 2s 198us/step - loss: 0.2947\n",
            "accuracy 0.0001 64 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            "  896/10002 [=>............................] - ETA: 1s - loss: 0.0267"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 197us/step - loss: 0.0804\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 2s 197us/step - loss: 0.5259\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 2s 200us/step - loss: 0.3558\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 2s 201us/step - loss: 0.4365\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 2s 200us/step - loss: 0.5171\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 2s 203us/step - loss: 0.8530\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 2s 201us/step - loss: 0.4956\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 2s 199us/step - loss: 0.3591\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 2s 193us/step - loss: 2.1005\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 2s 197us/step - loss: 0.5412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.0001 64 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 6s 572us/step - loss: 5.9887\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 137us/step - loss: 2.2326\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 135us/step - loss: 1.6966\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 131us/step - loss: 1.4036\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 132us/step - loss: 0.4133\n",
            "accuracy 0.0001 100 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 0.4887"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 130us/step - loss: 1.4430\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 131us/step - loss: 1.0413\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 135us/step - loss: 0.5020\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 133us/step - loss: 1.9545\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 132us/step - loss: 0.2253\n",
            "accuracy 0.0001 100 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 0.0125"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 131us/step - loss: 0.2310\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 130us/step - loss: 0.9645\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 130us/step - loss: 0.3444\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 132us/step - loss: 2.2435\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 129us/step - loss: 1.5487\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 129us/step - loss: 0.8659\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 130us/step - loss: 2.2683\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 130us/step - loss: 1.3375\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 131us/step - loss: 0.9898\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 129us/step - loss: 0.4201\n",
            "accuracy 0.0001 100 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 0.0272"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 131us/step - loss: 0.3107\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 129us/step - loss: 0.3615\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 129us/step - loss: 1.7391\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 129us/step - loss: 0.2819\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 128us/step - loss: 1.5229\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 127us/step - loss: 0.6410\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 127us/step - loss: 0.2352\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 126us/step - loss: 0.1203\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 125us/step - loss: 1.1937\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 126us/step - loss: 0.3061\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.0001 100 10 0.5001999600079984\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 5s 549us/step - loss: 2.6797\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 109us/step - loss: 1.6594\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 107us/step - loss: 2.0372\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 107us/step - loss: 0.9534\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 107us/step - loss: 0.6474\n",
            "accuracy 0.0001 128 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 0.2636"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 106us/step - loss: 0.3819\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 107us/step - loss: 0.8305\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 107us/step - loss: 0.5596\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 106us/step - loss: 0.2924\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 106us/step - loss: 0.2624\n",
            "accuracy 0.0001 128 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 0.0155"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 103us/step - loss: 0.2024\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 105us/step - loss: 1.3172\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 103us/step - loss: 3.4495\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 105us/step - loss: 0.8217\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 105us/step - loss: 1.1298\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 104us/step - loss: 4.0577\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 106us/step - loss: 5.5114\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 105us/step - loss: 1.6124\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 103us/step - loss: 0.9556\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 103us/step - loss: 0.3592\n",
            "accuracy 0.0001 128 10 0.5001999600079984\n",
            "Epoch 1/10\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 2.4515"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 102us/step - loss: 1.2675\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 104us/step - loss: 0.1727\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 103us/step - loss: 0.0729\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 107us/step - loss: 0.1075\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 105us/step - loss: 0.5240\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 105us/step - loss: 0.4638\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 105us/step - loss: 0.2242\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 104us/step - loss: 0.6498\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 104us/step - loss: 0.1435\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 104us/step - loss: 0.0698\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.0001 128 10 0.5001999600079984\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 5s 519us/step - loss: 5.6240\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 3.0853\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 1.7367\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 1.0849\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 3.5533\n",
            "accuracy 0.0001 256 5 0.5001999600079984\n",
            "Epoch 1/5\n",
            " 3328/10002 [========>.....................] - ETA: 0s - loss: 7.4046 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 55us/step - loss: 2.6730\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 0.3144\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 54us/step - loss: 0.3044\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 0.2003\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 54us/step - loss: 0.0878\n",
            "accuracy 0.0001 256 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 3328/10002 [========>.....................] - ETA: 0s - loss: 0.2864"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 54us/step - loss: 0.2208\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 54us/step - loss: 0.9177\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 0.1323\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 0.2550\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 54us/step - loss: 0.1683\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 0.6897\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 0.1245\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 0.3574\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 54us/step - loss: 0.2378\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 54us/step - loss: 0.2317\n",
            "accuracy 0.0001 256 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 3328/10002 [========>.....................] - ETA: 0s - loss: 0.2683"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 53us/step - loss: 0.5389\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 54us/step - loss: 2.8268\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 4.1550\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 0.3388\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 2.7430\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 0.3034\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 52us/step - loss: 0.7418\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 0.1138\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 0.2795\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 53us/step - loss: 0.3645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.0001 256 10 0.5001999600079984\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 5s 496us/step - loss: 6.2545\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 4.1877\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 2.4467\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 0s 30us/step - loss: 1.5762\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.2938\n",
            "accuracy 0.0001 512 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            " 3584/10002 [=========>....................] - ETA: 0s - loss: 0.2258"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 38us/step - loss: 1.1623\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 1.1648\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 0.8733\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.6341\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.3434\n",
            "accuracy 0.0001 512 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 4608/10002 [============>.................] - ETA: 0s - loss: 0.0497"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.6169\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 2.0336\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.8014\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 0s 30us/step - loss: 1.0142\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 0s 30us/step - loss: 0.1871\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.2673\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 0.1583\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.3221\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.3118\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 0s 30us/step - loss: 0.5399\n",
            "accuracy 0.0001 512 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 4608/10002 [============>.................] - ETA: 0s - loss: 0.0372"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.1682\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.0460\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.3910\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.2079\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 0s 30us/step - loss: 0.3505\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.2266\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.2303\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.0574\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.0420\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.0177\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.0001 512 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 6s 642us/step - loss: 5.0464\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 2s 164us/step - loss: 1.3830\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 2s 165us/step - loss: 4.8738\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 2s 165us/step - loss: 0.7818\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 2s 163us/step - loss: 2.1685\n",
            "accuracy 0.0003 64 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            "  896/10002 [=>............................] - ETA: 1s - loss: 10.2250"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 168us/step - loss: 3.1878\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 2s 169us/step - loss: 3.7627\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 2s 169us/step - loss: 1.3028\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 2s 171us/step - loss: 2.7844\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 2s 166us/step - loss: 1.4788\n",
            "accuracy 0.0003 64 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1024/10002 [==>...........................] - ETA: 1s - loss: 2.9326"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 166us/step - loss: 4.7667\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 2s 170us/step - loss: 1.9716\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 2s 174us/step - loss: 0.8368\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 2s 173us/step - loss: 1.2378\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 2s 173us/step - loss: 3.0127\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 2s 173us/step - loss: 1.3341\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 2s 176us/step - loss: 2.6322\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 2s 177us/step - loss: 2.2049\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 2s 179us/step - loss: 0.4159\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 2s 178us/step - loss: 1.1642\n",
            "accuracy 0.0003 64 10 0.5002999400119976\n",
            "Epoch 1/10\n",
            "  960/10002 [=>............................] - ETA: 1s - loss: 0.9913"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 179us/step - loss: 3.3714\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 2s 179us/step - loss: 1.3503\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 2s 181us/step - loss: 2.6834\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 2s 179us/step - loss: 4.6178\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 2s 180us/step - loss: 2.6551\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 2s 179us/step - loss: 1.9836\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 2s 178us/step - loss: 0.7482\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 2s 178us/step - loss: 0.7986\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 2s 178us/step - loss: 3.7670\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 2s 178us/step - loss: 0.9589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.0003 64 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 6s 635us/step - loss: 3.2966\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 137us/step - loss: 1.9728\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 137us/step - loss: 0.9922\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 139us/step - loss: 8.2267\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 138us/step - loss: 2.1328\n",
            "accuracy 0.0003 100 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 0.1357"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 137us/step - loss: 2.3079\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 137us/step - loss: 0.4037\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 140us/step - loss: 1.5574\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 138us/step - loss: 1.1943\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 140us/step - loss: 4.9955\n",
            "accuracy 0.0003 100 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 0.2265"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 140us/step - loss: 0.9679\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 137us/step - loss: 2.5920\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 137us/step - loss: 0.7646\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 139us/step - loss: 0.2210\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 136us/step - loss: 1.3883\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 136us/step - loss: 1.4350\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 137us/step - loss: 1.7509\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 137us/step - loss: 0.9682\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 136us/step - loss: 2.5194\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 140us/step - loss: 1.0119\n",
            "accuracy 0.0003 100 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 5.4241"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 134us/step - loss: 2.2629\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 137us/step - loss: 3.2630\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 137us/step - loss: 1.0898\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 137us/step - loss: 1.5850\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 135us/step - loss: 2.9216\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 134us/step - loss: 1.6706\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 136us/step - loss: 5.4767\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 135us/step - loss: 0.8501\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 136us/step - loss: 1.7925\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 140us/step - loss: 2.2598\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.0003 100 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 6s 625us/step - loss: 2.7111\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 3.5375\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 113us/step - loss: 2.9425\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 113us/step - loss: 4.3292\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 114us/step - loss: 4.3063\n",
            "accuracy 0.0003 128 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 0.6661"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 112us/step - loss: 1.7198\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 113us/step - loss: 14.2059\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 111us/step - loss: 1.3264\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 111us/step - loss: 0.3775\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 112us/step - loss: 1.3238\n",
            "accuracy 0.0003 128 5 0.5002999400119976\n",
            "Epoch 1/10\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 13.3202"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 111us/step - loss: 2.7227\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 111us/step - loss: 1.3684\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 113us/step - loss: 0.3788\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 112us/step - loss: 30.3430\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 112us/step - loss: 4.0286\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 114us/step - loss: 2.0645\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 111us/step - loss: 1.2726\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 112us/step - loss: 0.6918\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 110us/step - loss: 2.5105\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 113us/step - loss: 0.8167\n",
            "accuracy 0.0003 128 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 1.2960"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 111us/step - loss: 0.5368\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 112us/step - loss: 1.0572\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 111us/step - loss: 0.4480\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 113us/step - loss: 0.7483\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 111us/step - loss: 1.1957\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 112us/step - loss: 1.3437\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 112us/step - loss: 4.7089\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 113us/step - loss: 1.0839\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 112us/step - loss: 10.1155\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 113us/step - loss: 2.5225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.0003 128 10 0.5001999600079984\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 6s 583us/step - loss: 4.7401\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.9754\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.3902\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.6712\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 5.3240\n",
            "accuracy 0.0003 256 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            " 3328/10002 [========>.....................] - ETA: 0s - loss: 2.2404"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 59us/step - loss: 5.7238\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 2.6226\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 4.1863\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 2.0017\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.6056\n",
            "accuracy 0.0003 256 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 3328/10002 [========>.....................] - ETA: 0s - loss: 0.0979"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.2802\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 1.8212\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 1.4053\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.7197\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 3.0496\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 2.5833\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 3.7109\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 4.0347\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 0.7271\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 2.1764\n",
            "accuracy 0.0003 256 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 3328/10002 [========>.....................] - ETA: 0s - loss: 0.1809"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.1856\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.8290\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 3.2690\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 4.5552\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 1.8959\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 2.1955\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 2.3912\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 4.3772\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 3.3912\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 2.0703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.0003 256 10 0.5002999400119976\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 6s 575us/step - loss: 3.9503\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 2.0314\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 3.1770\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 5.2614\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 3.3801\n",
            "accuracy 0.0003 512 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            " 3584/10002 [=========>....................] - ETA: 0s - loss: 2.0890"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 40us/step - loss: 1.4937\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 0s 36us/step - loss: 1.6988\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 0s 35us/step - loss: 1.4746\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 0s 35us/step - loss: 2.1941\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 3.8895\n",
            "accuracy 0.0003 512 5 0.5002999400119976\n",
            "Epoch 1/10\n",
            " 6144/10002 [=================>............] - ETA: 0s - loss: 2.6913"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 33us/step - loss: 2.3217\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 2.4056\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 2.4012\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 0.7636\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 0.6234\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 0.3029\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 3.8511\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 4.2994\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 2.8040\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 5.7334\n",
            "accuracy 0.0003 512 10 0.5001999600079984\n",
            "Epoch 1/10\n",
            " 4608/10002 [============>.................] - ETA: 0s - loss: 1.0879"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 31us/step - loss: 4.8289\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 2.8224\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 2.1707\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.9105\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.2477\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.1916\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.1938\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.8476\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.9182\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 3.5190\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.0003 512 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 7s 725us/step - loss: 6.7021\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 2s 172us/step - loss: 6.5035\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 2s 168us/step - loss: 6.0839\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 2s 170us/step - loss: 5.3981\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 2s 170us/step - loss: 4.2578\n",
            "accuracy 1e-05 64 5 0.5002999400119976\n",
            "Epoch 1/5\n",
            "  960/10002 [=>............................] - ETA: 1s - loss: 0.0537"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 170us/step - loss: 2.9984\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 2s 171us/step - loss: 2.1874\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 2s 176us/step - loss: 1.8073\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 2s 179us/step - loss: 1.5671\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 2s 181us/step - loss: 1.4140\n",
            "accuracy 1e-05 64 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1024/10002 [==>...........................] - ETA: 1s - loss: 3.9549"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 184us/step - loss: 1.3755\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 2s 188us/step - loss: 1.2081\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 2s 189us/step - loss: 1.0079\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 2s 187us/step - loss: 0.8384\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 2s 186us/step - loss: 0.6324\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 2s 190us/step - loss: 0.4031\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 2s 188us/step - loss: 0.2214\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 2s 188us/step - loss: 0.1018\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 2s 188us/step - loss: 0.0488\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 2s 187us/step - loss: 0.0338\n",
            "accuracy 1e-05 64 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            "  960/10002 [=>............................] - ETA: 1s - loss: 0.0042"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 188us/step - loss: 0.0235\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 2s 187us/step - loss: 0.0347\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 2s 190us/step - loss: 0.0410\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 2s 190us/step - loss: 0.0438\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 2s 188us/step - loss: 0.0353\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 2s 188us/step - loss: 0.1334\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 2s 188us/step - loss: 0.0595\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 2s 188us/step - loss: 0.0602\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 2s 187us/step - loss: 0.1652\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 2s 187us/step - loss: 0.1404\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 1e-05 64 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 7s 694us/step - loss: 6.6946\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 143us/step - loss: 6.6243\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 142us/step - loss: 6.4392\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 142us/step - loss: 6.0453\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 142us/step - loss: 5.3537\n",
            "accuracy 1e-05 100 5 0.5002999400119976\n",
            "Epoch 1/5\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 0.1706"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 142us/step - loss: 4.3793\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 143us/step - loss: 3.3632\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 143us/step - loss: 2.5621\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 145us/step - loss: 2.0018\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 143us/step - loss: 1.5621\n",
            "accuracy 1e-05 100 5 0.5002999400119976\n",
            "Epoch 1/10\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 5.8071"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 143us/step - loss: 1.2017\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 143us/step - loss: 0.9247\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 142us/step - loss: 0.6257\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 142us/step - loss: 0.3992\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 142us/step - loss: 0.2308\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 144us/step - loss: 0.1162\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 140us/step - loss: 0.0556\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 142us/step - loss: 0.0286\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 143us/step - loss: 0.0194\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 138us/step - loss: 0.0162\n",
            "accuracy 1e-05 100 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 0.0011"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 140us/step - loss: 0.0186\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 140us/step - loss: 0.0154\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 143us/step - loss: 0.0149\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 139us/step - loss: 0.0157\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 140us/step - loss: 0.0158\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 140us/step - loss: 0.0238\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 142us/step - loss: 0.0223\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 140us/step - loss: 0.0317\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 140us/step - loss: 0.0320\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 140us/step - loss: 0.0315\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 1e-05 100 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 7s 668us/step - loss: 6.6952\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 6.6131\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 6.4243\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 117us/step - loss: 6.0541\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 5.4402\n",
            "accuracy 1e-05 128 5 0.5002999400119976\n",
            "Epoch 1/5\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 1.5575"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 114us/step - loss: 4.5753\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 114us/step - loss: 3.6122\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 114us/step - loss: 2.7262\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 118us/step - loss: 2.0440\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 1.6219\n",
            "accuracy 1e-05 128 5 0.5002999400119976\n",
            "Epoch 1/10\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 3.7825"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 117us/step - loss: 1.3693\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 114us/step - loss: 1.1412\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 0.9468\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 0.7730\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 0.5695\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 0.4671\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 114us/step - loss: 0.3157\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 114us/step - loss: 0.2105\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 114us/step - loss: 0.1389\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 0.0890\n",
            "accuracy 1e-05 128 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 0.0064"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 116us/step - loss: 0.0555\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 114us/step - loss: 0.0429\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 114us/step - loss: 0.0462\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 0.0550\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 113us/step - loss: 0.0630\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 0.0599\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 118us/step - loss: 0.0627\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 118us/step - loss: 0.0514\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 119us/step - loss: 0.0379\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 118us/step - loss: 0.0447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 1e-05 128 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 6s 631us/step - loss: 6.6999\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 6.6595\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 6.5785\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 6.4348\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 6.2107\n",
            "accuracy 1e-05 256 5 0.5002999400119976\n",
            "Epoch 1/5\n",
            " 3072/10002 [========>.....................] - ETA: 0s - loss: 0.6501"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 65us/step - loss: 5.8462\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 5.5279\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 4.8526\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 4.2396\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 3.4985\n",
            "accuracy 1e-05 256 5 0.5002999400119976\n",
            "Epoch 1/10\n",
            " 3328/10002 [========>.....................] - ETA: 0s - loss: 0.6732"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 57us/step - loss: 2.8356\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.3692\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.9781\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.7825\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.6129\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.4819\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.4362\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.3315\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.3089\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.2772\n",
            "accuracy 1e-05 256 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 3328/10002 [========>.....................] - ETA: 0s - loss: 0.2000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.1999\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.1621\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.1115\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.0837\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.9847\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.9185\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.8313\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.7494\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.6771\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.5699\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 1e-05 256 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 6s 607us/step - loss: 6.7051\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 6.6934\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 6.6579\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 6.6241\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 6.5583\n",
            "accuracy 1e-05 512 5 0.5002999400119976\n",
            "Epoch 1/5\n",
            " 3584/10002 [=========>....................] - ETA: 0s - loss: 16.6598"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 40us/step - loss: 6.4860\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 0s 36us/step - loss: 6.3525\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 0s 35us/step - loss: 6.1805\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 5.9631\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 5.6253\n",
            "accuracy 1e-05 512 5 0.5002999400119976\n",
            "Epoch 1/10\n",
            " 4608/10002 [============>.................] - ETA: 0s - loss: 8.8893 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 31us/step - loss: 5.2774\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 4.7981\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 4.2913\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 3.7307\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 3.2460\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 2.7203\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 2.3015\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 2.1118\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.8389\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.7114\n",
            "accuracy 1e-05 512 10 0.5002999400119976\n",
            "Epoch 1/10\n",
            " 4608/10002 [============>.................] - ETA: 0s - loss: 1.0390"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.6128\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.6098\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.4368\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.3802\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.3233\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.2788\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.2356\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.1802\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.1460\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.1161\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 1e-05 512 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 8s 752us/step - loss: 5.9854\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 2s 173us/step - loss: 3.6140\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 2s 172us/step - loss: 1.9386\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 2s 171us/step - loss: 1.3687\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 2s 171us/step - loss: 0.5934\n",
            "accuracy 3e-05 64 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            "  960/10002 [=>............................] - ETA: 1s - loss: 0.1135"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 172us/step - loss: 0.3021\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 2s 170us/step - loss: 0.0794\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 2s 171us/step - loss: 0.2340\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 2s 173us/step - loss: 0.6430\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 2s 176us/step - loss: 0.0939\n",
            "accuracy 3e-05 64 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1024/10002 [==>...........................] - ETA: 1s - loss: 0.0199"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 183us/step - loss: 0.0762\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 2s 188us/step - loss: 0.4678\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 2s 195us/step - loss: 0.7333\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 2s 193us/step - loss: 0.1252\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 2s 192us/step - loss: 0.5255\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 2s 191us/step - loss: 0.2827\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 2s 192us/step - loss: 0.2324\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 2s 191us/step - loss: 1.5327\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 2s 192us/step - loss: 3.7110\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 2s 191us/step - loss: 0.2510\n",
            "accuracy 3e-05 64 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            "  960/10002 [=>............................] - ETA: 1s - loss: 0.0099"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 191us/step - loss: 0.1365\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 2s 189us/step - loss: 0.0750\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 2s 191us/step - loss: 0.5838\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 2s 192us/step - loss: 1.5825\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 2s 191us/step - loss: 0.0725\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 2s 190us/step - loss: 0.0608\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 2s 189us/step - loss: 0.2303\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 2s 191us/step - loss: 0.5179\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 2s 191us/step - loss: 2.3798\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 2s 192us/step - loss: 2.0079\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 3e-05 64 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 7s 739us/step - loss: 4.9005\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 144us/step - loss: 2.6704\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 140us/step - loss: 1.7436\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 143us/step - loss: 1.1485\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 142us/step - loss: 0.5614\n",
            "accuracy 3e-05 100 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 0.0258"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 141us/step - loss: 0.1478\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 145us/step - loss: 0.0607\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 144us/step - loss: 0.1486\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 145us/step - loss: 0.0896\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 142us/step - loss: 0.0610\n",
            "accuracy 3e-05 100 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 0.4932"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 144us/step - loss: 0.1215\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 144us/step - loss: 0.0743\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 144us/step - loss: 0.0822\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 144us/step - loss: 0.1918\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 143us/step - loss: 1.7317\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 146us/step - loss: 0.1257\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 145us/step - loss: 0.1749\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 147us/step - loss: 0.0854\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 143us/step - loss: 0.3143\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 142us/step - loss: 0.1446\n",
            "accuracy 3e-05 100 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 0.3870"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 143us/step - loss: 0.1615\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 145us/step - loss: 0.0554\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 144us/step - loss: 0.4234\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 143us/step - loss: 0.3674\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 144us/step - loss: 1.6597\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 145us/step - loss: 0.3760\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 143us/step - loss: 1.7655\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 144us/step - loss: 0.0912\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 146us/step - loss: 0.1071\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 142us/step - loss: 0.0863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 3e-05 100 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 7s 719us/step - loss: 5.9210\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 4.7026\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 2.9648\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 1.9436\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 114us/step - loss: 1.6065\n",
            "accuracy 3e-05 128 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 0.2217"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 116us/step - loss: 1.1936\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 0.7890\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 0.4167\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 0.1685\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 117us/step - loss: 0.0813\n",
            "accuracy 3e-05 128 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 1.4112"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 114us/step - loss: 0.2936\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 113us/step - loss: 0.0825\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 0.0660\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 0.0839\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 0.1195\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 0.1571\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 0.1178\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 0.0451\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 113us/step - loss: 0.0535\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 114us/step - loss: 0.0451\n",
            "accuracy 3e-05 128 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 0.0220"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 114us/step - loss: 0.1185\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 0.4389\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 114us/step - loss: 1.0113\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 117us/step - loss: 0.2884\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 0.3397\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 0.1019\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 117us/step - loss: 0.1936\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 1.9166\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 114us/step - loss: 2.9206\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 117us/step - loss: 0.5845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 3e-05 128 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 7s 687us/step - loss: 6.3640\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 5.6909\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 4.4674\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 2.8897\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.9334\n",
            "accuracy 3e-05 256 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            " 2816/10002 [=======>......................] - ETA: 0s - loss: 1.2174"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 64us/step - loss: 1.5375\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 1.4829\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.2865\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 1.2733\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.1884\n",
            "accuracy 3e-05 256 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 3072/10002 [========>.....................] - ETA: 0s - loss: 0.1117"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 61us/step - loss: 1.2019\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.2081\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 1.1596\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 0.9829\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 0.6278\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.3240\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.1090\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.0954\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 0.2070\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 0.2903\n",
            "accuracy 3e-05 256 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 3328/10002 [========>.....................] - ETA: 0s - loss: 0.0750"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.4290\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 0.2305\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.4258\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.2185\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 0.2907\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 0.0961\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.1098\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.1023\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.1237\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.0577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 3e-05 256 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 7s 670us/step - loss: 6.5697\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 0s 35us/step - loss: 6.4288\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 6.0747\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 5.4636\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 4.3821\n",
            "accuracy 3e-05 512 5 0.5002999400119976\n",
            "Epoch 1/5\n",
            " 3584/10002 [=========>....................] - ETA: 0s - loss: 0.4218"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 40us/step - loss: 3.1524\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 0s 36us/step - loss: 2.5422\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 0s 34us/step - loss: 1.9328\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.6704\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.4738\n",
            "accuracy 3e-05 512 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 4608/10002 [============>.................] - ETA: 0s - loss: 0.1970"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.3376\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.2922\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.3124\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.2199\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.2221\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.1832\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.1832\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.1522\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.1434\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 1.1194\n",
            "accuracy 3e-05 512 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 4608/10002 [============>.................] - ETA: 0s - loss: 1.8861"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 32us/step - loss: 1.0761\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 0.9024\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 0.7744\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.5448\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 0.3040\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.1571\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 0.0937\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 0.0849\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 0.0832\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 0s 31us/step - loss: 0.1106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 3e-05 512 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 8s 825us/step - loss: 6.7073\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 2s 173us/step - loss: 6.7025\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 2s 172us/step - loss: 6.6965\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 2s 173us/step - loss: 6.6894\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 2s 174us/step - loss: 6.6805\n",
            "accuracy 1e-06 64 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            "  832/10002 [=>............................] - ETA: 1s - loss: 0.8696"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 210us/step - loss: 6.6697\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 2s 213us/step - loss: 6.6571\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 2s 209us/step - loss: 6.6420\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 2s 211us/step - loss: 6.6258\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 2s 210us/step - loss: 6.6072\n",
            "accuracy 1e-06 64 5 0.5002999400119976\n",
            "Epoch 1/10\n",
            "  832/10002 [=>............................] - ETA: 1s - loss: 3.9120"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 210us/step - loss: 6.5867\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 2s 214us/step - loss: 6.5648\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 2s 211us/step - loss: 6.5412\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 2s 211us/step - loss: 6.5149\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 2s 211us/step - loss: 6.4877\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 2s 208us/step - loss: 6.4581\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 2s 210us/step - loss: 6.4268\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 2s 210us/step - loss: 6.3934\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 2s 212us/step - loss: 6.3578\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 2s 212us/step - loss: 6.3205\n",
            "accuracy 1e-06 64 10 0.5002999400119976\n",
            "Epoch 1/10\n",
            "  832/10002 [=>............................] - ETA: 1s - loss: 1.1954"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 2s 211us/step - loss: 6.2818\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 2s 213us/step - loss: 6.2395\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 2s 210us/step - loss: 6.1949\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 2s 211us/step - loss: 6.1476\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 2s 210us/step - loss: 6.1009\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 2s 210us/step - loss: 6.0455\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 2s 210us/step - loss: 5.9910\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 2s 210us/step - loss: 5.9328\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 2s 210us/step - loss: 5.8745\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 2s 209us/step - loss: 5.8148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 1e-06 64 10 0.5002999400119976\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 8s 809us/step - loss: 6.7158\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 145us/step - loss: 6.7140\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 146us/step - loss: 6.7106\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 144us/step - loss: 6.7066\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 145us/step - loss: 6.7010\n",
            "accuracy 1e-06 100 5 0.5002999400119976\n",
            "Epoch 1/5\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 0.4350"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 147us/step - loss: 6.6939\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 144us/step - loss: 6.6852\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 145us/step - loss: 6.6754\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 146us/step - loss: 6.6640\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 145us/step - loss: 6.6516\n",
            "accuracy 1e-06 100 5 0.5002999400119976\n",
            "Epoch 1/10\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 0.2767"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 147us/step - loss: 6.6372\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 146us/step - loss: 6.6212\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 147us/step - loss: 6.6044\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 145us/step - loss: 6.5859\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 146us/step - loss: 6.5657\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 145us/step - loss: 6.5458\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 146us/step - loss: 6.5226\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 145us/step - loss: 6.4975\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 146us/step - loss: 6.4730\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 147us/step - loss: 6.4457\n",
            "accuracy 1e-06 100 10 0.5002999400119976\n",
            "Epoch 1/10\n",
            " 1300/10002 [==>...........................] - ETA: 1s - loss: 0.1147"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 145us/step - loss: 6.4154\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 146us/step - loss: 6.3836\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 146us/step - loss: 6.3503\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 147us/step - loss: 6.3155\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 145us/step - loss: 6.2823\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 147us/step - loss: 6.2436\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 147us/step - loss: 6.2039\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 148us/step - loss: 6.1630\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 148us/step - loss: 6.1207\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 149us/step - loss: 6.0764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 1e-06 100 10 0.5002999400119976\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 8s 791us/step - loss: 6.7164\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 117us/step - loss: 6.7149\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 6.7126\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 118us/step - loss: 6.7092\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 117us/step - loss: 6.7047\n",
            "accuracy 1e-06 128 5 0.5002999400119976\n",
            "Epoch 1/5\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 0.5658"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 116us/step - loss: 6.6983\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 6.6924\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 6.6828\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 6.6738\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 6.6615\n",
            "accuracy 1e-06 128 5 0.5002999400119976\n",
            "Epoch 1/10\n",
            " 1536/10002 [===>..........................] - ETA: 0s - loss: 34.2504"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 116us/step - loss: 6.6492\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 117us/step - loss: 6.6356\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 117us/step - loss: 6.6202\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 117us/step - loss: 6.6041\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 6.5872\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 6.5686\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 117us/step - loss: 6.5494\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 6.5297\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 6.5075\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 114us/step - loss: 6.4846\n",
            "accuracy 1e-06 128 10 0.5002999400119976\n",
            "Epoch 1/10\n",
            " 1664/10002 [===>..........................] - ETA: 0s - loss: 0.9590"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 115us/step - loss: 6.4597\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 117us/step - loss: 6.4351\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 6.4078\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 6.3806\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 6.3512\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 6.3216\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 6.2909\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 115us/step - loss: 6.2574\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 116us/step - loss: 6.2232\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 117us/step - loss: 6.1878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 1e-06 128 10 0.5002999400119976\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 8s 752us/step - loss: 6.7183\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 63us/step - loss: 6.7177\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 64us/step - loss: 6.7175\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 62us/step - loss: 6.7173\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 6.7170\n",
            "accuracy 1e-06 256 5 0.5001999600079984\n",
            "Epoch 1/5\n",
            " 2560/10002 [======>.......................] - ETA: 0s - loss: 6.7232"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 66us/step - loss: 6.7167\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 1s 62us/step - loss: 6.7158\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 6.7138\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 6.7115\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 1s 62us/step - loss: 6.7086\n",
            "accuracy 1e-06 256 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 2304/10002 [=====>........................] - ETA: 0s - loss: 3.2765"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 61us/step - loss: 6.7050\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 62us/step - loss: 6.7015\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 63us/step - loss: 6.6968\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 6.6919\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 62us/step - loss: 6.6874\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 6.6812\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 63us/step - loss: 6.6756\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 6.6692\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 6.6623\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 6.6551\n",
            "accuracy 1e-06 256 10 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 3328/10002 [========>.....................] - ETA: 0s - loss: 13.6095"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 1s 61us/step - loss: 6.6480\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 6.6398\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 6.6319\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 6.6227\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 6.6134\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 6.6040\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 6.5936\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 6.5844\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 6.5726\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 6.5628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy 1e-06 256 10 0.5000999800039992\n",
            "Epoch 1/5\n",
            "10002/10002 [==============================] - 8s 751us/step - loss: 6.7172\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 0s 37us/step - loss: 6.7166\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 0s 34us/step - loss: 6.7159\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 0s 34us/step - loss: 6.7151\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 6.7142\n",
            "accuracy 1e-06 512 5 0.5000999800039992\n",
            "Epoch 1/5\n",
            " 3584/10002 [=========>....................] - ETA: 0s - loss: 15.8603"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 41us/step - loss: 6.7130\n",
            "Epoch 2/5\n",
            "10002/10002 [==============================] - 0s 37us/step - loss: 6.7117\n",
            "Epoch 3/5\n",
            "10002/10002 [==============================] - 0s 36us/step - loss: 6.7103\n",
            "Epoch 4/5\n",
            "10002/10002 [==============================] - 0s 34us/step - loss: 6.7084\n",
            "Epoch 5/5\n",
            "10002/10002 [==============================] - 0s 34us/step - loss: 6.7062\n",
            "accuracy 1e-06 512 5 0.5000999800039992\n",
            "Epoch 1/10\n",
            " 4608/10002 [============>.................] - ETA: 0s - loss: 0.8462"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 32us/step - loss: 6.7036\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 0s 34us/step - loss: 6.7007\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 6.6976\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 6.6939\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 6.6901\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 6.6862\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 6.6804\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 6.6751\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 6.6705\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 6.6650\n",
            "accuracy 1e-06 512 10 0.5002999400119976\n",
            "Epoch 1/10\n",
            " 5632/10002 [===============>..............] - ETA: 0s - loss: 10.1125"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10002/10002 [==============================] - 0s 33us/step - loss: 6.6588\n",
            "Epoch 2/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 6.6519\n",
            "Epoch 3/10\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 6.6469\n",
            "Epoch 4/10\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 6.6382\n",
            "Epoch 5/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 6.6301\n",
            "Epoch 6/10\n",
            "10002/10002 [==============================] - 0s 33us/step - loss: 6.6235\n",
            "Epoch 7/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 6.6153\n",
            "Epoch 8/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 6.6066\n",
            "Epoch 9/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 6.6011\n",
            "Epoch 10/10\n",
            "10002/10002 [==============================] - 0s 32us/step - loss: 6.5912\n",
            "accuracy 1e-06 512 10 0.5002999400119976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faI92XWRni7n",
        "colab_type": "code",
        "outputId": "32076e81-baf6-47be-dff1-bba47d5fe3dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "loss_dict = dict((lr,dict((batch_size, dict((epoch, loss_tuning[i][j][k]) for k,epoch in enumerate(epochs))) for j, batch_size in enumerate(batch_sizes ))) for i, lr in enumerate(lrs)) \n",
        "# accuracy_dict = dict((lr,dict((batch_size, accuracy_tuning[j][i]) for i, batch_size in enumerate(batch_sizes ))) for j, lr in enumerate(lrs)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-21e4e8f4849c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_tuning\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# accuracy_dict = dict((lr,dict((batch_size, accuracy_tuning[j][i]) for i, batch_size in enumerate(batch_sizes ))) for j, lr in enumerate(lrs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-21e4e8f4849c>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_tuning\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# accuracy_dict = dict((lr,dict((batch_size, accuracy_tuning[j][i]) for i, batch_size in enumerate(batch_sizes ))) for j, lr in enumerate(lrs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-21e4e8f4849c>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_tuning\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# accuracy_dict = dict((lr,dict((batch_size, accuracy_tuning[j][i]) for i, batch_size in enumerate(batch_sizes ))) for j, lr in enumerate(lrs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-21e4e8f4849c>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_tuning\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# accuracy_dict = dict((lr,dict((batch_size, accuracy_tuning[j][i]) for i, batch_size in enumerate(batch_sizes ))) for j, lr in enumerate(lrs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErIXVcHMttgX",
        "colab_type": "code",
        "outputId": "82882e3d-70aa-45bd-d48a-79fb9e23777f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from math import log10#, exp\n",
        "print(str(pow(10,-(5-log10(3) + 1/4))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.2650895102857471e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E_WyPUBQLJI",
        "colab_type": "code",
        "outputId": "0933d0ac-4747-48e5-ef1a-dd58c8032442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "lr_index = 5\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(accuracy_tuning[lr_index])\n",
        "\n",
        "# We want to show all ticks...\n",
        "ax.set_xticks(np.arange(len(epochs)))\n",
        "ax.set_yticks(np.arange(len(batch_sizes)))\n",
        "# ... and label them with the respective list entries\n",
        "ax.set_xticklabels(epochs)\n",
        "ax.set_yticklabels(batch_sizes)\n",
        "\n",
        "# Rotate the tick labels and set their alignment.\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "         rotation_mode=\"anchor\")\n",
        "\n",
        "# Loop over data dimensions and create text annotations.\n",
        "for i in range(len(batch_sizes)):\n",
        "    for j in range(len(epochs)):\n",
        "        text = ax.text(j, i, np.around(accuracy_tuning[lr_index][i][j], decimals = 4),\n",
        "                       ha=\"center\", va=\"center\", color=\"r\")\n",
        "\n",
        "ax.set_title(f\"Accuracies for lr = {lrs[lr_index]}\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAIwCAYAAAAS6LXfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 222,
              "height": 280
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzMs9wNt8TH1",
        "colab_type": "code",
        "outputId": "a3f42739-afc5-4027-bfec-e6ebfd2a9588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "autoencoder, encoder = Autoencoder(dims, init=init)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-154028ea33f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dims' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqrZCZeH8kiu",
        "colab_type": "code",
        "outputId": "82f65620-516e-4725-dbe8-6e491e9cc28a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(autoencoder, to_file='autoencoder.png', show_shapes=True)\n",
        "from IPython.display import Image\n",
        "Image(filename='autoencoder.png') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-93682344dead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'autoencoder.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'autoencoder.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'autoencoder' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpE0h9YwCPC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ClusteringLayer(Layer):\n",
        "    \"\"\"\n",
        "    Clustering layer converts input sample (feature) to soft label, i.e. a vector that represents the probability of the\n",
        "    sample belonging to each cluster. The probability is calculated with student's t-distribution.\n",
        "\n",
        "    # Example\n",
        "    ```\n",
        "        model.add(ClusteringLayer(n_clusters=10))\n",
        "    ```\n",
        "    # Arguments\n",
        "        n_clusters: number of clusters.\n",
        "        weights: list of Numpy array with shape `(n_clusters, n_features)` which represents the initial cluster centers.\n",
        "        alpha: degrees of freedom parameter in Student's t-distribution. Default to 1.0.\n",
        "    # Input shape\n",
        "        2D tensor with shape: `(n_samples, n_features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(n_samples, n_clusters)`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
        "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
        "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
        "        super(ClusteringLayer, self).__init__(**kwargs)\n",
        "        self.n_clusters = n_clusters\n",
        "        self.alpha = alpha\n",
        "        self.initial_weights = weights\n",
        "        self.input_spec = InputSpec(ndim=2)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 2\n",
        "        input_dim = input_shape[1]\n",
        "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
        "        self.clusters = self.add_weight((self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
        "        if self.initial_weights is not None:\n",
        "            self.set_weights(self.initial_weights)\n",
        "            del self.initial_weights\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        \"\"\" student t-distribution, as same as used in t-SNE algorithm.\n",
        "         Measure the similarity between embedded point z_i and centroid µ_j.\n",
        "                 q_ij = 1/(1+dist(x_i, µ_j)^2), then normalize it.\n",
        "                 q_ij can be interpreted as the probability of assigning sample i to cluster j.\n",
        "                 (i.e., a soft assignment)\n",
        "        Arguments:\n",
        "            inputs: the variable containing data, shape=(n_samples, n_features)\n",
        "        Return:\n",
        "            q: student's t-distribution, or soft labels for each sample. shape=(n_samples, n_clusters)\n",
        "        \"\"\"\n",
        "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
        "        q **= (self.alpha + 1.0) / 2.0\n",
        "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1)) # Make sure each sample's 10 values add up to 1.\n",
        "        return q\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        assert input_shape and len(input_shape) == 2\n",
        "        return input_shape[0], self.n_clusters\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'n_clusters': self.n_clusters}\n",
        "        base_config = super(ClusteringLayer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBWW-5j2CeE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# computing an auxiliary target distribution\n",
        "def target_distribution(q):\n",
        "    weight = q ** 2 / q.sum(0)\n",
        "    return (weight.T / weight.sum(1)).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR5uUeU7EKTr",
        "colab_type": "code",
        "outputId": "8cef02a0-3f5c-463f-d869-008feb9fcfc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "time_means_start = time.time()\n",
        "y_pred_train_list = []\n",
        "y_pred_train_list_means = []\n",
        "accuracy_list = []\n",
        "accuracy_means_list = []\n",
        "accuracy_ae_means_list=[]\n",
        "accuracy_ae_list = []\n",
        "tsne_list = []\n",
        "accuracy_dec_list = []\n",
        "label_list = []\n",
        "# dbs = [100, 50, 30, 20, 10] + [i for i in range(9, -1, -1)]\n",
        "sensitivities = [100, 20, 10] + [5/i for i in range(1, 6, 1)]\n",
        "for sensitivity in sensitivities:\n",
        "  if os.path.exists(os.path.join(synthetic_path, f'X_sparsity_1_std_{1/sensitivity:.2f}.npy')):\n",
        "    X = np.load(os.path.join(synthetic_path, f'X_sparsity_1_std_{1/sensitivity:.2f}.npy'))\n",
        "    labels = np.load(os.path.join(synthetic_path, f'labels_sparsity_1_std_{1/sensitivity:.2f}.npy'))\n",
        "    labels = torch.Tensor(labels)\n",
        "    X =  torch.Tensor(X)\n",
        "  else:\n",
        "    a = create_data(sparsity = 1,std=1/sensitivity)\n",
        "    X = a[0]\n",
        "    labels = a[1]\n",
        "    np.save(os.path.join(synthetic_path, f'X_sparsity_1_std_{1/sensitivity:.2f}.npy'), X)\n",
        "    np.save(os.path.join(synthetic_path, f'labels_sparsity_1_std_{1/sensitivity:.2f}.npy'), labels)\n",
        "  X = normalize(X.numpy(), axis = 0)\n",
        "\n",
        "  #===========================#\n",
        "  autoencoder, encoder = Autoencoder(dims, init=init)\n",
        "  autoencoder.compile(optimizer=pretrain_optimizer, loss='mse')\n",
        "  autoencoder.fit(X, X, batch_size=batch_size, epochs=pretrain_epochs) #, callbacks=cb)\n",
        "  autoencoder.save_weights(os.path.join(synthetic_path, f\"ae_sparsity_1_std_{1/sensitivity:.2f}.h5\"))\n",
        "  encoding = encoder.predict(X)\n",
        "  kmmeans = KMeans(n_clusters=2, n_init = 15).fit(encoding)\n",
        "  y_pred_ae_means = kmmeans.labels_\n",
        "  accs_ae_means = metrics.acc(labels.numpy().reshape(10002,), y_pred_ae_means.reshape(10002,))\n",
        "  print(\"Accuracy\",sensitivity, accs_ae_means)\n",
        "  accuracy_ae_means_list.append(accs_ae_means)\n",
        "  np.save(os.path.join(synthetic_path, f'encoding_sparsity_1_std_{1/sensitivity:.2f}.npy'), encoding)\n",
        "  del kmmeans, accs_ae_means\n",
        "  #============#\n",
        "  clustering_layer = ClusteringLayer(n_clusters = 2, name='clustering')(encoder.output)\n",
        "  model = Model(inputs=encoder.input, outputs=clustering_layer)\n",
        "  model.compile(optimizer=SGD(0.01, 0.9), loss='kld')\n",
        "  k_means = KMeans(n_clusters=2, n_init=20)\n",
        "  y_pred_ae = k_means.fit_predict(encoding) \n",
        "  y_pred_last = np.copy(y_pred_ae)\n",
        "  model.get_layer(name='clustering').set_weights([k_means.cluster_centers_])\n",
        "  # ===================#\n",
        "  loss = 0\n",
        "  index = 0\n",
        "  maxiter = 8000\n",
        "  update_interval = 140\n",
        "  index_array = np.arange(X.shape[0])\n",
        "  tol = 0.001 \n",
        "  acc = 0\n",
        "  #=====================#\n",
        "  for ite in range(int(maxiter)):\n",
        "      if ite % update_interval == 0:\n",
        "          q = model.predict(X, verbose=0)\n",
        "          p = target_distribution(q) \n",
        "          y_pred_ae = q.argmax(1)\n",
        "          print(y_pred_ae.shape)\n",
        "          print(labels.numpy().shape)\n",
        "          if labels.numpy() is not None:\n",
        "              acc = np.round(metrics.acc(labels.numpy().reshape(10002,), y_pred_ae), 5)\n",
        "              nmi = np.round(metrics.nmi(labels.numpy().reshape(10002,), y_pred_ae), 5)\n",
        "              ari = np.round(metrics.ari(labels.numpy().reshape(10002,), y_pred_ae), 5)\n",
        "              loss = np.round(loss, 5)\n",
        "              print('Iter %d: acc = %.5f, nmi = %.5f, ari = %.5f' % (ite, acc, nmi, ari), ' ; loss=', loss)\n",
        "          delta_label = np.sum(y_pred_ae != y_pred_last).astype(np.float32) / y_pred_ae.shape[0]\n",
        "          y_pred_last = np.copy(y_pred_ae)\n",
        "          if ite > 0 and delta_label < tol:\n",
        "              print('delta_label ', delta_label, '< tol ', tol)\n",
        "              print('Reached tolerance threshold. Stopping training.')\n",
        "              break\n",
        "      idx = index_array[index * batch_size: min((index+1) * batch_size, X.shape[0])]\n",
        "      loss = model.train_on_batch(x=X[idx], y=p[idx])\n",
        "      index = index + 1 if (index + 1) * batch_size <= X.shape[0] else 0\n",
        "  accuracy_dec_list.append(acc)\n",
        "  model.save_weights(os.path.join(synthetic_path, f'DEC_model_final_sparsity_1_std_{1/sensitivity:.2f}.h5'))\n",
        "  encoded_dec = encoder.predict(X)\n",
        "  np.save(os.path.join(synthetic_path, f'encoded_dec_sparsity_1_std_{1/sensitivity:.2f}.npy'), encoded_dec)\n",
        "  del encoding, loss, idx, index, model,acc,nmi, ari, clustering_layer, k_means, y_pred_last, delta_label, encoded_dec\n",
        "  #===========================#\n",
        "\n",
        "  #=========================#\n",
        "  gmmodel = mixture.GaussianMixture(n_components = 2, random_state = 42)\n",
        "  gmmodel.fit(X)  \n",
        "  y_pred_train = gmmodel.predict(X)\n",
        "  print(f'Gaussian Mixtures Models Done for std = {1/sensitivity:.2f}. Time elapsed = {time.time()-time_means_start:.2f}s')\n",
        "  accuracy = metrics.acc(labels.numpy(), y_pred_train)\n",
        "  print(f'Gaussian Mixture Model Accuracy = {(accuracy)*100:.2f}%')\n",
        "  #===========================#\n",
        "\n",
        "  #===========================#\n",
        "  kmodel = KMeans(n_clusters = 2, random_state = 42)\n",
        "  kmeans = kmodel.fit(X)\n",
        "  print(f'KMeans completed. Time elapsed = {time.time()-time_means_start:.2f}s')\n",
        "  y_pred_train_means = kmeans.labels_\n",
        "  accuracy_means = metrics.acc(labels.numpy(), y_pred_train_means)\n",
        "  print(f'KMeans Accuracy = {accuracy_means*100:.2f}%')\n",
        "  #===========================#\n",
        "  \n",
        "  #===========================#\n",
        "  # print(f'TSNE Started. Time elapsed = {time.time()-time_means_start:.2f}s')\n",
        "  # tsne =  TSNE(n_components=2, random_state=42).fit_transform(X)\n",
        "  # np.save(os.path.join(synthetic_path, f'tsne_sparsity_1_sensitivity_{sensitivity}'), tsne)\n",
        "  # print(f'TSNE Completed. Time elapsed = {time.time()-time_means_start:.2f}s')\n",
        "  # tsne_list.append(tsne)\n",
        "  # del tsne\n",
        "  #===========================#\n",
        "\n",
        "  #===========================#\n",
        "  y_pred_train_list_means.append(y_pred_train_means)\n",
        "  accuracy_means_list.append(accuracy_means)\n",
        "  accuracy_list.append(accuracy)\n",
        "  y_pred_train_list.append(y_pred_train)\n",
        "  label_list.append(labels)\n",
        "  \n",
        "  np.save(os.path.join(synthetic_path, f'gmm_preds_sparsity_1_std_{1/sensitivity:.2f}'), y_pred_train)\n",
        "  np.save(os.path.join(synthetic_path, f'kmeans_preds_sparsity_1_std_{1/sensitivity:.2f}'), y_pred_train_means)\n",
        "  del kmodel\n",
        "  del autoencoder\n",
        "  del encoder\n",
        "  del gmmodel\n",
        "  del X\n",
        "  del labels\n",
        "  del y_pred_train\n",
        "  print(f'Done time elapsed = {time.time()-time_means_start:.2f}s') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "10002/10002 [==============================] - 2s 191us/step - loss: 0.0883\n",
            "Epoch 2/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0013\n",
            "Epoch 3/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 0.0021\n",
            "Epoch 4/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 2.8726e-04\n",
            "Epoch 5/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 1.2786e-04\n",
            "Epoch 6/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 1.3770e-04\n",
            "Epoch 7/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 1.0394e-04\n",
            "Epoch 8/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 8.7034e-05\n",
            "Epoch 9/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 7.5205e-05\n",
            "Epoch 10/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 4.2812e-05\n",
            "Epoch 11/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 6.6054e-05\n",
            "Epoch 12/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 8.5123e-05\n",
            "Epoch 13/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 3.1457e-05\n",
            "Epoch 14/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 2.5204e-05\n",
            "Epoch 15/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 3.5326e-05\n",
            "Epoch 16/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 3.6565e-05\n",
            "Epoch 17/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 8.4093e-04\n",
            "Epoch 18/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 2.9588e-05\n",
            "Epoch 19/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 1.2454e-04\n",
            "Epoch 20/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 9.7793e-06\n",
            "Epoch 21/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 1.0030e-05\n",
            "Epoch 22/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 9.8907e-06\n",
            "Epoch 23/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 1.8509e-04\n",
            "Epoch 24/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 1.0830e-05\n",
            "Epoch 25/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 3.4735e-06\n",
            "Epoch 26/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 4.2308e-05\n",
            "Epoch 27/30\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 2.0270e-06\n",
            "Epoch 28/30\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 2.1331e-06\n",
            "Epoch 29/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 4.2454e-05\n",
            "Epoch 30/30\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 1.7059e-06\n",
            "Accuracy 100 1.0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 0: acc = 1.00000, nmi = 1.00000, ari = 1.00000  ; loss= 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 140: acc = 1.00000, nmi = 1.00000, ari = 1.00000  ; loss= 0.00096\n",
            "delta_label  0.0 < tol  0.001\n",
            "Reached tolerance threshold. Stopping training.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gaussian Mixtures Models Done for std = 0.01. Time elapsed = 26.94s\n",
            "Gaussian Mixture Model Accuracy = 100.00%\n",
            "KMeans completed. Time elapsed = 27.12s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KMeans Accuracy = 100.00%\n",
            "Done time elapsed = 27.20s\n",
            "Creating Uniform data\n",
            "Creating Sparse Data\n",
            "Epoch 1/30\n",
            "10002/10002 [==============================] - 2s 227us/step - loss: 0.0896\n",
            "Epoch 2/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0014\n",
            "Epoch 3/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 8.5859e-04\n",
            "Epoch 4/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 2.8772e-04\n",
            "Epoch 5/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.6076e-04\n",
            "Epoch 6/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 7.9731e-05\n",
            "Epoch 7/30\n",
            "10002/10002 [==============================] - 1s 54us/step - loss: 8.5103e-05\n",
            "Epoch 8/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 7.2647e-05\n",
            "Epoch 9/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 7.1080e-05\n",
            "Epoch 10/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 7.8064e-05\n",
            "Epoch 11/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 2.3922e-04\n",
            "Epoch 12/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.0017\n",
            "Epoch 13/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 1.9678e-04\n",
            "Epoch 14/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 9.2343e-05\n",
            "Epoch 15/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.2224e-04\n",
            "Epoch 16/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 4.5063e-04\n",
            "Epoch 17/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.0018\n",
            "Epoch 18/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 5.8625e-04\n",
            "Epoch 19/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 6.1459e-04\n",
            "Epoch 20/30\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 2.8268e-05\n",
            "Epoch 21/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.5873e-05\n",
            "Epoch 22/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 1.1786e-05\n",
            "Epoch 23/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 6.0429e-05\n",
            "Epoch 24/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 0.0015\n",
            "Epoch 25/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.1173e-04\n",
            "Epoch 26/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 1.0131e-04\n",
            "Epoch 27/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 9.4185e-05\n",
            "Epoch 28/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 8.9989e-05\n",
            "Epoch 29/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.2933e-04\n",
            "Epoch 30/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 2.8038e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy 20 1.0\n",
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 0: acc = 1.00000, nmi = 1.00000, ari = 1.00000  ; loss= 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 140: acc = 1.00000, nmi = 1.00000, ari = 1.00000  ; loss= 0.0068\n",
            "delta_label  0.0 < tol  0.001\n",
            "Reached tolerance threshold. Stopping training.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gaussian Mixtures Models Done for std = 0.05. Time elapsed = 56.01s\n",
            "Gaussian Mixture Model Accuracy = 100.00%\n",
            "KMeans completed. Time elapsed = 56.19s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KMeans Accuracy = 100.00%\n",
            "Done time elapsed = 56.27s\n",
            "Epoch 1/30\n",
            "10002/10002 [==============================] - 3s 278us/step - loss: 0.0915\n",
            "Epoch 2/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.0021\n",
            "Epoch 3/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 5.0540e-04\n",
            "Epoch 4/30\n",
            "10002/10002 [==============================] - 1s 64us/step - loss: 2.2445e-04\n",
            "Epoch 5/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 1.5698e-04\n",
            "Epoch 6/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 7.1459e-05\n",
            "Epoch 7/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 7.8547e-05\n",
            "Epoch 8/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 5.0269e-05\n",
            "Epoch 9/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 7.0820e-05\n",
            "Epoch 10/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 1.1894e-04\n",
            "Epoch 11/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 2.0367e-04\n",
            "Epoch 12/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 6.7147e-05\n",
            "Epoch 13/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 5.0004e-05\n",
            "Epoch 14/30\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 1.1281e-04\n",
            "Epoch 15/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 7.3909e-05\n",
            "Epoch 16/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 1.6781e-04\n",
            "Epoch 17/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 7.5215e-05\n",
            "Epoch 18/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 9.9366e-05\n",
            "Epoch 19/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 5.2483e-05\n",
            "Epoch 20/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 6.1492e-05\n",
            "Epoch 21/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.8623e-05\n",
            "Epoch 22/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 3.4094e-05\n",
            "Epoch 23/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 4.5526e-04\n",
            "Epoch 24/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 1.7004e-04\n",
            "Epoch 25/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 1.2058e-04\n",
            "Epoch 26/30\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 1.1624e-04\n",
            "Epoch 27/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 7.5963e-04\n",
            "Epoch 28/30\n",
            "10002/10002 [==============================] - 1s 55us/step - loss: 4.8858e-05\n",
            "Epoch 29/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 7.0860e-05\n",
            "Epoch 30/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.8250e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy 10 1.0\n",
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 0: acc = 1.00000, nmi = 1.00000, ari = 1.00000  ; loss= 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 140: acc = 1.00000, nmi = 1.00000, ari = 1.00000  ; loss= 0.00159\n",
            "delta_label  0.0 < tol  0.001\n",
            "Reached tolerance threshold. Stopping training.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gaussian Mixtures Models Done for std = 0.10. Time elapsed = 88.17s\n",
            "Gaussian Mixture Model Accuracy = 100.00%\n",
            "KMeans completed. Time elapsed = 88.37s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KMeans Accuracy = 100.00%\n",
            "Done time elapsed = 88.45s\n",
            "Epoch 1/30\n",
            "10002/10002 [==============================] - 3s 308us/step - loss: 0.0926\n",
            "Epoch 2/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0014\n",
            "Epoch 3/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 5.1279e-04\n",
            "Epoch 4/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 3.2276e-04\n",
            "Epoch 5/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 8.4797e-04\n",
            "Epoch 6/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 3.9076e-04\n",
            "Epoch 7/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.5592e-04\n",
            "Epoch 8/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.0870e-04\n",
            "Epoch 9/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.6877e-04\n",
            "Epoch 10/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 9.2521e-05\n",
            "Epoch 11/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 6.9481e-05\n",
            "Epoch 12/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 9.1819e-05\n",
            "Epoch 13/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 7.3821e-05\n",
            "Epoch 14/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 6.1034e-05\n",
            "Epoch 15/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 7.2770e-05\n",
            "Epoch 16/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.3092e-04\n",
            "Epoch 17/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 5.4774e-05\n",
            "Epoch 18/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 1.4047e-04\n",
            "Epoch 19/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 9.6144e-05\n",
            "Epoch 20/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.1807e-04\n",
            "Epoch 21/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 6.4949e-05\n",
            "Epoch 22/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 9.9895e-05\n",
            "Epoch 23/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 3.8370e-05\n",
            "Epoch 24/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 4.8098e-05\n",
            "Epoch 25/30\n",
            "10002/10002 [==============================] - 1s 62us/step - loss: 3.4354e-05\n",
            "Epoch 26/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 4.8158e-05\n",
            "Epoch 27/30\n",
            "10002/10002 [==============================] - 1s 62us/step - loss: 6.6349e-05\n",
            "Epoch 28/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 3.8212e-05\n",
            "Epoch 29/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 3.0712e-05\n",
            "Epoch 30/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 3.4885e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy 5.0 1.0\n",
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 0: acc = 1.00000, nmi = 1.00000, ari = 1.00000  ; loss= 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 140: acc = 1.00000, nmi = 1.00000, ari = 1.00000  ; loss= 0.00557\n",
            "delta_label  0.0 < tol  0.001\n",
            "Reached tolerance threshold. Stopping training.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gaussian Mixtures Models Done for std = 0.20. Time elapsed = 123.32s\n",
            "Gaussian Mixture Model Accuracy = 100.00%\n",
            "KMeans completed. Time elapsed = 123.50s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KMeans Accuracy = 100.00%\n",
            "Done time elapsed = 123.58s\n",
            "Creating Uniform data\n",
            "Creating Sparse Data\n",
            "Epoch 1/30\n",
            "10002/10002 [==============================] - 4s 357us/step - loss: 0.0977\n",
            "Epoch 2/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.0015\n",
            "Epoch 3/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 5.4250e-04\n",
            "Epoch 4/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 4.8587e-04\n",
            "Epoch 5/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 3.5126e-04\n",
            "Epoch 6/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 4.3768e-04\n",
            "Epoch 7/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 2.8838e-04\n",
            "Epoch 8/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.6566e-04\n",
            "Epoch 9/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 2.4943e-04\n",
            "Epoch 10/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 2.1298e-04\n",
            "Epoch 11/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.1249e-04\n",
            "Epoch 12/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.1251e-04\n",
            "Epoch 13/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 2.0234e-04\n",
            "Epoch 14/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 2.7172e-04\n",
            "Epoch 15/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.8601e-04\n",
            "Epoch 16/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.8373e-04\n",
            "Epoch 17/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 1.5939e-04\n",
            "Epoch 18/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.8146e-04\n",
            "Epoch 19/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.7719e-04\n",
            "Epoch 20/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 1.6322e-04\n",
            "Epoch 21/30\n",
            "10002/10002 [==============================] - 1s 56us/step - loss: 1.9197e-04\n",
            "Epoch 22/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.5814e-04\n",
            "Epoch 23/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 1.4634e-04\n",
            "Epoch 24/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.4063e-04\n",
            "Epoch 25/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.3873e-04\n",
            "Epoch 26/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.5481e-04\n",
            "Epoch 27/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.2916e-04\n",
            "Epoch 28/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.1051e-04\n",
            "Epoch 29/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.5283e-04\n",
            "Epoch 30/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.8923e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy 2.5 0.8396320735852829\n",
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 0: acc = 0.84003, nmi = 0.40783, ari = 0.46244  ; loss= 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 140: acc = 0.84193, nmi = 0.42293, ari = 0.46762  ; loss= 0.00935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 280: acc = 0.84993, nmi = 0.45454, ari = 0.48976  ; loss= 0.06333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 420: acc = 0.85103, nmi = 0.47393, ari = 0.49284  ; loss= 0.0121\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 560: acc = 0.85233, nmi = 0.48784, ari = 0.49650  ; loss= 0.08203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 700: acc = 0.84963, nmi = 0.48839, ari = 0.48892  ; loss= 0.01136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 840: acc = 0.85033, nmi = 0.49376, ari = 0.49088  ; loss= 0.0852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 980: acc = 0.84963, nmi = 0.49398, ari = 0.48892  ; loss= 0.01021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1120: acc = 0.85153, nmi = 0.49879, ari = 0.49425  ; loss= 0.07872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1260: acc = 0.85173, nmi = 0.50031, ari = 0.49481  ; loss= 0.00915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1400: acc = 0.85193, nmi = 0.50127, ari = 0.49537  ; loss= 0.06874\n",
            "delta_label  0.0003999200159968006 < tol  0.001\n",
            "Reached tolerance threshold. Stopping training.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gaussian Mixtures Models Done for std = 0.40. Time elapsed = 174.13s\n",
            "Gaussian Mixture Model Accuracy = 99.62%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KMeans completed. Time elapsed = 174.35s\n",
            "KMeans Accuracy = 99.18%\n",
            "Done time elapsed = 174.44s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "10002/10002 [==============================] - 4s 402us/step - loss: 0.0757\n",
            "Epoch 2/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 0.0012\n",
            "Epoch 3/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 6.1391e-04\n",
            "Epoch 4/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 3.6173e-04\n",
            "Epoch 5/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.8917e-04\n",
            "Epoch 6/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 5.4869e-04\n",
            "Epoch 7/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.9264e-04\n",
            "Epoch 8/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 3.2402e-04\n",
            "Epoch 9/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 2.1030e-04\n",
            "Epoch 10/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 2.3858e-04\n",
            "Epoch 11/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.3908e-04\n",
            "Epoch 12/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.6210e-04\n",
            "Epoch 13/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.3671e-04\n",
            "Epoch 14/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.3533e-04\n",
            "Epoch 15/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.4771e-04\n",
            "Epoch 16/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 1.0992e-04\n",
            "Epoch 17/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.2949e-04\n",
            "Epoch 18/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 1.5676e-04\n",
            "Epoch 19/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 1.4587e-04\n",
            "Epoch 20/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.1099e-04\n",
            "Epoch 21/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.4756e-04\n",
            "Epoch 22/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.0504e-04\n",
            "Epoch 23/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.0614e-04\n",
            "Epoch 24/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 1.1041e-04\n",
            "Epoch 25/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.6510e-04\n",
            "Epoch 26/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.3116e-04\n",
            "Epoch 27/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.5183e-04\n",
            "Epoch 28/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 1.0363e-04\n",
            "Epoch 29/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 9.0209e-05\n",
            "Epoch 30/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 9.8758e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy 1.6666666666666667 0.7792441511697661\n",
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 0: acc = 0.77924, nmi = 0.24141, ari = 0.31184  ; loss= 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 140: acc = 0.77554, nmi = 0.24100, ari = 0.30363  ; loss= 0.01416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 280: acc = 0.77455, nmi = 0.24118, ari = 0.30143  ; loss= 0.01692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 420: acc = 0.77554, nmi = 0.24385, ari = 0.30363  ; loss= 0.02232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 560: acc = 0.77514, nmi = 0.24569, ari = 0.30275  ; loss= 0.013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 700: acc = 0.77904, nmi = 0.25056, ari = 0.31140  ; loss= 0.02988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 840: acc = 0.77754, nmi = 0.25023, ari = 0.30806  ; loss= 0.01175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 980: acc = 0.78404, nmi = 0.25735, ari = 0.32266  ; loss= 0.03131\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1120: acc = 0.78534, nmi = 0.25976, ari = 0.32562  ; loss= 0.01707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1260: acc = 0.78744, nmi = 0.26251, ari = 0.33043  ; loss= 0.02641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1400: acc = 0.78754, nmi = 0.26317, ari = 0.33066  ; loss= 0.0255\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1540: acc = 0.79074, nmi = 0.26794, ari = 0.33806  ; loss= 0.02535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1680: acc = 0.79074, nmi = 0.26672, ari = 0.33806  ; loss= 0.02688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1820: acc = 0.79164, nmi = 0.26766, ari = 0.34015  ; loss= 0.02379\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1960: acc = 0.79164, nmi = 0.26670, ari = 0.34015  ; loss= 0.02702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2100: acc = 0.79264, nmi = 0.26744, ari = 0.34249  ; loss= 0.02318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2240: acc = 0.79364, nmi = 0.26825, ari = 0.34484  ; loss= 0.03127\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2380: acc = 0.79474, nmi = 0.27027, ari = 0.34742  ; loss= 0.02098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2520: acc = 0.79654, nmi = 0.27263, ari = 0.35168  ; loss= 0.03358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2660: acc = 0.79684, nmi = 0.27326, ari = 0.35239  ; loss= 0.01765\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2800: acc = 0.79724, nmi = 0.27336, ari = 0.35334  ; loss= 0.03237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2940: acc = 0.79784, nmi = 0.27467, ari = 0.35477  ; loss= 0.01659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3080: acc = 0.79854, nmi = 0.27563, ari = 0.35644  ; loss= 0.02999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3220: acc = 0.79894, nmi = 0.27648, ari = 0.35740  ; loss= 0.01673\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3360: acc = 0.79964, nmi = 0.27754, ari = 0.35907  ; loss= 0.02748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3500: acc = 0.80024, nmi = 0.27893, ari = 0.36051  ; loss= 0.01708\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3640: acc = 0.80054, nmi = 0.27918, ari = 0.36123  ; loss= 0.02571\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3780: acc = 0.80224, nmi = 0.28274, ari = 0.36533  ; loss= 0.01769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3920: acc = 0.80264, nmi = 0.28338, ari = 0.36630  ; loss= 0.0237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4060: acc = 0.80334, nmi = 0.28493, ari = 0.36800  ; loss= 0.01743\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4200: acc = 0.80414, nmi = 0.28644, ari = 0.36994  ; loss= 0.02237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4340: acc = 0.80454, nmi = 0.28724, ari = 0.37091  ; loss= 0.01772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4480: acc = 0.80504, nmi = 0.28840, ari = 0.37213  ; loss= 0.02067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4620: acc = 0.80494, nmi = 0.28810, ari = 0.37189  ; loss= 0.01917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4760: acc = 0.80654, nmi = 0.29159, ari = 0.37580  ; loss= 0.01945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4900: acc = 0.80634, nmi = 0.29103, ari = 0.37531  ; loss= 0.01916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5040: acc = 0.80644, nmi = 0.29144, ari = 0.37556  ; loss= 0.01833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5180: acc = 0.80694, nmi = 0.29241, ari = 0.37678  ; loss= 0.01975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5320: acc = 0.80684, nmi = 0.29242, ari = 0.37654  ; loss= 0.01724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5460: acc = 0.80664, nmi = 0.29204, ari = 0.37605  ; loss= 0.02099\n",
            "delta_label  0.0007998400319936012 < tol  0.001\n",
            "Reached tolerance threshold. Stopping training.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gaussian Mixtures Models Done for std = 0.60. Time elapsed = 270.38s\n",
            "Gaussian Mixture Model Accuracy = 80.38%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KMeans completed. Time elapsed = 270.76s\n",
            "KMeans Accuracy = 79.63%\n",
            "Done time elapsed = 270.83s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "10002/10002 [==============================] - 4s 445us/step - loss: 0.0767\n",
            "Epoch 2/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 0.0013\n",
            "Epoch 3/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 6.2647e-04\n",
            "Epoch 4/30\n",
            "10002/10002 [==============================] - 1s 62us/step - loss: 6.5491e-04\n",
            "Epoch 5/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 7.6163e-04\n",
            "Epoch 6/30\n",
            "10002/10002 [==============================] - 1s 64us/step - loss: 4.5475e-04\n",
            "Epoch 7/30\n",
            "10002/10002 [==============================] - 1s 62us/step - loss: 3.1851e-04\n",
            "Epoch 8/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.6458e-04\n",
            "Epoch 9/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.2862e-04\n",
            "Epoch 10/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 2.3079e-04\n",
            "Epoch 11/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 2.2121e-04\n",
            "Epoch 12/30\n",
            "10002/10002 [==============================] - 1s 62us/step - loss: 2.1653e-04\n",
            "Epoch 13/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 3.0449e-04\n",
            "Epoch 14/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 2.6291e-04\n",
            "Epoch 15/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 1.5483e-04\n",
            "Epoch 16/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 2.2728e-04\n",
            "Epoch 17/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.8286e-04\n",
            "Epoch 18/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.5034e-04\n",
            "Epoch 19/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.7120e-04\n",
            "Epoch 20/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 1.5517e-04\n",
            "Epoch 21/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.4170e-04\n",
            "Epoch 22/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.2974e-04\n",
            "Epoch 23/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.2763e-04\n",
            "Epoch 24/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.7153e-04\n",
            "Epoch 25/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.3212e-04\n",
            "Epoch 26/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 1.0401e-04\n",
            "Epoch 27/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.6296e-04\n",
            "Epoch 28/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.1069e-04\n",
            "Epoch 29/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 1.7423e-04\n",
            "Epoch 30/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.0142e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy 1.25 0.6690661867626475\n",
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 0: acc = 0.66907, nmi = 0.11805, ari = 0.11426  ; loss= 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 140: acc = 0.68476, nmi = 0.12254, ari = 0.13647  ; loss= 0.02987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 280: acc = 0.69526, nmi = 0.12710, ari = 0.15243  ; loss= 0.05783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 420: acc = 0.69576, nmi = 0.12785, ari = 0.15321  ; loss= 0.02958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 560: acc = 0.70306, nmi = 0.13379, ari = 0.16485  ; loss= 0.09083\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 700: acc = 0.69646, nmi = 0.12804, ari = 0.15431  ; loss= 0.02519\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 840: acc = 0.69976, nmi = 0.13027, ari = 0.15954  ; loss= 0.10029\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 980: acc = 0.69046, nmi = 0.12130, ari = 0.14502  ; loss= 0.03024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1120: acc = 0.68866, nmi = 0.11789, ari = 0.14229  ; loss= 0.07298\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1260: acc = 0.69296, nmi = 0.11968, ari = 0.14886  ; loss= 0.04123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1400: acc = 0.69586, nmi = 0.11999, ari = 0.15336  ; loss= 0.13587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1540: acc = 0.69036, nmi = 0.11477, ari = 0.14487  ; loss= 0.0578\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1680: acc = 0.68816, nmi = 0.11140, ari = 0.14154  ; loss= 0.08752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1820: acc = 0.67576, nmi = 0.09811, ari = 0.12349  ; loss= 0.07072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1960: acc = 0.66967, nmi = 0.08903, ari = 0.11506  ; loss= 0.04834\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2100: acc = 0.65087, nmi = 0.07133, ari = 0.09096  ; loss= 0.10918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2240: acc = 0.64367, nmi = 0.06303, ari = 0.08248  ; loss= 0.0219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2380: acc = 0.62537, nmi = 0.04830, ari = 0.06279  ; loss= 0.11904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2520: acc = 0.61808, nmi = 0.04273, ari = 0.05568  ; loss= 0.04348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2660: acc = 0.59578, nmi = 0.02779, ari = 0.03660  ; loss= 0.09429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2800: acc = 0.58528, nmi = 0.02211, ari = 0.02900  ; loss= 0.0657\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2940: acc = 0.55969, nmi = 0.01058, ari = 0.01415  ; loss= 0.11033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3080: acc = 0.54669, nmi = 0.00648, ari = 0.00862  ; loss= 0.12969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3220: acc = 0.52949, nmi = 0.00256, ari = 0.00338  ; loss= 0.12691\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3360: acc = 0.52040, nmi = 0.00122, ari = 0.00157  ; loss= 0.04649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3500: acc = 0.50280, nmi = 0.00002, ari = -0.00007  ; loss= 0.10235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3640: acc = 0.51010, nmi = 0.00029, ari = 0.00031  ; loss= 0.14027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3780: acc = 0.52809, nmi = 0.00228, ari = 0.00306  ; loss= 0.11557\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3920: acc = 0.53039, nmi = 0.00267, ari = 0.00360  ; loss= 0.32603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4060: acc = 0.54569, nmi = 0.00606, ari = 0.00825  ; loss= 0.11104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4200: acc = 0.53879, nmi = 0.00437, ari = 0.00592  ; loss= 0.30988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4340: acc = 0.55169, nmi = 0.00777, ari = 0.01059  ; loss= 0.10241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4480: acc = 0.54329, nmi = 0.00544, ari = 0.00740  ; loss= 0.30002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4620: acc = 0.55789, nmi = 0.00975, ari = 0.01331  ; loss= 0.09855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4760: acc = 0.55099, nmi = 0.00755, ari = 0.01030  ; loss= 0.30904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4900: acc = 0.56459, nmi = 0.01218, ari = 0.01659  ; loss= 0.099\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5040: acc = 0.55799, nmi = 0.00981, ari = 0.01335  ; loss= 0.3206\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5180: acc = 0.56869, nmi = 0.01382, ari = 0.01877  ; loss= 0.09522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5320: acc = 0.56009, nmi = 0.01058, ari = 0.01434  ; loss= 0.31228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5460: acc = 0.57309, nmi = 0.01574, ari = 0.02127  ; loss= 0.09013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5600: acc = 0.56649, nmi = 0.01305, ari = 0.01759  ; loss= 0.29733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5740: acc = 0.57419, nmi = 0.01629, ari = 0.02192  ; loss= 0.08486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5880: acc = 0.56879, nmi = 0.01404, ari = 0.01883  ; loss= 0.28336\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 6020: acc = 0.57768, nmi = 0.01795, ari = 0.02404  ; loss= 0.08597\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 6160: acc = 0.57019, nmi = 0.01470, ari = 0.01961  ; loss= 0.27318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 6300: acc = 0.58178, nmi = 0.02013, ari = 0.02666  ; loss= 0.0911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 6440: acc = 0.57349, nmi = 0.01630, ari = 0.02151  ; loss= 0.26148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 6580: acc = 0.58458, nmi = 0.02171, ari = 0.02852  ; loss= 0.10428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 6720: acc = 0.57648, nmi = 0.01784, ari = 0.02331  ; loss= 0.25135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 6860: acc = 0.58708, nmi = 0.02327, ari = 0.03024  ; loss= 0.109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7000: acc = 0.58308, nmi = 0.02127, ari = 0.02752  ; loss= 0.24412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7140: acc = 0.59128, nmi = 0.02567, ari = 0.03324  ; loss= 0.108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7280: acc = 0.58738, nmi = 0.02361, ari = 0.03045  ; loss= 0.2427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7420: acc = 0.59588, nmi = 0.02847, ari = 0.03668  ; loss= 0.09638\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7560: acc = 0.59288, nmi = 0.02673, ari = 0.03442  ; loss= 0.24072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7700: acc = 0.60108, nmi = 0.03177, ari = 0.04078  ; loss= 0.09009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7840: acc = 0.59878, nmi = 0.03031, ari = 0.03894  ; loss= 0.23921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7980: acc = 0.60928, nmi = 0.03729, ari = 0.04768  ; loss= 0.0771\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gaussian Mixtures Models Done for std = 0.80. Time elapsed = 397.08s\n",
            "Gaussian Mixture Model Accuracy = 63.34%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KMeans completed. Time elapsed = 397.44s\n",
            "KMeans Accuracy = 63.36%\n",
            "Done time elapsed = 397.51s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "10002/10002 [==============================] - 5s 500us/step - loss: 0.0718\n",
            "Epoch 2/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.0012\n",
            "Epoch 3/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 3.7133e-04\n",
            "Epoch 4/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 3.4280e-04\n",
            "Epoch 5/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 3.3857e-04\n",
            "Epoch 6/30\n",
            "10002/10002 [==============================] - 1s 62us/step - loss: 3.3023e-04\n",
            "Epoch 7/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.0374e-04\n",
            "Epoch 8/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.2958e-04\n",
            "Epoch 9/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.6349e-04\n",
            "Epoch 10/30\n",
            "10002/10002 [==============================] - 1s 62us/step - loss: 2.5680e-04\n",
            "Epoch 11/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 1.9259e-04\n",
            "Epoch 12/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 1.9697e-04\n",
            "Epoch 13/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.0317e-04\n",
            "Epoch 14/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.4927e-04\n",
            "Epoch 15/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 1.5797e-04\n",
            "Epoch 16/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 2.4136e-04\n",
            "Epoch 17/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.5156e-04\n",
            "Epoch 18/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.4560e-04\n",
            "Epoch 19/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 1.1840e-04\n",
            "Epoch 20/30\n",
            "10002/10002 [==============================] - 1s 63us/step - loss: 1.4345e-04\n",
            "Epoch 21/30\n",
            "10002/10002 [==============================] - 1s 62us/step - loss: 1.1650e-04\n",
            "Epoch 22/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 1.0294e-04\n",
            "Epoch 23/30\n",
            "10002/10002 [==============================] - 1s 65us/step - loss: 1.0713e-04\n",
            "Epoch 24/30\n",
            "10002/10002 [==============================] - 1s 63us/step - loss: 1.2758e-04\n",
            "Epoch 25/30\n",
            "10002/10002 [==============================] - 1s 63us/step - loss: 1.0221e-04\n",
            "Epoch 26/30\n",
            "10002/10002 [==============================] - 1s 64us/step - loss: 2.4861e-04\n",
            "Epoch 27/30\n",
            "10002/10002 [==============================] - 1s 62us/step - loss: 1.3189e-04\n",
            "Epoch 28/30\n",
            "10002/10002 [==============================] - 1s 63us/step - loss: 1.4074e-04\n",
            "Epoch 29/30\n",
            "10002/10002 [==============================] - 1s 60us/step - loss: 1.1364e-04\n",
            "Epoch 30/30\n",
            "10002/10002 [==============================] - 1s 61us/step - loss: 1.1384e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy 1.0 0.5615876824635073\n",
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 0: acc = 0.56219, nmi = 0.01191, ari = 0.01538  ; loss= 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 140: acc = 0.56359, nmi = 0.01216, ari = 0.01608  ; loss= 0.01146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 280: acc = 0.56689, nmi = 0.01307, ari = 0.01780  ; loss= 0.09239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 420: acc = 0.56889, nmi = 0.01375, ari = 0.01888  ; loss= 0.02201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 560: acc = 0.57039, nmi = 0.01441, ari = 0.01972  ; loss= 0.18207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 700: acc = 0.57219, nmi = 0.01526, ari = 0.02075  ; loss= 0.02903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 840: acc = 0.57259, nmi = 0.01538, ari = 0.02098  ; loss= 0.16784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 980: acc = 0.57269, nmi = 0.01538, ari = 0.02104  ; loss= 0.02314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1120: acc = 0.57369, nmi = 0.01575, ari = 0.02162  ; loss= 0.1331\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1260: acc = 0.57499, nmi = 0.01629, ari = 0.02239  ; loss= 0.01695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1400: acc = 0.57508, nmi = 0.01634, ari = 0.02245  ; loss= 0.14688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1540: acc = 0.57528, nmi = 0.01645, ari = 0.02257  ; loss= 0.01686\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1680: acc = 0.57469, nmi = 0.01625, ari = 0.02221  ; loss= 0.10922\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1820: acc = 0.57528, nmi = 0.01655, ari = 0.02257  ; loss= 0.01673\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 1960: acc = 0.57499, nmi = 0.01647, ari = 0.02239  ; loss= 0.13822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2100: acc = 0.57329, nmi = 0.01577, ari = 0.02139  ; loss= 0.01433\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2240: acc = 0.57419, nmi = 0.01626, ari = 0.02192  ; loss= 0.0892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2380: acc = 0.57299, nmi = 0.01586, ari = 0.02121  ; loss= 0.01358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2520: acc = 0.57079, nmi = 0.01518, ari = 0.01995  ; loss= 0.04089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2660: acc = 0.57039, nmi = 0.01507, ari = 0.01972  ; loss= 0.01532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2800: acc = 0.56749, nmi = 0.01426, ari = 0.01813  ; loss= 0.0193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 2940: acc = 0.56679, nmi = 0.01399, ari = 0.01775  ; loss= 0.01535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3080: acc = 0.56559, nmi = 0.01385, ari = 0.01712  ; loss= 0.00815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3220: acc = 0.56549, nmi = 0.01382, ari = 0.01706  ; loss= 0.01428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3360: acc = 0.56529, nmi = 0.01404, ari = 0.01696  ; loss= 0.00705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3500: acc = 0.56409, nmi = 0.01350, ari = 0.01634  ; loss= 0.01348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3640: acc = 0.56489, nmi = 0.01411, ari = 0.01675  ; loss= 0.00617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3780: acc = 0.56359, nmi = 0.01357, ari = 0.01609  ; loss= 0.01301\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 3920: acc = 0.56439, nmi = 0.01352, ari = 0.01649  ; loss= 0.00541\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4060: acc = 0.56449, nmi = 0.01323, ari = 0.01654  ; loss= 0.01117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4200: acc = 0.56419, nmi = 0.01330, ari = 0.01639  ; loss= 0.01041\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4340: acc = 0.56289, nmi = 0.01281, ari = 0.01573  ; loss= 0.01273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4480: acc = 0.56309, nmi = 0.01322, ari = 0.01583  ; loss= 0.00478\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4620: acc = 0.56219, nmi = 0.01289, ari = 0.01538  ; loss= 0.01317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4760: acc = 0.56189, nmi = 0.01300, ari = 0.01523  ; loss= 0.00333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 4900: acc = 0.56189, nmi = 0.01307, ari = 0.01523  ; loss= 0.01221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5040: acc = 0.56089, nmi = 0.01281, ari = 0.01474  ; loss= 0.00492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5180: acc = 0.56019, nmi = 0.01256, ari = 0.01440  ; loss= 0.01176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5320: acc = 0.55949, nmi = 0.01234, ari = 0.01407  ; loss= 0.00616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5460: acc = 0.56009, nmi = 0.01258, ari = 0.01436  ; loss= 0.01119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5600: acc = 0.55919, nmi = 0.01232, ari = 0.01393  ; loss= 0.00625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5740: acc = 0.56049, nmi = 0.01287, ari = 0.01455  ; loss= 0.01031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 5880: acc = 0.55999, nmi = 0.01276, ari = 0.01431  ; loss= 0.00547\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 6020: acc = 0.55929, nmi = 0.01259, ari = 0.01398  ; loss= 0.01042\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 6160: acc = 0.55639, nmi = 0.01165, ari = 0.01264  ; loss= 0.00726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 6300: acc = 0.55669, nmi = 0.01176, ari = 0.01277  ; loss= 0.01081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 6440: acc = 0.55699, nmi = 0.01198, ari = 0.01291  ; loss= 0.00572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 6580: acc = 0.55659, nmi = 0.01178, ari = 0.01273  ; loss= 0.01168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 6720: acc = 0.55559, nmi = 0.01153, ari = 0.01228  ; loss= 0.0047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 6860: acc = 0.55559, nmi = 0.01150, ari = 0.01228  ; loss= 0.0115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7000: acc = 0.55479, nmi = 0.01132, ari = 0.01193  ; loss= 0.00457\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7140: acc = 0.55569, nmi = 0.01168, ari = 0.01232  ; loss= 0.01058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7280: acc = 0.55329, nmi = 0.01084, ari = 0.01128  ; loss= 0.00433\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7420: acc = 0.55479, nmi = 0.01141, ari = 0.01193  ; loss= 0.01105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7560: acc = 0.55299, nmi = 0.01079, ari = 0.01115  ; loss= 0.00386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7700: acc = 0.55489, nmi = 0.01146, ari = 0.01197  ; loss= 0.01113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7840: acc = 0.55299, nmi = 0.01082, ari = 0.01115  ; loss= 0.00369\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 7980: acc = 0.55339, nmi = 0.01101, ari = 0.01132  ; loss= 0.01062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gaussian Mixtures Models Done for std = 1.00. Time elapsed = 530.93s\n",
            "Gaussian Mixture Model Accuracy = 54.79%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KMeans completed. Time elapsed = 531.36s\n",
            "KMeans Accuracy = 55.92%\n",
            "Done time elapsed = 531.43s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64FNVVoSdxPV",
        "colab_type": "text"
      },
      "source": [
        "### Visualization and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgzeRXYYCqJl",
        "colab_type": "code",
        "outputId": "e8935acc-0a7b-455f-96a1-5fda5cc220af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "tol = 0.001\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.plot(accuracy_list, label='Accuracy_GMM')\n",
        "plt.plot(accuracy_means_list, label = 'Accuracy by KMeans')\n",
        "plt.xlabel('std index')\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(accuracy_dec_list, label='DEC Accuracy')\n",
        "plt.plot(accuracy_ae_means_list, label = 'AE + kmeans Accuracy')\n",
        "# plt.plot(accuracy_ae_list, label = 'AE Accuracy')\n",
        "plt.legend(frameon=False)\n",
        "plt.title('Accuracies vs std')\n",
        "plt.savefig(os.path.join(synthetic_path,f'Accuracies_vs_stds_tol_{tol}_update_interval_{update_interval}.png'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwMAAAIqCAYAAAB49pZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 385,
              "height": 277
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QJO-eVYQJhh",
        "colab_type": "code",
        "outputId": "cb27fdf5-ebca-4424-a31c-7e00d3fc7bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "j = 10\n",
        "X = np.load(os.path.join(synthetic_path, f'X_sparsity_1_sensitivity_{j}.npy'))\n",
        "y = np.load(os.path.join(synthetic_path, f'labels_sparsity_1_sensitivity_{j}.npy'))\n",
        "np.max(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "702.94885"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCPXgmTBKSyF",
        "colab_type": "code",
        "outputId": "45497e64-5453-4270-ad26-4b2ad8f5b54c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "time_start = time.time()\n",
        "js = [100, 10, 5, 5/3, 5/4,1]\n",
        "for j in js:\n",
        "  a = create_data(sparsity = 1, std= 1/j)\n",
        "  X = a[0].numpy()\n",
        "  y = a[1].numpy()\n",
        "  np.save(os.path.join(synthetic_path, f'X_sparsity_1_std_{1/j:.2f}.npy'),X)\n",
        "  np.save(os.path.join(synthetic_path, f'labels_sparsity_1_std_{1/j:.2f}.npy'), y)\n",
        "  \n",
        "  tsne = TSNE(n_components=2).fit_transform(X)\n",
        "  print(f'TSNE done. Time elapsed = {time.time()- time_start:.2f}s')\n",
        "\n",
        "  for i in tqdm(range(len(tsne))):\n",
        "    plt.scatter(tsne[i][0], tsne[i][1], c=colors[int(y[i].item())])\n",
        "  plt.title(f'TSNE Vis. W/O Norm. on Ground Truth std {1/j:.2f}')\n",
        "  plt.savefig(os.path.join(synthetic_path, f'tsne_visualization_wo_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "  plt.clf()\n",
        "  print(f'Visualized TSNE Grounds. Time elapsed = {time.time()- time_start:.2f}s')\n",
        "  del tsne\n",
        "\n",
        "  pca = PCA(n_components=2).fit_transform(X)\n",
        "  print(f'PCA done. Time elapsed = {time.time()- time_start:.2f}s')\n",
        "\n",
        "  for i in tqdm(range(len(pca))):\n",
        "    plt.scatter(pca[i][0], pca[i][1], c=colors[int(y[i].item())])\n",
        "  plt.title(f'PCA Vis. W/O Norm. on Ground Truth std {1/j:.2f}')\n",
        "  plt.savefig(os.path.join(synthetic_path, f'pca_visualization_wo_normalization_ground_truth_std_{1/j:.2f}.png'))  \n",
        "  plt.clf()\n",
        "  print(f'Visualized PCA Grounds. Time elapsed = {time.time()- time_start:.2f}s')  \n",
        "  del pca\n",
        "\n",
        "  Lda = LinearDiscriminantAnalysis(n_components=2)\n",
        "  lda = Lda.fit_transform(X, y.reshape(len(y),))\n",
        "  plt.hist(lda)\n",
        "  plt.title(f'LDA Vis. W/O Norm. on Ground Truth std {1/j:.2f}')\n",
        "  plt.savefig(os.path.join(synthetic_path, f'lda_visualization_wo_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "  plt.clf()\n",
        "  del lda, Lda\n",
        "  print(f'LDA done. Time elapsed = {time.time()- time_start:.2f}s')\n",
        "\n",
        "  if(j == 100):\n",
        "      to_conc = cv2.imread(os.path.join(synthetic_path, f'tsne_visualization_wo_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "      po_conc = cv2.imread(os.path.join(synthetic_path, f'pca_visualization_wo_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "      lo_conc = cv2.imread(os.path.join(synthetic_path, f'lda_visualization_wo_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "  else:\n",
        "    ton = cv2.imread(os.path.join(synthetic_path, f'tsne_visualization_wo_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "    po = cv2.imread(os.path.join(synthetic_path,f'pca_visualization_wo_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "    lo = cv2.imread(os.path.join(synthetic_path, f'lda_visualization_wo_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "    to_conc = cv2.hconcat([to_conc, ton])\n",
        "    po_conc = cv2.hconcat([po_conc, po])\n",
        "    lo_conc = cv2.hconcat([lo_conc, lo])\n",
        "    del ton,po,lo  \n",
        "\n",
        "  X = normalize(X, axis = 0)\n",
        "  print('Normalized.')\n",
        "\n",
        "  tsne = TSNE(n_components=2).fit_transform(X)\n",
        "  print(f'TSNE done. Time elapsed = {time.time()- time_start:.2f}s')\n",
        "\n",
        "  for i in tqdm(range(len(tsne))):\n",
        "    plt.scatter(tsne[i][0], tsne[i][1], c=colors[int(y[i].item())])\n",
        "  plt.title(f'TSNE Vis. W/ Norm. on Ground Truth std {1/j:.2f}')\n",
        "  plt.savefig(os.path.join(synthetic_path, f'tsne_visualization_w_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "  plt.clf()\n",
        "  print(f'Visualized TSNE Grounds. Time elapsed = {time.time()- time_start:.2f}s')\n",
        "  del tsne\n",
        "\n",
        "  pca = PCA(n_components=2).fit_transform(X)\n",
        "  print(f'PCA done. Time elapsed = {time.time()- time_start:.2f}s')\n",
        "\n",
        "  for i in tqdm(range(len(pca))):\n",
        "    plt.scatter(pca[i][0], pca[i][1], c=colors[int(y[i].item())])\n",
        "  plt.title(f'PCA Vis. W/ Norm. on Ground Truth std {1/j:.2f}')\n",
        "  plt.savefig(os.path.join(synthetic_path, f'pca_visualization_w_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "  plt.clf()\n",
        "  print(f'Visualized PCA Grounds. Time elapsed = {time.time()- time_start:.2f}s')\n",
        "  \n",
        "  del pca\n",
        "\n",
        "  Lda = LinearDiscriminantAnalysis(n_components=2)\n",
        "  lda = Lda.fit_transform(X, y.reshape(len(y),))\n",
        "  plt.hist(lda)\n",
        "  plt.title(f'LDA Vis. W/ Norm. on Ground Truth std {1/j:.2f}')\n",
        "  plt.legend(frameon=False)\n",
        "  plt.savefig(os.path.join(synthetic_path, f'lda_visualization_w_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "  plt.clf()\n",
        "  del lda, Lda\n",
        "  print(f'LDA done. Time elapsed = {time.time()- time_start:.2f}s')\n",
        "\n",
        "  if(j == 100):\n",
        "      t_conc = cv2.imread(os.path.join(synthetic_path, f'tsne_visualization_w_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "      p_conc = cv2.imread(os.path.join(synthetic_path, f'pca_visualization_w_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "      l_conc = cv2.imread(os.path.join(synthetic_path, f'lda_visualization_w_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "  else:\n",
        "    t = cv2.imread(os.path.join(synthetic_path, f'tsne_visualization_w_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "    p = cv2.imread(os.path.join(synthetic_path,f'pca_visualization_w_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "    l = cv2.imread(os.path.join(synthetic_path, f'lda_visualization_w_normalization_ground_truth_std_{1/j:.2f}.png'))\n",
        "    t_conc = cv2.hconcat([t_conc, t])\n",
        "    p_conc = cv2.hconcat([p_conc, p])\n",
        "    l_conc = cv2.hconcat([l_conc, l])\n",
        "    del t,p,l\n",
        "  del X, y\n",
        "  print(f'Done std {1/j:.2f}. Time Elapsed = {time.time()- time_start:.2f}s')\n",
        "\n",
        "cv2.imwrite(os.path.join(synthetic_path, 'tsne_visualization_wo_normalization_for_all_std.png'), to_conc)\n",
        "cv2.imwrite(os.path.join(synthetic_path, 'tsne_visualization_w_normalization_for_all_std.png'), t_conc)\n",
        "cv2.imwrite(os.path.join(synthetic_path, 'pca_visualization_wo_normalization_for_all_std.png'), po_conc)\n",
        "cv2.imwrite(os.path.join(synthetic_path, 'pca_visualization_w_normalization_for_all_std.png'), p_conc)\n",
        "cv2.imwrite(os.path.join(synthetic_path, 'lda_visualization_wo_normalization_for_all_std.png'), lo_conc)\n",
        "cv2.imwrite(os.path.join(synthetic_path, 'lda_visualization_w_normalization_for_all_std.png'), l_conc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Uniform data\n",
            "Creating Sparse Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 40/10002 [00:00<00:25, 393.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TSNE done. Time elapsed = 77.62s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:00<00:00, 164.72it/s]\n",
            "  0%|          | 38/10002 [00:00<00:26, 378.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized TSNE Grounds. Time elapsed = 142.27s\n",
            "PCA done. Time elapsed = 142.29s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:00<00:00, 165.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized PCA Grounds. Time elapsed = 206.62s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LDA done. Time elapsed = 206.85s\n",
            "Normalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 40/10002 [00:00<00:25, 392.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TSNE done. Time elapsed = 288.23s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [00:59<00:00, 166.80it/s]\n",
            "  0%|          | 37/10002 [00:00<00:27, 366.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized TSNE Grounds. Time elapsed = 352.03s\n",
            "PCA done. Time elapsed = 352.06s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:00<00:00, 165.83it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized PCA Grounds. Time elapsed = 416.21s\n",
            "LDA done. Time elapsed = 416.43s\n",
            "Done std 0.01. Time Elapsed = 416.44s\n",
            "Creating Uniform data\n",
            "Creating Sparse Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 38/10002 [00:00<00:26, 374.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TSNE done. Time elapsed = 493.65s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [00:59<00:00, 168.90it/s]\n",
            "  0%|          | 39/10002 [00:00<00:25, 387.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized TSNE Grounds. Time elapsed = 556.70s\n",
            "PCA done. Time elapsed = 556.72s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [00:59<00:00, 167.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized PCA Grounds. Time elapsed = 620.35s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LDA done. Time elapsed = 620.57s\n",
            "Normalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 39/10002 [00:00<00:26, 383.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TSNE done. Time elapsed = 697.95s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:01<00:00, 163.74it/s]\n",
            "  0%|          | 34/10002 [00:00<00:29, 337.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized TSNE Grounds. Time elapsed = 762.95s\n",
            "PCA done. Time elapsed = 762.97s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:01<00:00, 162.33it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized PCA Grounds. Time elapsed = 828.47s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LDA done. Time elapsed = 829.18s\n",
            "Done std 0.10. Time Elapsed = 829.20s\n",
            "Creating Uniform data\n",
            "Creating Sparse Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 38/10002 [00:00<00:26, 373.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TSNE done. Time elapsed = 921.99s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:01<00:00, 163.15it/s]\n",
            "  0%|          | 36/10002 [00:00<00:27, 357.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized TSNE Grounds. Time elapsed = 987.19s\n",
            "PCA done. Time elapsed = 987.21s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:02<00:00, 159.76it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized PCA Grounds. Time elapsed = 1053.79s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LDA done. Time elapsed = 1054.02s\n",
            "Normalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 36/10002 [00:00<00:27, 357.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TSNE done. Time elapsed = 1133.59s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:02<00:00, 160.66it/s]\n",
            "  0%|          | 34/10002 [00:00<00:29, 333.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized TSNE Grounds. Time elapsed = 1199.78s\n",
            "PCA done. Time elapsed = 1199.80s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:03<00:00, 158.49it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized PCA Grounds. Time elapsed = 1266.93s\n",
            "LDA done. Time elapsed = 1267.17s\n",
            "Done std 0.20. Time Elapsed = 1267.18s\n",
            "Creating Uniform data\n",
            "Creating Sparse Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 36/10002 [00:00<00:27, 359.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TSNE done. Time elapsed = 1381.09s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:02<00:00, 160.19it/s]\n",
            "  0%|          | 37/10002 [00:00<00:27, 364.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized TSNE Grounds. Time elapsed = 1447.54s\n",
            "PCA done. Time elapsed = 1447.56s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:01<00:00, 161.41it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized PCA Grounds. Time elapsed = 1513.50s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LDA done. Time elapsed = 1513.73s\n",
            "Normalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 34/10002 [00:00<00:29, 338.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TSNE done. Time elapsed = 1628.35s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:02<00:00, 159.37it/s]\n",
            "  0%|          | 34/10002 [00:00<00:29, 335.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized TSNE Grounds. Time elapsed = 1695.11s\n",
            "PCA done. Time elapsed = 1695.14s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:03<00:00, 102.10it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized PCA Grounds. Time elapsed = 1762.43s\n",
            "LDA done. Time elapsed = 1762.66s\n",
            "Done std 0.60. Time Elapsed = 1762.67s\n",
            "Creating Uniform data\n",
            "Creating Sparse Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 29/10002 [00:00<00:34, 285.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TSNE done. Time elapsed = 1860.01s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:01<00:00, 162.45it/s]\n",
            "  0%|          | 36/10002 [00:00<00:27, 359.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized TSNE Grounds. Time elapsed = 1925.56s\n",
            "PCA done. Time elapsed = 1925.59s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:02<00:00, 158.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized PCA Grounds. Time elapsed = 1992.50s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LDA done. Time elapsed = 1992.72s\n",
            "Normalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 31/10002 [00:00<00:32, 307.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TSNE done. Time elapsed = 2079.83s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:03<00:00, 158.61it/s]\n",
            "  0%|          | 35/10002 [00:00<00:28, 344.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized TSNE Grounds. Time elapsed = 2146.89s\n",
            "PCA done. Time elapsed = 2146.91s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:02<00:00, 160.48it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized PCA Grounds. Time elapsed = 2213.20s\n",
            "LDA done. Time elapsed = 2213.42s\n",
            "Done std 0.80. Time Elapsed = 2213.43s\n",
            "Creating Uniform data\n",
            "Creating Sparse Data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 40/10002 [00:00<00:25, 386.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TSNE done. Time elapsed = 2318.38s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:01<00:00, 163.44it/s]\n",
            "  0%|          | 36/10002 [00:00<00:28, 351.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized TSNE Grounds. Time elapsed = 2383.50s\n",
            "PCA done. Time elapsed = 2383.52s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:00<00:00, 164.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized PCA Grounds. Time elapsed = 2448.33s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LDA done. Time elapsed = 2448.56s\n",
            "Normalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 35/10002 [00:00<00:28, 346.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TSNE done. Time elapsed = 2560.49s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:01<00:00, 162.61it/s]\n",
            "  0%|          | 37/10002 [00:00<00:27, 363.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized TSNE Grounds. Time elapsed = 2625.95s\n",
            "PCA done. Time elapsed = 2625.98s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:02<00:00, 160.74it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n",
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Visualized PCA Grounds. Time elapsed = 2692.13s\n",
            "LDA done. Time elapsed = 2692.36s\n",
            "Done std 1.00. Time Elapsed = 2692.37s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08n6BLj_F1cp",
        "colab_type": "code",
        "outputId": "93381c74-a9a1-4dc3-f64c-caa838077286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "j = 10\n",
        "X = np.load(os.path.join(synthetic_path, f'X_sparsity_1_variance_{1/j:.2f}.npy'))\n",
        "y = np.load(os.path.join(synthetic_path, f'labels_sparsity_1_variance_{1/j:.2f}.npy'))\n",
        "Lda = LinearDiscriminantAnalysis(n_components=2)\n",
        "lda = Lda.fit_transform(X, y.reshape(len(y),), )\n",
        "print(np.median(lda))\n",
        "plt.hist(lda, bins = 2, range=(np.median(lda), ),  )\n",
        "plt.savefig(os.path.join(synthetic_path, f'lda_visualization_wo_normalization_variance_{1/j:.2f}.png'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(39, 2 - 1) = 1 components.\n",
            "  ChangedBehaviorWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
            "  warnings.warn(future_msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
            "  warnings.warn(\"Variables are collinear.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.4903896092592291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCRhGEiSMAwkSRgGkiQMA0kS8L8KZAbKszm1zgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9Kf1bm2D_L-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j = 100\n",
        "t= cv2.imread(os.path.join(synthetic_path, f'tsne_visualization_wo_normalization_ground_truth_variance_{1/j:.2f}.png'))\n",
        "p= cv2.imread(os.path.join(synthetic_path,f'pca_visualization_wo_normalization_ground_truth_variance_{1/j:.2f}.png'))\n",
        "h = cv2.hconcat([t,p])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I3NfKDhEhQf",
        "colab_type": "code",
        "outputId": "14d4eb7b-1e14-42ed-94ab-d868d89d7826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cv2.imwrite(os.path.join(synthetic_path, f'visualization_wo_normalization_ground_truth_variance_{1/j:.2f}.png'), h)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_iEVYQB9Utq",
        "colab_type": "code",
        "outputId": "cadd1fdd-0f29-4481-e204-1b89b7a10ac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "time_enc = time.time() \n",
        "db = 9\n",
        "# accuracy_ae = []\n",
        "accuracy_ae_means_list = []\n",
        "dbs = [100, 50, 30,20, 10] + [i for i in range(9, -1, -1)]\n",
        "for db in dbs:\n",
        "  encoding = np.load(os.path.join(synthetic_path, f'encoding_sparsity_1_db_{db}.npy'))\n",
        "  y = np.load(os.path.join(synthetic_path, f'labels_sparsity_1_db_{db}.npy'))\n",
        "\n",
        "  kmeans = KMeans(n_clusters=2, n_init = 15).fit(encoding)\n",
        "  y_pred_ae_means = kmeans.labels_\n",
        "  accs_ae_means = metrics.acc(y.reshape(10002,), y_pred_ae_means.reshape(10002,))\n",
        "  print(\"Accuracy\",db, accs_ae_means)\n",
        "  accuracy_ae_means_list.append(accs_ae_means)\n",
        "  \n",
        "  # y_pred_ae = np.argmax(encoding, axis = 1)\n",
        "  # accs_ae = metrics.acc(y.reshape(10002,), y_pred_ae)\n",
        "  # print(\"accuracy\",db,accs_ae)\n",
        "  # accuracy_ae.append(accs_ae)\n",
        "\n",
        "  # for i in range(len(encoding)):\n",
        "  #   plt.scatter(encoding[i][0], encoding[i][1], c = colors[int(y[i].item())])\n",
        "  #   if(i% 250 ==0):\n",
        "  #     print(\".\", end = \"\")\n",
        "  #     plt.savefig(os.path.join(synthetic_path, f'Encoding_db_{db}.png'))\n",
        "  # print(f\"\\n done time elapsed = {time.time()-time_enc:.2f}s\")\n",
        "  # plt.title(f'Encoding Visualization db {db}')\n",
        "  # plt.savefig(os.path.join(synthetic_path, f'Encoding_db_{db}.png'))\n",
        "  # plt.clf()\n",
        "  del encoding, y, kmeans, y_pred_ae_means, accs_ae_means#, y_pred_ae, accs_ae"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy 100 1.0\n",
            "Accuracy 50 1.0\n",
            "Accuracy 30 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy 20 1.0\n",
            "Accuracy 10 0.5002999400119976\n",
            "Accuracy 9 0.5000999800039992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy 8 0.5008998200359928\n",
            "Accuracy 7 0.5003999200159968\n",
            "Accuracy 6 0.5005998800239952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy 5 0.5001999600079984\n",
            "Accuracy 4 0.5005998800239952\n",
            "Accuracy 3 0.5000999800039992\n",
            "Accuracy 2 0.5000999800039992\n",
            "Accuracy 1 0.5005998800239952\n",
            "Accuracy 0 0.5000999800039992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0k_pUn-HbsA",
        "colab_type": "code",
        "outputId": "689dd53f-bf43-4612-91f9-4461a51f1937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.xlabel('db')\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(accuracy_ae_means_list, label='Autoencoder Accuracy')\n",
        "plt.legend(frameon=False)\n",
        "plt.title('Accuracies vs db')\n",
        "plt.savefig(os.path.join(synthetic_path,f'Accuracies_vs_dbs_autoencoder.png'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwMAAAIqCAYAAAB49pZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 385,
              "height": 277
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTc3Bes3E_0b",
        "colab_type": "code",
        "outputId": "00413a05-9e1d-4e08-a83c-9fbec6b01159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "time_start = time.time()\n",
        "# tsne_model = TSNE(random_state = 42)\n",
        "# print(f'TSNE started. Time collapsed = {(time.time()-time_start):.2f}s')\n",
        "# tsne = tsne_model.fit_transform(X)\n",
        "# print(f'TSNE completed. Time collapsed = {(time.time()-time_start):.2f}s')\n",
        "# j = 2\n",
        "for j in range(0, 18):\n",
        "  tsne = np.load(os.path.join(synthetic_path, f'tsne_sparsity{j+1}.npy') )\n",
        "  y_pred_train = np.load(os.path.join(synthetic_path, f'gmm_preds_sparsity{j}.npy'))\n",
        "  for i in range(len(tsne)):\n",
        "    plt.scatter(tsne[i][0], tsne[i][1], c=colors[y_pred_train[i]])\n",
        "  del tsne\n",
        "  del y_pred_train \n",
        "  print(f'done. Time collapsed ={time.time()-time_start}')\n",
        "  plt.title(f'Visualization against the predicted clustering by GMM for Sparsity = {j+1}')\n",
        "  plt.savefig(os.path.join(gmm_path,f'predictedGMM_for_Sparsity_{j+1}.png'))\n",
        "  plt.clf()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done. Time collapsed =60.104713678359985\n",
            "done. Time collapsed =122.83830094337463\n",
            "done. Time collapsed =186.1231939792633\n",
            "done. Time collapsed =252.53311562538147\n",
            "done. Time collapsed =316.08072805404663\n",
            "done. Time collapsed =380.33908104896545\n",
            "done. Time collapsed =443.3959836959839\n",
            "done. Time collapsed =506.5995943546295\n",
            "done. Time collapsed =570.6039922237396\n",
            "done. Time collapsed =634.7487516403198\n",
            "done. Time collapsed =698.045307636261\n",
            "done. Time collapsed =760.759204864502\n",
            "done. Time collapsed =824.3234689235687\n",
            "done. Time collapsed =887.3940515518188\n",
            "done. Time collapsed =950.2635970115662\n",
            "done. Time collapsed =1016.7553551197052\n",
            "done. Time collapsed =1079.9479503631592\n",
            "done. Time collapsed =1142.2407364845276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFnlXafU8CXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.randn((5000,39))\n",
        "X = torch.ones((1, 39))/39\n",
        "m = X + 0.01*a \n",
        "m = torch.abs(m)\n",
        "m = (m/torch.sum(m, dim = 1).view(-1,1))\n",
        "m, c = torch.sort(m, dim = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSjHlYPF6iyb",
        "colab_type": "code",
        "outputId": "9cad8b96-2372-40b2-bce1-66de4f3121fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "m[500:505]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0012, 0.0100, 0.0125, 0.0132, 0.0133, 0.0156, 0.0164, 0.0171, 0.0174,\n",
              "         0.0178, 0.0200, 0.0205, 0.0207, 0.0210, 0.0211, 0.0229, 0.0234, 0.0236,\n",
              "         0.0240, 0.0241, 0.0259, 0.0265, 0.0265, 0.0274, 0.0288, 0.0290, 0.0308,\n",
              "         0.0322, 0.0330, 0.0338, 0.0346, 0.0363, 0.0363, 0.0364, 0.0383, 0.0403,\n",
              "         0.0410, 0.0419, 0.0452],\n",
              "        [0.0026, 0.0090, 0.0101, 0.0118, 0.0139, 0.0156, 0.0159, 0.0159, 0.0163,\n",
              "         0.0176, 0.0190, 0.0196, 0.0214, 0.0217, 0.0219, 0.0228, 0.0246, 0.0254,\n",
              "         0.0260, 0.0268, 0.0274, 0.0276, 0.0279, 0.0291, 0.0294, 0.0296, 0.0311,\n",
              "         0.0316, 0.0316, 0.0318, 0.0322, 0.0330, 0.0339, 0.0341, 0.0358, 0.0371,\n",
              "         0.0450, 0.0454, 0.0486],\n",
              "        [0.0063, 0.0077, 0.0081, 0.0098, 0.0117, 0.0120, 0.0132, 0.0136, 0.0137,\n",
              "         0.0143, 0.0161, 0.0184, 0.0189, 0.0190, 0.0224, 0.0241, 0.0250, 0.0259,\n",
              "         0.0262, 0.0263, 0.0284, 0.0294, 0.0304, 0.0306, 0.0306, 0.0311, 0.0311,\n",
              "         0.0323, 0.0329, 0.0329, 0.0337, 0.0345, 0.0354, 0.0355, 0.0365, 0.0428,\n",
              "         0.0444, 0.0460, 0.0489],\n",
              "        [0.0025, 0.0093, 0.0096, 0.0118, 0.0123, 0.0134, 0.0138, 0.0144, 0.0155,\n",
              "         0.0166, 0.0174, 0.0177, 0.0186, 0.0189, 0.0192, 0.0208, 0.0233, 0.0237,\n",
              "         0.0238, 0.0258, 0.0259, 0.0261, 0.0261, 0.0288, 0.0297, 0.0307, 0.0316,\n",
              "         0.0317, 0.0324, 0.0334, 0.0359, 0.0366, 0.0369, 0.0393, 0.0414, 0.0428,\n",
              "         0.0432, 0.0469, 0.0523],\n",
              "        [0.0024, 0.0081, 0.0089, 0.0117, 0.0118, 0.0118, 0.0122, 0.0143, 0.0148,\n",
              "         0.0151, 0.0199, 0.0215, 0.0224, 0.0225, 0.0237, 0.0239, 0.0245, 0.0254,\n",
              "         0.0255, 0.0259, 0.0269, 0.0273, 0.0284, 0.0289, 0.0292, 0.0305, 0.0306,\n",
              "         0.0308, 0.0333, 0.0335, 0.0338, 0.0349, 0.0361, 0.0368, 0.0394, 0.0397,\n",
              "         0.0412, 0.0454, 0.0470]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fve7i_fZFibM",
        "colab_type": "code",
        "outputId": "3e06e413-7b51-4773-ddec-7f288cd94235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "time_start = time.time()\n",
        "js = [100, 20, 10] + [5/i for i in range(1, 6, 1)]\n",
        "for j in js:\n",
        "  # autoencoder, encoder = Autoencoder(dims, init = init)\n",
        "  # autoencoder.load_weights(os.path.join(synthetic_path, f\"ae_sparsity_1_db_9_lr_0.001_batch_size_64_epochs_10.h5\"))\n",
        "  encoding = np.load(os.path.join(synthetic_path, f'encoding_sparsity_1_variance_{1/j:.2f}.npy'))\n",
        "  labels = np.load(os.path.join(synthetic_path, f'labels_sparsity_1_variance_{1/j:.2f}.npy'))\n",
        "  for i in tqdm(range(len(encoding))):\n",
        "    plt.scatter(encoding[i][0], encoding[i][1], c=colors[int(labels[i].item())])  \n",
        "  del encoding, labels#, encoder, autoencoder\n",
        "  print(f'done. Time collapsed ={time.time()-time_start}')\n",
        "  plt.title(f'Visualization against the ground truth for Sparsity = 1, sensitivity = {j}')\n",
        "  plt.savefig(os.path.join(synthetic_path,f'encoding_ground_truth_Sparsity_1_sensitivity_{j}.png'))\n",
        "  plt.clf()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:01<00:00, 162.73it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done. Time collapsed =65.89033222198486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:01<00:00, 162.03it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done. Time collapsed =132.5977098941803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:02<00:00, 160.73it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done. Time collapsed =200.17616820335388\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:03<00:00, 158.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done. Time collapsed =269.0175778865814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:02<00:00, 159.98it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done. Time collapsed =336.44376611709595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:02<00:00, 160.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done. Time collapsed =403.7915756702423\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:02<00:00, 158.99it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done. Time collapsed =471.65338373184204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:03<00:00, 157.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done. Time collapsed =540.1085662841797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8MR2iW6CLJJ",
        "colab_type": "code",
        "outputId": "ece03d8a-0fae-4c69-e519-0996fd9c3899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "btime_start = time.time()\n",
        "for j in range(0, 18):\n",
        "  tsne = np.load(os.path.join(synthetic_path, f'tsne_sparsity{j+1}.npy') )\n",
        "  y_pred_train = np.load(os.path.join(synthetic_path, f'kmeans_preds_sparsity{j}.npy') )\n",
        "  for i in range(len(tsne)):\n",
        "    plt.scatter(tsne[i][0], tsne[i][1], c=colors[int(y_pred_train[i].item())]) \n",
        "    if(i%250==0):\n",
        "      print('.', end = '')\n",
        "  del tsne\n",
        "  del y_pred_train\n",
        "  print(f'done. Time collapsed ={time.time()-time_start}')\n",
        "  plt.title(f'Visualization against the KMeans Prediction for Sparsity = {j+1}')\n",
        "  plt.savefig(os.path.join(kmeans_path,f'predictedKMeans_for_Sparsity_{j+1}.png'))\n",
        "  plt.clf()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "......"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ecf300e1ca8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0my_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynthetic_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'kmeans_preds_sparsity{j}.npy'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsne\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2839\u001b[0m         \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2840\u001b[0m         plotnonfinite=plotnonfinite, **({\"data\": data} if data is not\n\u001b[0;32m-> 2841\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2842\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2843\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4524\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ymargin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4526\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4527\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_collection\u001b[0;34m(self, collection, autolim)\u001b[0m\n\u001b[1;32m   1871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mautolim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1873\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_datalim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_datalim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/collections.py\u001b[0m in \u001b[0;36mget_datalim\u001b[0;34m(self, transData)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrozen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 offsets, transOffset.frozen())\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transformed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36minverse_transformed\u001b[0;34m(self, transform)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mof\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \"\"\"\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     coefs = {'C':  (0.5, 0.5),\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36minverted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2404\u001b[0m         \u001b[0;31m# docstring inherited\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2405\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCompositeGenericTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36minverted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2404\u001b[0m         \u001b[0;31m# docstring inherited\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2405\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCompositeGenericTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36minverted\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1807\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shorthand_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m                 \u001b[0mshorthand_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(%s)-1'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shorthand_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1809\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAffine2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshorthand_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshorthand_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1810\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD5CAYAAADCxEVRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nINDBBJEPBAKBDuZ/AOODZCBtopTLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7xueshFJ3Wy",
        "colab_type": "code",
        "outputId": "b974f4fc-1d20-4f1a-ca5b-e8b3f4e5dae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred_train = torch.from_numpy(y_pred_train).type(torch.ByteTensor)#.cuda()\n",
        "accuracy = torch.mean((torch.from_numpy(y_pred_train).view(10002) == labels.view(10002)).type(torch.FloatTensor)).item()\n",
        "print(f'Gaussian Mixture Model Accuracy = {(accuracy)*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gaussian Mixture Model Accuracy = 5.10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G48ZepmUNDR-",
        "colab_type": "code",
        "outputId": "1509e21e-de82-4073-ceea-2e151c8cbce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "uni = sparse()\n",
        "(uni[90:96])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([39, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.4063e-01, -2.8145e-01,  4.4411e-01,  5.8321e-02, -2.1524e-01,\n",
              "          8.6211e-02, -1.0329e-01,  1.2181e-01,  7.2102e-01, -2.8954e-01,\n",
              "          1.5922e-02,  1.0000e+00,  2.3463e-02, -4.5925e-02, -5.2821e-02,\n",
              "          3.5522e-01, -1.6904e-04, -4.1855e-01,  1.2959e-01,  3.0241e-01,\n",
              "         -1.7134e-01, -2.2824e-01, -2.7596e-01, -1.2453e-01, -9.1200e-02,\n",
              "          1.3983e-01, -2.4867e-01,  4.8624e-02, -1.4572e-01, -9.8532e-02,\n",
              "          4.0182e-01,  1.1139e-01, -7.1844e-02, -2.2730e-01, -9.3280e-02,\n",
              "         -6.3991e-01, -9.7520e-02, -3.8303e-01,  4.2248e-01],\n",
              "        [-6.9391e-01,  3.8642e-01, -3.8027e-01, -4.3062e-01,  3.5098e-01,\n",
              "         -5.5339e-01,  3.5102e-01, -2.6369e-01, -8.6607e-02, -1.0981e-01,\n",
              "          2.5792e-01,  1.0000e+00, -1.0263e-01, -1.6609e-01,  2.7656e-01,\n",
              "          1.4986e-01, -4.4353e-01, -2.9889e-01,  2.4021e-02, -6.1056e-01,\n",
              "          5.3332e-03,  2.5645e-01,  2.4435e-01, -5.7948e-03, -5.7108e-01,\n",
              "         -2.6533e-01,  2.5154e-01,  3.0417e-03, -1.2283e-01,  2.3258e-02,\n",
              "          1.8363e-02, -2.2958e-02, -1.6068e-01,  5.0948e-01, -1.0369e-01,\n",
              "         -2.2251e-01,  2.7960e-02,  4.6708e-01,  1.1979e-01],\n",
              "        [-4.1335e-02,  2.5592e-01, -2.1066e-01,  2.5309e-01,  1.8603e-01,\n",
              "         -1.4379e-01,  1.1374e-01,  3.1817e-02, -4.7773e-02,  2.3711e-01,\n",
              "          2.0067e-01,  1.0000e+00,  8.7468e-02,  1.3938e-01,  1.5412e-01,\n",
              "         -1.3170e-01, -7.0996e-02,  1.7644e-01,  3.3462e-02, -5.8314e-02,\n",
              "          7.1867e-02, -7.6584e-02,  2.5883e-01,  7.2042e-02,  6.7485e-02,\n",
              "          5.2804e-02,  2.0426e-01, -9.0903e-02, -2.7663e-01, -5.2912e-02,\n",
              "          7.6843e-02,  1.0887e-01,  3.4036e-01,  2.7687e-01,  1.0976e-01,\n",
              "          7.7865e-02, -4.2379e-02,  8.9470e-02, -1.8344e-01],\n",
              "        [-1.2769e-01,  1.4912e-01,  1.8827e-02, -4.7390e-02, -6.8659e-02,\n",
              "          1.4041e-01,  4.6419e-02, -1.4333e-01,  1.0849e-01, -3.5558e-01,\n",
              "         -1.1472e-01,  1.0000e+00,  6.8276e-02,  1.6543e-01,  2.1910e-01,\n",
              "         -1.0370e-01,  1.2789e-01,  6.7667e-02, -2.1509e-01, -1.0938e-01,\n",
              "         -3.2674e-02, -1.6351e-01, -1.2707e-01,  3.3946e-01, -3.8683e-02,\n",
              "          3.1942e-01, -2.8289e-02, -1.9579e-01,  6.7682e-02,  1.2316e-01,\n",
              "          1.3326e-02,  8.3305e-02,  1.9525e-01, -1.8204e-01,  1.4707e-01,\n",
              "         -3.6154e-02, -5.7044e-02, -4.4668e-02,  4.6880e-02],\n",
              "        [-2.5569e-01,  3.7372e-01,  3.5606e-01,  2.6358e-01, -1.0437e+00,\n",
              "          4.4064e-01, -2.2998e-01, -1.6653e-01,  5.7784e-01, -5.2149e-01,\n",
              "          5.0963e-01,  1.0000e+00,  9.6858e-02, -2.2331e-02,  3.4814e-01,\n",
              "         -7.4502e-02, -4.2771e-01, -7.3334e-01,  6.9213e-01,  5.2361e-01,\n",
              "         -4.8408e-01, -1.6652e-01,  5.0288e-01, -9.1135e-01,  6.7247e-01,\n",
              "          9.0404e-02, -4.1189e-01,  5.2642e-01,  1.2132e-01,  3.1258e-01,\n",
              "         -1.8477e-01, -4.9922e-01, -5.8059e-01, -2.6615e-01,  5.8487e-01,\n",
              "          2.2349e-01, -5.6527e-01, -1.4531e-01, -1.2698e-01],\n",
              "        [ 1.5131e-02,  4.5492e-02,  1.1960e-01, -3.4617e-01,  1.3988e-02,\n",
              "          1.9737e-01,  2.9697e-01,  1.5590e-02,  7.6061e-02,  1.0818e-01,\n",
              "          3.7169e-03,  1.0000e+00,  7.5971e-02, -2.0960e-01, -3.3185e-01,\n",
              "          4.9969e-02,  5.0603e-01, -1.9857e-01,  5.3166e-02,  6.3754e-02,\n",
              "         -1.1338e-01,  4.2258e-03,  1.2937e-01,  3.8102e-01,  4.7968e-02,\n",
              "          2.1371e-01,  1.1431e-01, -1.3571e-01,  9.8926e-02, -1.4315e-01,\n",
              "          1.5969e-01,  7.1162e-02,  5.2133e-02,  1.9314e-02,  1.3173e-01,\n",
              "          6.0171e-02,  2.8977e-01,  6.1672e-02,  1.2943e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL9_uZwPcMz6",
        "colab_type": "text"
      },
      "source": [
        "## KMeans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG0BfiflcPPY",
        "colab_type": "code",
        "outputId": "87aba22a-fba0-4aee-aaf7-f322b78b902c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "kmodel = KMeans(n_clusters = 2, random_state = 42)\n",
        "y_pred_train = None\n",
        "time_means_start = time.time()\n",
        "X = X.cpu()\n",
        "kmeans = kmodel.fit(X)\n",
        "print(f'KMeans completed. Time elapsed = {time.time()-time_means_start:.2f}s')\n",
        "y_pred_train = kmeans.labels_\n",
        "train_accuracy = torch.mean((torch.from_numpy(y_pred_train).view(10002) == labels.view(10002)).type(torch.FloatTensor)).item()\n",
        "print(f'KMeans Accuracy = {train_accuracy*100:.2f}%')\n",
        "print(f'Done time elapsed = {time.time()-time_means_start:.2f}s')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KMeans completed. Time elapsed = 0.18s\n",
            "KMeans Accuracy = 5.10%\n",
            "Done time elapsed = 0.18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PzIaassdl1w",
        "colab_type": "code",
        "outputId": "e4a4ef1b-9cc1-45d5-ecf3-e8f524cce965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "for i in range(len(tsne)):\n",
        "  plt.scatter(tsne[i][0], tsne[i][1], c=colors[kmeans.labels_[i]])\n",
        "  if(i%100==0):\n",
        "    print('.', end = '')  \n",
        "plt.title('Visualization against the prediction by KMeans')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "....................................................................................................."
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvIAAAIPCAYAAAARlzqLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 377,
              "height": 263
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fgT0kD1gZm8",
        "colab_type": "text"
      },
      "source": [
        "## Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSoOnKzXeDOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class encoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Sequential(nn.Linear(39, 2), \n",
        "                             nn.LogSoftmax(dim = 1))\n",
        "  def forward(self, X):\n",
        "    X = self.fc1(X)\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFOTtLSig-5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class decoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc2 = nn.Sequential(nn.Linear(2,39),\n",
        "                             nn.Softmax(dim = 1))\n",
        "  def forward(self, X):\n",
        "    X = self.fc2(X)\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9_HhQVBhNnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self, enc, dec):\n",
        "    super().__init__()\n",
        "    self.enc = enc\n",
        "    self.dec = dec\n",
        "  def forward(self, X):\n",
        "    X = self.enc(X)\n",
        "    X = self.dec(X)\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNDAC5wBh2ck",
        "colab_type": "code",
        "outputId": "a7e29015-9b57-4dc6-c11d-41643289115e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "enc = encoder()\n",
        "dec = decoder()\n",
        "autoencoder = Autoencoder(enc, dec)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "autoencoder.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Autoencoder(\n",
              "  (enc): encoder(\n",
              "    (fc1): Sequential(\n",
              "      (0): Linear(in_features=39, out_features=2, bias=True)\n",
              "      (1): LogSoftmax()\n",
              "    )\n",
              "  )\n",
              "  (dec): decoder(\n",
              "    (fc2): Sequential(\n",
              "      (0): Linear(in_features=2, out_features=39, bias=True)\n",
              "      (1): Softmax(dim=1)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edaPOBeOi5qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 600\n",
        "optimizer = torch.optim.Adam(autoencoder.parameters(), lr = 0.001)\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpJb5rkajqDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvDY290ajRSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "  \n",
        "  autoencoder.train()\n",
        "  train_loss = 0\n",
        "  \n",
        "  \n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  X_p = autoencoder(X)\n",
        "\n",
        "  loss = criterion(X_p, X)\n",
        "  \n",
        "  loss.backward()\n",
        "  train_loss += loss.item()\n",
        "  \n",
        "  optimizer.step()\n",
        "  return train_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxzfR-eBjuAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "  autoencoder.eval()\n",
        "  test_loss = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    X_p = autoencoder(X)\n",
        "\n",
        "    loss = criterion(X_p, X)\n",
        "\n",
        "    test_loss += loss.item()\n",
        "  return test_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GgqV6VkkIr_",
        "colab_type": "code",
        "outputId": "1b291181-def1-4631-d4a4-2d436ccaf70d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_loss_list = []\n",
        "# test_loss_list = []\n",
        "time_start = time.time()\n",
        "for e in range(epochs):\n",
        "  \n",
        "  train_loss = train()\n",
        "  train_loss /= len(X)\n",
        "  print(f'Training done. Time Collapsed = {time.time() - time_start: .2f}s')\n",
        "  # print(f'Testing..')\n",
        "  # test_loss = test()\n",
        "  # test_loss /= len(val_data)\n",
        "  # print(f'Testing done. Time Collapsed = {time.time() - time_start: .2f}s')\n",
        "  train_loss_list.append(train_loss)\n",
        "  # test_loss_list.append(test_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training done. Time Collapsed =  0.00s\n",
            "Training done. Time Collapsed =  0.01s\n",
            "Training done. Time Collapsed =  0.01s\n",
            "Training done. Time Collapsed =  0.01s\n",
            "Training done. Time Collapsed =  0.02s\n",
            "Training done. Time Collapsed =  0.02s\n",
            "Training done. Time Collapsed =  0.02s\n",
            "Training done. Time Collapsed =  0.02s\n",
            "Training done. Time Collapsed =  0.03s\n",
            "Training done. Time Collapsed =  0.03s\n",
            "Training done. Time Collapsed =  0.03s\n",
            "Training done. Time Collapsed =  0.03s\n",
            "Training done. Time Collapsed =  0.03s\n",
            "Training done. Time Collapsed =  0.04s\n",
            "Training done. Time Collapsed =  0.04s\n",
            "Training done. Time Collapsed =  0.04s\n",
            "Training done. Time Collapsed =  0.04s\n",
            "Training done. Time Collapsed =  0.04s\n",
            "Training done. Time Collapsed =  0.04s\n",
            "Training done. Time Collapsed =  0.05s\n",
            "Training done. Time Collapsed =  0.05s\n",
            "Training done. Time Collapsed =  0.05s\n",
            "Training done. Time Collapsed =  0.05s\n",
            "Training done. Time Collapsed =  0.05s\n",
            "Training done. Time Collapsed =  0.05s\n",
            "Training done. Time Collapsed =  0.06s\n",
            "Training done. Time Collapsed =  0.06s\n",
            "Training done. Time Collapsed =  0.06s\n",
            "Training done. Time Collapsed =  0.06s\n",
            "Training done. Time Collapsed =  0.06s\n",
            "Training done. Time Collapsed =  0.07s\n",
            "Training done. Time Collapsed =  0.07s\n",
            "Training done. Time Collapsed =  0.07s\n",
            "Training done. Time Collapsed =  0.07s\n",
            "Training done. Time Collapsed =  0.07s\n",
            "Training done. Time Collapsed =  0.08s\n",
            "Training done. Time Collapsed =  0.08s\n",
            "Training done. Time Collapsed =  0.08s\n",
            "Training done. Time Collapsed =  0.08s\n",
            "Training done. Time Collapsed =  0.08s\n",
            "Training done. Time Collapsed =  0.09s\n",
            "Training done. Time Collapsed =  0.09s\n",
            "Training done. Time Collapsed =  0.09s\n",
            "Training done. Time Collapsed =  0.09s\n",
            "Training done. Time Collapsed =  0.10s\n",
            "Training done. Time Collapsed =  0.10s\n",
            "Training done. Time Collapsed =  0.10s\n",
            "Training done. Time Collapsed =  0.10s\n",
            "Training done. Time Collapsed =  0.10s\n",
            "Training done. Time Collapsed =  0.11s\n",
            "Training done. Time Collapsed =  0.11s\n",
            "Training done. Time Collapsed =  0.11s\n",
            "Training done. Time Collapsed =  0.11s\n",
            "Training done. Time Collapsed =  0.11s\n",
            "Training done. Time Collapsed =  0.12s\n",
            "Training done. Time Collapsed =  0.12s\n",
            "Training done. Time Collapsed =  0.12s\n",
            "Training done. Time Collapsed =  0.12s\n",
            "Training done. Time Collapsed =  0.12s\n",
            "Training done. Time Collapsed =  0.13s\n",
            "Training done. Time Collapsed =  0.13s\n",
            "Training done. Time Collapsed =  0.13s\n",
            "Training done. Time Collapsed =  0.13s\n",
            "Training done. Time Collapsed =  0.13s\n",
            "Training done. Time Collapsed =  0.14s\n",
            "Training done. Time Collapsed =  0.14s\n",
            "Training done. Time Collapsed =  0.14s\n",
            "Training done. Time Collapsed =  0.14s\n",
            "Training done. Time Collapsed =  0.14s\n",
            "Training done. Time Collapsed =  0.15s\n",
            "Training done. Time Collapsed =  0.15s\n",
            "Training done. Time Collapsed =  0.15s\n",
            "Training done. Time Collapsed =  0.15s\n",
            "Training done. Time Collapsed =  0.15s\n",
            "Training done. Time Collapsed =  0.15s\n",
            "Training done. Time Collapsed =  0.16s\n",
            "Training done. Time Collapsed =  0.16s\n",
            "Training done. Time Collapsed =  0.16s\n",
            "Training done. Time Collapsed =  0.16s\n",
            "Training done. Time Collapsed =  0.16s\n",
            "Training done. Time Collapsed =  0.17s\n",
            "Training done. Time Collapsed =  0.17s\n",
            "Training done. Time Collapsed =  0.17s\n",
            "Training done. Time Collapsed =  0.17s\n",
            "Training done. Time Collapsed =  0.17s\n",
            "Training done. Time Collapsed =  0.17s\n",
            "Training done. Time Collapsed =  0.18s\n",
            "Training done. Time Collapsed =  0.18s\n",
            "Training done. Time Collapsed =  0.18s\n",
            "Training done. Time Collapsed =  0.18s\n",
            "Training done. Time Collapsed =  0.18s\n",
            "Training done. Time Collapsed =  0.19s\n",
            "Training done. Time Collapsed =  0.19s\n",
            "Training done. Time Collapsed =  0.19s\n",
            "Training done. Time Collapsed =  0.19s\n",
            "Training done. Time Collapsed =  0.19s\n",
            "Training done. Time Collapsed =  0.19s\n",
            "Training done. Time Collapsed =  0.20s\n",
            "Training done. Time Collapsed =  0.20s\n",
            "Training done. Time Collapsed =  0.20s\n",
            "Training done. Time Collapsed =  0.20s\n",
            "Training done. Time Collapsed =  0.20s\n",
            "Training done. Time Collapsed =  0.21s\n",
            "Training done. Time Collapsed =  0.21s\n",
            "Training done. Time Collapsed =  0.21s\n",
            "Training done. Time Collapsed =  0.21s\n",
            "Training done. Time Collapsed =  0.22s\n",
            "Training done. Time Collapsed =  0.22s\n",
            "Training done. Time Collapsed =  0.22s\n",
            "Training done. Time Collapsed =  0.22s\n",
            "Training done. Time Collapsed =  0.23s\n",
            "Training done. Time Collapsed =  0.23s\n",
            "Training done. Time Collapsed =  0.23s\n",
            "Training done. Time Collapsed =  0.23s\n",
            "Training done. Time Collapsed =  0.23s\n",
            "Training done. Time Collapsed =  0.24s\n",
            "Training done. Time Collapsed =  0.24s\n",
            "Training done. Time Collapsed =  0.24s\n",
            "Training done. Time Collapsed =  0.24s\n",
            "Training done. Time Collapsed =  0.24s\n",
            "Training done. Time Collapsed =  0.24s\n",
            "Training done. Time Collapsed =  0.25s\n",
            "Training done. Time Collapsed =  0.25s\n",
            "Training done. Time Collapsed =  0.25s\n",
            "Training done. Time Collapsed =  0.25s\n",
            "Training done. Time Collapsed =  0.25s\n",
            "Training done. Time Collapsed =  0.25s\n",
            "Training done. Time Collapsed =  0.26s\n",
            "Training done. Time Collapsed =  0.26s\n",
            "Training done. Time Collapsed =  0.26s\n",
            "Training done. Time Collapsed =  0.26s\n",
            "Training done. Time Collapsed =  0.26s\n",
            "Training done. Time Collapsed =  0.27s\n",
            "Training done. Time Collapsed =  0.27s\n",
            "Training done. Time Collapsed =  0.27s\n",
            "Training done. Time Collapsed =  0.27s\n",
            "Training done. Time Collapsed =  0.27s\n",
            "Training done. Time Collapsed =  0.27s\n",
            "Training done. Time Collapsed =  0.28s\n",
            "Training done. Time Collapsed =  0.28s\n",
            "Training done. Time Collapsed =  0.28s\n",
            "Training done. Time Collapsed =  0.28s\n",
            "Training done. Time Collapsed =  0.28s\n",
            "Training done. Time Collapsed =  0.29s\n",
            "Training done. Time Collapsed =  0.29s\n",
            "Training done. Time Collapsed =  0.29s\n",
            "Training done. Time Collapsed =  0.29s\n",
            "Training done. Time Collapsed =  0.30s\n",
            "Training done. Time Collapsed =  0.30s\n",
            "Training done. Time Collapsed =  0.30s\n",
            "Training done. Time Collapsed =  0.30s\n",
            "Training done. Time Collapsed =  0.30s\n",
            "Training done. Time Collapsed =  0.31s\n",
            "Training done. Time Collapsed =  0.31s\n",
            "Training done. Time Collapsed =  0.31s\n",
            "Training done. Time Collapsed =  0.31s\n",
            "Training done. Time Collapsed =  0.31s\n",
            "Training done. Time Collapsed =  0.32s\n",
            "Training done. Time Collapsed =  0.32s\n",
            "Training done. Time Collapsed =  0.32s\n",
            "Training done. Time Collapsed =  0.32s\n",
            "Training done. Time Collapsed =  0.32s\n",
            "Training done. Time Collapsed =  0.32s\n",
            "Training done. Time Collapsed =  0.33s\n",
            "Training done. Time Collapsed =  0.33s\n",
            "Training done. Time Collapsed =  0.33s\n",
            "Training done. Time Collapsed =  0.33s\n",
            "Training done. Time Collapsed =  0.33s\n",
            "Training done. Time Collapsed =  0.34s\n",
            "Training done. Time Collapsed =  0.34s\n",
            "Training done. Time Collapsed =  0.34s\n",
            "Training done. Time Collapsed =  0.34s\n",
            "Training done. Time Collapsed =  0.34s\n",
            "Training done. Time Collapsed =  0.34s\n",
            "Training done. Time Collapsed =  0.35s\n",
            "Training done. Time Collapsed =  0.35s\n",
            "Training done. Time Collapsed =  0.35s\n",
            "Training done. Time Collapsed =  0.35s\n",
            "Training done. Time Collapsed =  0.35s\n",
            "Training done. Time Collapsed =  0.35s\n",
            "Training done. Time Collapsed =  0.36s\n",
            "Training done. Time Collapsed =  0.36s\n",
            "Training done. Time Collapsed =  0.36s\n",
            "Training done. Time Collapsed =  0.36s\n",
            "Training done. Time Collapsed =  0.36s\n",
            "Training done. Time Collapsed =  0.37s\n",
            "Training done. Time Collapsed =  0.37s\n",
            "Training done. Time Collapsed =  0.37s\n",
            "Training done. Time Collapsed =  0.37s\n",
            "Training done. Time Collapsed =  0.37s\n",
            "Training done. Time Collapsed =  0.38s\n",
            "Training done. Time Collapsed =  0.38s\n",
            "Training done. Time Collapsed =  0.38s\n",
            "Training done. Time Collapsed =  0.38s\n",
            "Training done. Time Collapsed =  0.38s\n",
            "Training done. Time Collapsed =  0.38s\n",
            "Training done. Time Collapsed =  0.39s\n",
            "Training done. Time Collapsed =  0.39s\n",
            "Training done. Time Collapsed =  0.39s\n",
            "Training done. Time Collapsed =  0.39s\n",
            "Training done. Time Collapsed =  0.39s\n",
            "Training done. Time Collapsed =  0.40s\n",
            "Training done. Time Collapsed =  0.40s\n",
            "Training done. Time Collapsed =  0.40s\n",
            "Training done. Time Collapsed =  0.40s\n",
            "Training done. Time Collapsed =  0.40s\n",
            "Training done. Time Collapsed =  0.40s\n",
            "Training done. Time Collapsed =  0.41s\n",
            "Training done. Time Collapsed =  0.41s\n",
            "Training done. Time Collapsed =  0.41s\n",
            "Training done. Time Collapsed =  0.42s\n",
            "Training done. Time Collapsed =  0.42s\n",
            "Training done. Time Collapsed =  0.42s\n",
            "Training done. Time Collapsed =  0.42s\n",
            "Training done. Time Collapsed =  0.42s\n",
            "Training done. Time Collapsed =  0.43s\n",
            "Training done. Time Collapsed =  0.43s\n",
            "Training done. Time Collapsed =  0.43s\n",
            "Training done. Time Collapsed =  0.43s\n",
            "Training done. Time Collapsed =  0.43s\n",
            "Training done. Time Collapsed =  0.43s\n",
            "Training done. Time Collapsed =  0.44s\n",
            "Training done. Time Collapsed =  0.44s\n",
            "Training done. Time Collapsed =  0.44s\n",
            "Training done. Time Collapsed =  0.44s\n",
            "Training done. Time Collapsed =  0.44s\n",
            "Training done. Time Collapsed =  0.45s\n",
            "Training done. Time Collapsed =  0.45s\n",
            "Training done. Time Collapsed =  0.45s\n",
            "Training done. Time Collapsed =  0.45s\n",
            "Training done. Time Collapsed =  0.45s\n",
            "Training done. Time Collapsed =  0.45s\n",
            "Training done. Time Collapsed =  0.46s\n",
            "Training done. Time Collapsed =  0.46s\n",
            "Training done. Time Collapsed =  0.46s\n",
            "Training done. Time Collapsed =  0.46s\n",
            "Training done. Time Collapsed =  0.46s\n",
            "Training done. Time Collapsed =  0.47s\n",
            "Training done. Time Collapsed =  0.47s\n",
            "Training done. Time Collapsed =  0.47s\n",
            "Training done. Time Collapsed =  0.48s\n",
            "Training done. Time Collapsed =  0.48s\n",
            "Training done. Time Collapsed =  0.48s\n",
            "Training done. Time Collapsed =  0.48s\n",
            "Training done. Time Collapsed =  0.48s\n",
            "Training done. Time Collapsed =  0.48s\n",
            "Training done. Time Collapsed =  0.49s\n",
            "Training done. Time Collapsed =  0.49s\n",
            "Training done. Time Collapsed =  0.49s\n",
            "Training done. Time Collapsed =  0.49s\n",
            "Training done. Time Collapsed =  0.49s\n",
            "Training done. Time Collapsed =  0.49s\n",
            "Training done. Time Collapsed =  0.50s\n",
            "Training done. Time Collapsed =  0.50s\n",
            "Training done. Time Collapsed =  0.50s\n",
            "Training done. Time Collapsed =  0.50s\n",
            "Training done. Time Collapsed =  0.50s\n",
            "Training done. Time Collapsed =  0.51s\n",
            "Training done. Time Collapsed =  0.51s\n",
            "Training done. Time Collapsed =  0.51s\n",
            "Training done. Time Collapsed =  0.51s\n",
            "Training done. Time Collapsed =  0.51s\n",
            "Training done. Time Collapsed =  0.51s\n",
            "Training done. Time Collapsed =  0.52s\n",
            "Training done. Time Collapsed =  0.52s\n",
            "Training done. Time Collapsed =  0.52s\n",
            "Training done. Time Collapsed =  0.52s\n",
            "Training done. Time Collapsed =  0.52s\n",
            "Training done. Time Collapsed =  0.52s\n",
            "Training done. Time Collapsed =  0.53s\n",
            "Training done. Time Collapsed =  0.53s\n",
            "Training done. Time Collapsed =  0.53s\n",
            "Training done. Time Collapsed =  0.53s\n",
            "Training done. Time Collapsed =  0.53s\n",
            "Training done. Time Collapsed =  0.54s\n",
            "Training done. Time Collapsed =  0.54s\n",
            "Training done. Time Collapsed =  0.54s\n",
            "Training done. Time Collapsed =  0.54s\n",
            "Training done. Time Collapsed =  0.54s\n",
            "Training done. Time Collapsed =  0.54s\n",
            "Training done. Time Collapsed =  0.55s\n",
            "Training done. Time Collapsed =  0.55s\n",
            "Training done. Time Collapsed =  0.55s\n",
            "Training done. Time Collapsed =  0.55s\n",
            "Training done. Time Collapsed =  0.55s\n",
            "Training done. Time Collapsed =  0.55s\n",
            "Training done. Time Collapsed =  0.56s\n",
            "Training done. Time Collapsed =  0.56s\n",
            "Training done. Time Collapsed =  0.56s\n",
            "Training done. Time Collapsed =  0.56s\n",
            "Training done. Time Collapsed =  0.56s\n",
            "Training done. Time Collapsed =  0.57s\n",
            "Training done. Time Collapsed =  0.57s\n",
            "Training done. Time Collapsed =  0.57s\n",
            "Training done. Time Collapsed =  0.57s\n",
            "Training done. Time Collapsed =  0.57s\n",
            "Training done. Time Collapsed =  0.57s\n",
            "Training done. Time Collapsed =  0.58s\n",
            "Training done. Time Collapsed =  0.58s\n",
            "Training done. Time Collapsed =  0.58s\n",
            "Training done. Time Collapsed =  0.58s\n",
            "Training done. Time Collapsed =  0.58s\n",
            "Training done. Time Collapsed =  0.58s\n",
            "Training done. Time Collapsed =  0.59s\n",
            "Training done. Time Collapsed =  0.59s\n",
            "Training done. Time Collapsed =  0.59s\n",
            "Training done. Time Collapsed =  0.59s\n",
            "Training done. Time Collapsed =  0.59s\n",
            "Training done. Time Collapsed =  0.59s\n",
            "Training done. Time Collapsed =  0.60s\n",
            "Training done. Time Collapsed =  0.60s\n",
            "Training done. Time Collapsed =  0.60s\n",
            "Training done. Time Collapsed =  0.60s\n",
            "Training done. Time Collapsed =  0.60s\n",
            "Training done. Time Collapsed =  0.61s\n",
            "Training done. Time Collapsed =  0.61s\n",
            "Training done. Time Collapsed =  0.61s\n",
            "Training done. Time Collapsed =  0.61s\n",
            "Training done. Time Collapsed =  0.61s\n",
            "Training done. Time Collapsed =  0.61s\n",
            "Training done. Time Collapsed =  0.62s\n",
            "Training done. Time Collapsed =  0.62s\n",
            "Training done. Time Collapsed =  0.62s\n",
            "Training done. Time Collapsed =  0.63s\n",
            "Training done. Time Collapsed =  0.63s\n",
            "Training done. Time Collapsed =  0.63s\n",
            "Training done. Time Collapsed =  0.63s\n",
            "Training done. Time Collapsed =  0.63s\n",
            "Training done. Time Collapsed =  0.63s\n",
            "Training done. Time Collapsed =  0.64s\n",
            "Training done. Time Collapsed =  0.64s\n",
            "Training done. Time Collapsed =  0.64s\n",
            "Training done. Time Collapsed =  0.65s\n",
            "Training done. Time Collapsed =  0.65s\n",
            "Training done. Time Collapsed =  0.65s\n",
            "Training done. Time Collapsed =  0.65s\n",
            "Training done. Time Collapsed =  0.65s\n",
            "Training done. Time Collapsed =  0.65s\n",
            "Training done. Time Collapsed =  0.66s\n",
            "Training done. Time Collapsed =  0.66s\n",
            "Training done. Time Collapsed =  0.66s\n",
            "Training done. Time Collapsed =  0.66s\n",
            "Training done. Time Collapsed =  0.66s\n",
            "Training done. Time Collapsed =  0.66s\n",
            "Training done. Time Collapsed =  0.67s\n",
            "Training done. Time Collapsed =  0.67s\n",
            "Training done. Time Collapsed =  0.67s\n",
            "Training done. Time Collapsed =  0.67s\n",
            "Training done. Time Collapsed =  0.67s\n",
            "Training done. Time Collapsed =  0.68s\n",
            "Training done. Time Collapsed =  0.68s\n",
            "Training done. Time Collapsed =  0.68s\n",
            "Training done. Time Collapsed =  0.68s\n",
            "Training done. Time Collapsed =  0.68s\n",
            "Training done. Time Collapsed =  0.68s\n",
            "Training done. Time Collapsed =  0.69s\n",
            "Training done. Time Collapsed =  0.69s\n",
            "Training done. Time Collapsed =  0.69s\n",
            "Training done. Time Collapsed =  0.69s\n",
            "Training done. Time Collapsed =  0.69s\n",
            "Training done. Time Collapsed =  0.69s\n",
            "Training done. Time Collapsed =  0.70s\n",
            "Training done. Time Collapsed =  0.70s\n",
            "Training done. Time Collapsed =  0.70s\n",
            "Training done. Time Collapsed =  0.70s\n",
            "Training done. Time Collapsed =  0.70s\n",
            "Training done. Time Collapsed =  0.71s\n",
            "Training done. Time Collapsed =  0.71s\n",
            "Training done. Time Collapsed =  0.71s\n",
            "Training done. Time Collapsed =  0.71s\n",
            "Training done. Time Collapsed =  0.71s\n",
            "Training done. Time Collapsed =  0.71s\n",
            "Training done. Time Collapsed =  0.72s\n",
            "Training done. Time Collapsed =  0.72s\n",
            "Training done. Time Collapsed =  0.72s\n",
            "Training done. Time Collapsed =  0.72s\n",
            "Training done. Time Collapsed =  0.72s\n",
            "Training done. Time Collapsed =  0.72s\n",
            "Training done. Time Collapsed =  0.73s\n",
            "Training done. Time Collapsed =  0.73s\n",
            "Training done. Time Collapsed =  0.73s\n",
            "Training done. Time Collapsed =  0.73s\n",
            "Training done. Time Collapsed =  0.73s\n",
            "Training done. Time Collapsed =  0.73s\n",
            "Training done. Time Collapsed =  0.74s\n",
            "Training done. Time Collapsed =  0.74s\n",
            "Training done. Time Collapsed =  0.74s\n",
            "Training done. Time Collapsed =  0.74s\n",
            "Training done. Time Collapsed =  0.74s\n",
            "Training done. Time Collapsed =  0.75s\n",
            "Training done. Time Collapsed =  0.75s\n",
            "Training done. Time Collapsed =  0.75s\n",
            "Training done. Time Collapsed =  0.75s\n",
            "Training done. Time Collapsed =  0.75s\n",
            "Training done. Time Collapsed =  0.75s\n",
            "Training done. Time Collapsed =  0.76s\n",
            "Training done. Time Collapsed =  0.76s\n",
            "Training done. Time Collapsed =  0.76s\n",
            "Training done. Time Collapsed =  0.76s\n",
            "Training done. Time Collapsed =  0.76s\n",
            "Training done. Time Collapsed =  0.76s\n",
            "Training done. Time Collapsed =  0.77s\n",
            "Training done. Time Collapsed =  0.77s\n",
            "Training done. Time Collapsed =  0.77s\n",
            "Training done. Time Collapsed =  0.77s\n",
            "Training done. Time Collapsed =  0.77s\n",
            "Training done. Time Collapsed =  0.78s\n",
            "Training done. Time Collapsed =  0.78s\n",
            "Training done. Time Collapsed =  0.78s\n",
            "Training done. Time Collapsed =  0.78s\n",
            "Training done. Time Collapsed =  0.78s\n",
            "Training done. Time Collapsed =  0.78s\n",
            "Training done. Time Collapsed =  0.79s\n",
            "Training done. Time Collapsed =  0.79s\n",
            "Training done. Time Collapsed =  0.79s\n",
            "Training done. Time Collapsed =  0.79s\n",
            "Training done. Time Collapsed =  0.79s\n",
            "Training done. Time Collapsed =  0.79s\n",
            "Training done. Time Collapsed =  0.80s\n",
            "Training done. Time Collapsed =  0.80s\n",
            "Training done. Time Collapsed =  0.80s\n",
            "Training done. Time Collapsed =  0.80s\n",
            "Training done. Time Collapsed =  0.80s\n",
            "Training done. Time Collapsed =  0.81s\n",
            "Training done. Time Collapsed =  0.81s\n",
            "Training done. Time Collapsed =  0.81s\n",
            "Training done. Time Collapsed =  0.81s\n",
            "Training done. Time Collapsed =  0.82s\n",
            "Training done. Time Collapsed =  0.82s\n",
            "Training done. Time Collapsed =  0.82s\n",
            "Training done. Time Collapsed =  0.82s\n",
            "Training done. Time Collapsed =  0.83s\n",
            "Training done. Time Collapsed =  0.83s\n",
            "Training done. Time Collapsed =  0.83s\n",
            "Training done. Time Collapsed =  0.83s\n",
            "Training done. Time Collapsed =  0.84s\n",
            "Training done. Time Collapsed =  0.84s\n",
            "Training done. Time Collapsed =  0.84s\n",
            "Training done. Time Collapsed =  0.84s\n",
            "Training done. Time Collapsed =  0.84s\n",
            "Training done. Time Collapsed =  0.84s\n",
            "Training done. Time Collapsed =  0.85s\n",
            "Training done. Time Collapsed =  0.85s\n",
            "Training done. Time Collapsed =  0.85s\n",
            "Training done. Time Collapsed =  0.85s\n",
            "Training done. Time Collapsed =  0.85s\n",
            "Training done. Time Collapsed =  0.85s\n",
            "Training done. Time Collapsed =  0.86s\n",
            "Training done. Time Collapsed =  0.86s\n",
            "Training done. Time Collapsed =  0.86s\n",
            "Training done. Time Collapsed =  0.86s\n",
            "Training done. Time Collapsed =  0.86s\n",
            "Training done. Time Collapsed =  0.87s\n",
            "Training done. Time Collapsed =  0.87s\n",
            "Training done. Time Collapsed =  0.87s\n",
            "Training done. Time Collapsed =  0.87s\n",
            "Training done. Time Collapsed =  0.87s\n",
            "Training done. Time Collapsed =  0.87s\n",
            "Training done. Time Collapsed =  0.88s\n",
            "Training done. Time Collapsed =  0.88s\n",
            "Training done. Time Collapsed =  0.88s\n",
            "Training done. Time Collapsed =  0.88s\n",
            "Training done. Time Collapsed =  0.88s\n",
            "Training done. Time Collapsed =  0.88s\n",
            "Training done. Time Collapsed =  0.89s\n",
            "Training done. Time Collapsed =  0.89s\n",
            "Training done. Time Collapsed =  0.89s\n",
            "Training done. Time Collapsed =  0.89s\n",
            "Training done. Time Collapsed =  0.89s\n",
            "Training done. Time Collapsed =  0.89s\n",
            "Training done. Time Collapsed =  0.90s\n",
            "Training done. Time Collapsed =  0.90s\n",
            "Training done. Time Collapsed =  0.90s\n",
            "Training done. Time Collapsed =  0.90s\n",
            "Training done. Time Collapsed =  0.90s\n",
            "Training done. Time Collapsed =  0.91s\n",
            "Training done. Time Collapsed =  0.91s\n",
            "Training done. Time Collapsed =  0.91s\n",
            "Training done. Time Collapsed =  0.91s\n",
            "Training done. Time Collapsed =  0.91s\n",
            "Training done. Time Collapsed =  0.91s\n",
            "Training done. Time Collapsed =  0.92s\n",
            "Training done. Time Collapsed =  0.92s\n",
            "Training done. Time Collapsed =  0.92s\n",
            "Training done. Time Collapsed =  0.92s\n",
            "Training done. Time Collapsed =  0.92s\n",
            "Training done. Time Collapsed =  0.92s\n",
            "Training done. Time Collapsed =  0.93s\n",
            "Training done. Time Collapsed =  0.93s\n",
            "Training done. Time Collapsed =  0.93s\n",
            "Training done. Time Collapsed =  0.93s\n",
            "Training done. Time Collapsed =  0.93s\n",
            "Training done. Time Collapsed =  0.93s\n",
            "Training done. Time Collapsed =  0.94s\n",
            "Training done. Time Collapsed =  0.94s\n",
            "Training done. Time Collapsed =  0.94s\n",
            "Training done. Time Collapsed =  0.94s\n",
            "Training done. Time Collapsed =  0.94s\n",
            "Training done. Time Collapsed =  0.95s\n",
            "Training done. Time Collapsed =  0.95s\n",
            "Training done. Time Collapsed =  0.95s\n",
            "Training done. Time Collapsed =  0.95s\n",
            "Training done. Time Collapsed =  0.95s\n",
            "Training done. Time Collapsed =  0.95s\n",
            "Training done. Time Collapsed =  0.96s\n",
            "Training done. Time Collapsed =  0.96s\n",
            "Training done. Time Collapsed =  0.96s\n",
            "Training done. Time Collapsed =  0.96s\n",
            "Training done. Time Collapsed =  0.96s\n",
            "Training done. Time Collapsed =  0.96s\n",
            "Training done. Time Collapsed =  0.97s\n",
            "Training done. Time Collapsed =  0.97s\n",
            "Training done. Time Collapsed =  0.97s\n",
            "Training done. Time Collapsed =  0.97s\n",
            "Training done. Time Collapsed =  0.97s\n",
            "Training done. Time Collapsed =  0.98s\n",
            "Training done. Time Collapsed =  0.98s\n",
            "Training done. Time Collapsed =  0.98s\n",
            "Training done. Time Collapsed =  0.98s\n",
            "Training done. Time Collapsed =  0.98s\n",
            "Training done. Time Collapsed =  0.98s\n",
            "Training done. Time Collapsed =  0.99s\n",
            "Training done. Time Collapsed =  0.99s\n",
            "Training done. Time Collapsed =  0.99s\n",
            "Training done. Time Collapsed =  0.99s\n",
            "Training done. Time Collapsed =  0.99s\n",
            "Training done. Time Collapsed =  0.99s\n",
            "Training done. Time Collapsed =  1.00s\n",
            "Training done. Time Collapsed =  1.00s\n",
            "Training done. Time Collapsed =  1.00s\n",
            "Training done. Time Collapsed =  1.00s\n",
            "Training done. Time Collapsed =  1.00s\n",
            "Training done. Time Collapsed =  1.00s\n",
            "Training done. Time Collapsed =  1.01s\n",
            "Training done. Time Collapsed =  1.01s\n",
            "Training done. Time Collapsed =  1.01s\n",
            "Training done. Time Collapsed =  1.01s\n",
            "Training done. Time Collapsed =  1.01s\n",
            "Training done. Time Collapsed =  1.02s\n",
            "Training done. Time Collapsed =  1.02s\n",
            "Training done. Time Collapsed =  1.02s\n",
            "Training done. Time Collapsed =  1.02s\n",
            "Training done. Time Collapsed =  1.02s\n",
            "Training done. Time Collapsed =  1.02s\n",
            "Training done. Time Collapsed =  1.03s\n",
            "Training done. Time Collapsed =  1.03s\n",
            "Training done. Time Collapsed =  1.03s\n",
            "Training done. Time Collapsed =  1.04s\n",
            "Training done. Time Collapsed =  1.04s\n",
            "Training done. Time Collapsed =  1.04s\n",
            "Training done. Time Collapsed =  1.04s\n",
            "Training done. Time Collapsed =  1.04s\n",
            "Training done. Time Collapsed =  1.04s\n",
            "Training done. Time Collapsed =  1.05s\n",
            "Training done. Time Collapsed =  1.05s\n",
            "Training done. Time Collapsed =  1.05s\n",
            "Training done. Time Collapsed =  1.05s\n",
            "Training done. Time Collapsed =  1.05s\n",
            "Training done. Time Collapsed =  1.05s\n",
            "Training done. Time Collapsed =  1.06s\n",
            "Training done. Time Collapsed =  1.06s\n",
            "Training done. Time Collapsed =  1.06s\n",
            "Training done. Time Collapsed =  1.06s\n",
            "Training done. Time Collapsed =  1.06s\n",
            "Training done. Time Collapsed =  1.07s\n",
            "Training done. Time Collapsed =  1.07s\n",
            "Training done. Time Collapsed =  1.07s\n",
            "Training done. Time Collapsed =  1.07s\n",
            "Training done. Time Collapsed =  1.07s\n",
            "Training done. Time Collapsed =  1.07s\n",
            "Training done. Time Collapsed =  1.08s\n",
            "Training done. Time Collapsed =  1.08s\n",
            "Training done. Time Collapsed =  1.08s\n",
            "Training done. Time Collapsed =  1.08s\n",
            "Training done. Time Collapsed =  1.08s\n",
            "Training done. Time Collapsed =  1.08s\n",
            "Training done. Time Collapsed =  1.09s\n",
            "Training done. Time Collapsed =  1.09s\n",
            "Training done. Time Collapsed =  1.09s\n",
            "Training done. Time Collapsed =  1.09s\n",
            "Training done. Time Collapsed =  1.09s\n",
            "Training done. Time Collapsed =  1.10s\n",
            "Training done. Time Collapsed =  1.10s\n",
            "Training done. Time Collapsed =  1.10s\n",
            "Training done. Time Collapsed =  1.10s\n",
            "Training done. Time Collapsed =  1.10s\n",
            "Training done. Time Collapsed =  1.11s\n",
            "Training done. Time Collapsed =  1.11s\n",
            "Training done. Time Collapsed =  1.11s\n",
            "Training done. Time Collapsed =  1.11s\n",
            "Training done. Time Collapsed =  1.11s\n",
            "Training done. Time Collapsed =  1.12s\n",
            "Training done. Time Collapsed =  1.12s\n",
            "Training done. Time Collapsed =  1.12s\n",
            "Training done. Time Collapsed =  1.12s\n",
            "Training done. Time Collapsed =  1.12s\n",
            "Training done. Time Collapsed =  1.12s\n",
            "Training done. Time Collapsed =  1.13s\n",
            "Training done. Time Collapsed =  1.13s\n",
            "Training done. Time Collapsed =  1.13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJILw7xAkX1g",
        "colab_type": "code",
        "outputId": "7381ca2c-9169-4e27-e785-af3c659d8c3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.plot(train_loss_list, label='Training loss')\n",
        "# plt.plot(test_loss_list, label='Validation loss')\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3c7b567668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvUAAAIFCAYAAABS0AKUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeZxXdd3//8drZthXAdlFQFFwV1Rc\nSnHP3VTKMrN+aZZZaVpelaZ19b2yfVGvMjX1Csu1XDC3lBQUIcElEBBkExEBkU32mffvj8+HYYAB\nZ5jPcOYz87jfbud2Pu+zvM/rI9N1PefM+7xPpJSQJEmSVLxKsi5AkiRJUt0Y6iVJkqQiZ6iXJEmS\nipyhXpIkSSpyhnpJkiSpyBnqJUmSpCJnqJckSZKKnKFekiRJKnKGekmSJKnIGeolSZKkImeolyRJ\nkoqcoV6SJEkqcoZ6SZIkqcgZ6iVJkqQiZ6ivhYg4NyJujIhREbEsIlJEDM+6rqoiojQizs/XOD8i\nVkbEmxFxR0TsnXV9kiRJKrxIKWVdQ9GIiFeB/YEVwFxgIHB3SulzmRZWRUTcC3yKXH2PAsuBfYFP\nAOuAk1NKz2ZXoSRJkgqtLOsCiswV5MLydOBoYGS25WwqIg4hF+gnAYemlFZW2fdF4E/ANYChXpIk\nqRFx+E0tpJRGppSmpVr8eSMiPhMRIyNiSUSsjojJEXFNRLSohxL759fPVA30eQ/n1zvXw3UlSZKU\nIUN9PYqIPwF/AXYHHgRuBhYD/w08ERGF/kvJpPz62Ihotdm+0/Lrfxb4mpIkScqYw2/qSUR8Afgi\n8Hfg/JTSqir7rgeuA74G/LZQ10wpTYyIX5MbJjQlIkaQG1O/N7kx9feQG34jSZKkRsQHZbdTRAwl\nN6a+2gdlI+IVYB9g55TSks32lQLvATNSSofWQ22XAL8Gqt6tHw9ck1J6otDXkyRJUra8U18PIqI1\nuVlyFgGXR0R1h60BBm123r/IPYBbUy+klD5W5fwgd+f/UnJ35IcDS4ADyIX8xyPispTSzbW4hiRJ\nkho4Q3392AkIcg+lXleL8+YAU2tx/OzN2hcCXwd+nVK6ocr20RFxOjADuCEi7koprajFdSRJktSA\nGerrx9L8+pWU0kE1PSml9Pk6XnfDw7BbTLWZUpofEVOAA4E9yQ3HkSRJUiPg7Df1IH8XfBKwd0R0\n2oGX3jBN5tamrdywfe0OqEWSJEk7iKG+/vwKaA78KSI6br4zInaKiBrfxa+hUfn1tyKiw2bX+wrQ\nG5gPvFHg60qSJClDzn5TCxFxFnBWvtkdOIncOPUNYXpRSumqKsffTO6h1cXAk+TGzHcC+gFHAXek\nlL5SwPraAi8A+wELgEfIPSh7EHAsUA58KqX0t0JdU5IkSdkz1NdClfnlt2Z2SqnvZuecBnwFOBTo\nSC7gzwGeAoanlKYUuMa2wLeAs4EB5P5asBAYDfwipTSukNeTJElS9gz1kiRJUpFzTL0kSZJU5Az1\nkiRJUpEz1EuSJElFzlAvSZIkFTnfKPsRImIm0B6YlXEpkiRJatz6AstSSv1qe6Kh/qO1b9WqVadB\ngwbtyDfDSpIkqYmZPHkyq1at2q5zDfUfbdagQYM6jR8/Pus6JEmS1IgNHjyYCRMmzNqecx1TL0mS\nJBU5Q70kSZJU5Az1kiRJUpEz1EuSJElFzlAvSZIkFTlDvSRJklTkDPWSJElSkTPUS5IkSUXOUC9J\nkiQVuTqH+ojoHBEXRcTfI2J6RKyKiKURMToivhQRNb5GRMyKiLSVZf42zjsiIv4REYvz1389Ii6P\niNK6fj9JkiSpoSsrQB/DgN8D7wIjgTlAN+Bs4Dbg5IgYllJKNexvKfCbaravqO7giDgTeBBYDdwL\nLAZOB34NHJmvT5IkSWq0ChHq3wTOAB5LKVVs2BgR3wPGAeeQC/gP1rC/JSml62tyYES0B24FyoGh\nKaWX89uvBZ4Fzo2I81JK99Tw2pIkSVLRqfPwm5TSsymlR6sG+vz2+cAf8s2hdb3OVpwL7AzcsyHQ\n56+9Grgm3/xqPV1bkiRJahAKcad+W9bl1+trcU6LiPgc0Af4EHgdeD6lVF7Nscfm109Us+95YCVw\nRES0SCmtqUUNkiRJUtGot1AfEWXA5/PN6kL31nQH/rzZtpkR8cWU0nObbd8zv35z805SSusjYiaw\nN9AfmPwR9Y7fyq6BH12yJEmSlJ36nNLyBmAf4B8ppSdreM4dwHHkgn0bYF/gFqAv8HhE7L/Z8R3y\n66Vb6W/D9o41vH6D8sGHa/nP3K19NUmSJCmnXkJ9RHwDuBKYAlxQ0/NSSj/Mj9F/L6W0MqU0MaX0\nFeBXQCvg+vqoN3/twdUt5L7DDjX3g5V86g9jGPzjp/n6XydQ84mDJEmSYMWKFUQEp512Wp37Ovjg\ng2nbtm0Bqiqcm266iYjggQceyLqUBqPgoT4iLgN+C7wBHJNSWlyAbjc8cHvUZts33MbuQPU2bF9S\ngBp2mC5tWzBx3lIqEsx6fyVvLfww65IkSVINREStljvvvDPrktVIFHRMfURcTm5++InAcSmlBQXq\nemF+3Waz7VOBg4E9gE3GxOfH9Pcj95DujALVsUO0bFbKxwd04clJ7wHwz8nvsXvXhvUbsiRJ2tJ1\n1123xbbf/OY3LF26lG9+85t07LjpiOADDjigXupo06YNkydPLsgd9gcffJA1a5xvpKErWKiPiKvJ\njaN/FTghpbSoUH0Dh+XXm4fzZ4HzgU8Af91s31FAa3Iz5xTdT+Lxg7pVhvpnJr/HV47eLeOKJEnS\nR7n++uu32HbnnXeydOlSLr/8cvr27btD6ogIBg4szFwfu+66a0H6Uf0qyPCb/MuebiB3t/y4bQX6\niGgWEQMjYrfNtg+KiM3vxBMRfYGb8s3hm+1+AFgEnBcRB1c5pyXw43zz97X7Ng3DMQO7EpH7PH72\nByz+cG22BUmSpHqzYdz6qlWruOaaa9h9991p3rw5l112GQDvv/8+N9xwA0cffTQ9e/akefPmdOvW\njXPOOYfx47ecwG9rY+qvuuoqIoKXX36Zu+++m8GDB9OqVSu6dOnCBRdcwIIFWw6yqG5M/YgRI4gI\nfvGLXzBu3DhOOukk2rdvT9u2bTn++OOrrQlgzpw5fO5zn6NLly60bt2awYMHc++9927SX12NGTOG\nM888ky5dutCiRQv69+/P5ZdfzsKFC7c4dt68eXzzm99kjz32oHXr1uy0004MGjSIL33pS7z99tuV\nx1VUVHDrrbcyZMgQunTpQqtWrejTpw+nnHIKDz30UJ1rLoQ636mPiAuBH5F7q+so4BuxIY1uNCul\ndGf+cy9y00vOJjerzQafBq6MiOfz+5YDuwGnAi2BfwCb/EunlJZFxMXkwv2/IuIeYDG5N9zumd9+\nb12/Yxa6tG3Bgbt0ZMKcJVQkGDllAecM7p11WZIkqZ5UVFRw2mmnMXXqVE466SQ6d+5ceZf8lVde\n4brrrmPo0KGceeaZdOjQgZkzZ/LII48wYsQInn76aY46avNHD7fuZz/7GSNGjODMM8/kmGOO4YUX\nXmD48OFMnDiRl19+mdLS0hr1M3r0aK655hqGDh3Kl7/8ZWbMmMFDDz3E0KFDmThx4iZ3+efOncvh\nhx/OvHnzOO644zjkkEN45513uPDCCzn55JNr9x9rK+677z7OP/98SktLGTZsGL179+all17it7/9\nLQ8//DAvvPACPXv2BGDZsmUMGTKEefPmceKJJ3LWWWexbt06Zs+ezQMPPMAFF1zALrvsAsDll1/O\njTfeyIABA/jMZz5D27ZtmTdvHmPHjuWhhx7irLPOKkj9dZJSqtNCbkaa9BHLv6oc3ze/bdZm/RxN\nbgjNFHIPtq4jN5b+aXLz3cc2ajiSXOj/AFgF/Ae4AigtwPcbf9BBB6Us3DxyWtr16hFp16tHpK8O\nfzmTGiRJUt3suuuuCUgzZ87c6jGDBw9OQDrkkEPSBx98sMX+999/Py1evHiL7dOnT0+dO3dOBx98\n8Cbbly9fnoB06qmnbrL9yiuvTEDq1KlTmjp1auX2ioqKdMYZZyQgPfbYY1vU1qZNm022Pfroo5U5\n7/77799k3y9+8YsEpG9/+9ubbP/Upz6VgPSjH/1ok+1jxoxJpaWlCUg///nPt/iO1bnxxhu3uPb7\n77+f2rVrl5o1a5b+/e9/b3L8Nddck4D0yU9+snLbX/7ylwSka665Zov+V61alZYvX55SSqm8vDy1\nbNky7bbbbmn16tVbHLtw4cIa1VwTBx10UALGp+3IrHW+U59Sup5aTDWZUpoFbHErP+VeLLX5y6Vq\n2ucLwCnbc25DdvygbvzsiakAPDd1IWvWl9OirGa/OUuS1ND0/a/Hsi6hxmbdcGom1/3JT36yxcO0\nAJ06dar2+N12240zzjiDO+64g8WLF2/1uM19+9vfZo899qhsRwQXXXQRjzzyCOPGjeOUU2oWq046\n6STOPffcTbZ9+ctf5qqrrmLcuHGV25YvX87f/vY3unbtyre//e1Njj/ssMMYNmwY99xzT42uuTX3\n338/y5cv5+KLL+bggw/eZN/3v/99brvtNh5++GEWLVpEly5dKve1atVqi75atmy5STsiaN68ebV/\nwajaV5bq8+VTqqMBXdvSp1NrAD5cW87YGYWYHVSSJDVUhx566Fb3jRw5krPPPpvevXvTvHnzymkx\n77jjDgDeeeedGl9n89ALVA41+eCDD+rUT7t27ejQocMm/UycOJH169czePDgLQIzwMc+9rEaX3Nr\nJkyYAMCxxx67xb6WLVtyxBFHUFFRwWuvvQbACSecwM4778y1117Laaedxs0338yrr75KRUXFJueW\nlJRw3nnnMXnyZPbZZx+uvfZannrqKZYvX17nmgupoFNaqrAiguMGdeWOF2YBuVlwjtpj52yLkiRJ\n9aJ169a0a9eu2n3Dhw/n85//PG3btuWEE06gX79+tGnThojgqaeeYsyYMbWadrK6vwaUleViYXl5\neZ362dBX1X6WLs29Wqhbt27VHr+17bWx4Ro9evSodv+G7UuW5F5f1KVLF8aOHcv111/PiBEjeOyx\nxypr+cY3vsHVV19deWf+lltuYeDAgdx11138+Me5uViaNWvGGWecwS9/+csGMUOQob6BO35Qt8pQ\n/8/JC7j+jEQ1DyJLktTgZTWkpVhs6/+/X3PNNbRr145XXnmF/v37b7Jv2rRpjBkzpr7Lq5P27dsD\n8N5771W7f2vba6NDh9w7R+fPn1/t/nfffXeT4wD69evHXXfdRUVFBRMnTuSZZ57hpptu4vvf/z6l\npaVcffXVQC7Af+c73+E73/kO8+fPZ9SoUQwfPpwHH3yQKVOm8Nprr9X44eL64vCbBu7Qfp1o1zL3\nu9c7S1YxZX7D+lOPJEmqX+vXr2f27NkccMABWwT6devWNfhAD7DvvvtSVlbG+PHjWb169Rb7R48e\nXedrHHjggQD861//2mLfmjVrGDNmDBFR7Qu/SkpK2G+//bjiiisYMWIEwFanquzevTvDhg3j4Ycf\n5tBDD2XSpElMnz69zvXXlaG+gWtWWsLRVYbcPDO57r/JSpKk4lFWVkavXr2YNGkSixZtfBVQRUUF\n3/3ud5k5c2aG1dVMu3btOOuss1iwYAE///nPN9k3duxY7r///jpf41Of+hRt27bljjvuqBw3v8FP\nfvIT3n333cr56wFef/31Tf57brDhrwatW+eea1yxYsUmD/1usGbNmsohP9U9bLujOfymCBw/qBsj\nXs/9yejpyQu47NgBGVckSZJ2pCuuuIKrrrqK/fbbj7PPPpuSkhKee+45Zs2axcknn8zjjz+edYkf\n6Ze//CWjR4/mBz/4Ac8//zyHHHIIc+fO5b777uP000/noYceoqRk++83d+rUiT/+8Y9ccMEFHH74\n4QwbNoxevXrx0ksvMXLkSPr06cNNN91UefwjjzzCj370I4488kgGDBhAly5dmD17Ng8//DClpaVc\nddVVQG4M/pAhQxg4cCAHHnggffr0YeXKlTzxxBNMmzaNz372s/Tp06fO/33qylBfBIbuuTOlJUF5\nReK1t5ewYPlqurbb8slxSZLUOH3rW9+ibdu23HTTTfzpT3+iTZs2DB06lPvuu49bb721KEJ9nz59\neOmll/jud7/Lk08+yejRo9lrr7246667WLVqFQ899FDl2Pvt9ZnPfIY+ffpwww03MGLECJYvX07P\nnj35+te/zjXXXEPXrl0rjz3jjDNYuHAho0aN4m9/+xsrVqygR48enH766Vx55ZWVM/t07tyZ//mf\n/2HkyJGMGjWKhQsX0r59ewYMGMDVV1/NhRdeWKeaCyVS7gVL2oqIGH/QQQcdtLXXHe8on75lDGNn\n5qa0vOHsfTnv0Ox/I5QkSSqEb37zm/zud79j9OjRHHnkkVmXk5nBgwczYcKECSmlwbU91zH1ReKE\nvTZO9fTPyQsyrESSJGn7zJs3b4tt//73v/njH/9Iz549GTJkSAZVNQ4OvykSxw3qxo8fmwzA6OkL\nWb2unJbNfLusJEkqHoMGDeKggw5i7733pmXLlkydOrVy6NDNN99cOVe+as879UWiX5c27LZzGwBW\nr6tg1LQtn9aWJElqyC699FIWL17M3XffzW9/+1vGjh3LaaedxvPPP89ZZ52VdXlFzV+HisgJe3Xn\nrefeAuDJSfM3GZIjSZLU0P3kJz/hJz/5SdZlNEreqS8iJ+29McQ/M/k91pdXZFiNJEmSGgpDfRHZ\nv3dHurVvAcAHK9cxbtbijCuSJElSQ2CoLyIlJcGJe3WvbD81ybfLSpIkyVBfdE7ae2Oof/qN9/A9\nA5IkSTLUF5kh/TvRvmXu+eZ3lqxi4jvLMq5IkiRJWTPUF5lmpSUcN2jjA7NPTpqfYTWSJElqCAz1\nRajqLDiGekmSJBnqi9BRe+xMi7LcP920BSuYsXBFxhVJkiQpS4b6ItS6eRlH7bFzZfupN5wFR5Ik\nqSkz1BepqrPgOARHkiSpaTPUF6njBnaltCQAeGXOEt5btjrjiiRJkpQVQ32R2qlNcw7t26my7RAc\nSZKkpstQX8SqzoLzlENwJEmSmixDfRE7scq4+jFvvc/SlesyrEaSJElZMdQXsZ4dW7Ff7w4ArK9I\n/HOyQ3AkSZKaIkN9kfvEPhvv1j8+8d0MK5EkSVJWDPVF7tR9e1R+fv7NRSxb7RAcSZKkpsZQX+R2\n7dyGvXu2B2BteQXPOARHkiSpyTHUNwKnVLlb/9jrzoIjSZLU1BjqG4Gqof75aQtZ7hAcSZKkJsVQ\n3wj069KGQT3yQ3DWV/DslAUZVyRJkqQdyVDfSJy678ZZcB573VlwJEmSmhJDfSNRdQjOv95cyIo1\n6zOsRpIkSTuSob6R6L9zWwZ2bwc4BEeSJKmpqXOoj4jOEXFRRPw9IqZHxKqIWBoRoyPiSxFRo2ts\nTz8R0Tci0jaWe+r6/YpJ1bv1/3AIjiRJUpNRVoA+hgG/B94FRgJzgG7A2cBtwMkRMSyllOqxn9eA\nh6rZPrH2X6d4nbJvD3719JsAjJy6gA/XrKdNi0L8E0uSJKkhK0TiexM4A3gspVSxYWNEfA8YB5xD\nLpg/WI/9vJpSur4O36FR2L1rW/bs1o6p7y1nTX4Izun798y6LEmSJNWzOg+/SSk9m1J6tGoQz2+f\nD/wh3xy6o/pp6jYZgvMfh+BIkiQ1BfX9oOyGtyDVdSqWj+qnZ0RcEhHfy6/3q+P1itap+22c2nLk\n1AWsXOssOJIkSY1dvQ24jogy4PP55hP13M8J+aXqef8CLkwpzanhdcZvZdfAmpzfUOzetR0DurZl\n2oIVrF6XG4Jz2n4OwZEkSWrM6vNO/Q3APsA/UkpP1lM/K4H/BgYDO+WXo8k9aDsUeCYi2tTh2kWp\naoh/5NV5GVYiSZKkHaFeQn1EfAO4EpgCXFBf/aSUFqSUfpBSmpBSWpJfngdOBMYCuwMX1eRaKaXB\n1S35axeVMw7YGOr/NXUhS1et28bRkiRJKnYFD/URcRnwW+AN4JiU0uId3U9KaT25aTABjtqe6xez\nfl3asG+vDgCsLa/gyYnzM65IkiRJ9amgoT4iLgduJDc//DH5mWuy6mdhft3kht8AnFFlKstHXnMI\njiRJUmNWsFAfEVcDvwZeJRfEF2TZD3BYfj1jO88vaqft34OI3OcX31rEguWrsy1IkiRJ9aYgoT4i\nriX3QOt44LiU0qJtHNssIgZGxG516Sd//EERscV3iIjjgCvyzeE1/yaNR48OrTikbycAKhL843Xn\nrJckSWqs6jylZURcCPwIKAdGAd+IDbeIN5qVUroz/7kXMBmYDfStQz8AvwIGRMSLwNz8tv2AY/Of\nr00pvbidX63onXlAT8bNzD2K8Mhr8/jCkf0yrkiSJEn1oRDz1G9IiqXA5Vs55jngznro58/AJ4FD\ngJOBZsB7wH3ATSmlUR9xzUbtlH16cN3Dk1hfkZgwZwlvL17JLp1aZ12WJEmSCqzOw29SStenlOIj\nlqFVjp+V39a3Lv3kz7k9pXRaSqlvSqltSqlFSqlPSunTTT3QA+zUpjkfH9Clsu0Ds5IkSY1Tfb58\nSg1A1TnrHzXUS5IkNUqG+kbuhL2606Is9888Zf5y3nxvecYVSZIkqdAM9Y1c2xZlHL9Xt8r2I696\nt16SJKmxMdQ3AZu/iCqllGE1kiRJKjRDfRMwdM+dadcyN9HRnMUrefXtJRlXJEmSpEIy1DcBLcpK\n+cTe3SvbD73yTobVSJIkqdAM9U3EJw/qVfn5kdfmsXZ9RYbVSJIkqZAM9U3EYf0607NDSwA+WLmO\n595cmHFFkiRJKhRDfRNRUhKb3K3/24S5GVYjSZKkQjLUNyGfPLB35ednJi9gycq1GVYjSZKkQjHU\nNyG7d23L/r07ALC2vIIRr7+bcUWSJEkqBEN9E3P2QRvv1jsER5IkqXEw1Dcxp+/fk7KSAGDCnCXM\nXPRhxhVJkiSprgz1TUynNs05ZmDXyvbfvVsvSZJU9Az1TdA5VWfBeeUdKipShtVIkiSprgz1TdAx\nA7vSoVUzAOZ+sIqXZ3+QcUWSJEmqC0N9E9SirJTT9+9R2faBWUmSpOJmqG+iqs6C89jr77J6XXmG\n1UiSJKkuDPVN1IG7dKRflzYALF+znqfeeC/jiiRJkrS9DPVNVETwyQM3PjB7/8tvZ1iNJEmS6sJQ\n34SdM7g3kZuyntHTFzH3g5XZFiRJkqTtYqhvwnp1bMXHB+wMQEpw/8s+MCtJklSMDPVN3KcP3qXy\n8wPj51LunPWSJElFx1DfxB2/V1d2ap2bs/6dJat4YfqijCuSJElSbRnqm7gWZaV88sCN01ve6wOz\nkiRJRcdQLz59yMYhOE9Peo8PPlybYTWSJEmqLUO92LN7O/bfpSMAa8sr+Psr72RckSRJkmrDUC9g\n0wdm73v5bVLygVlJkqRiYagXAKft34OWzXI/DlPmL+f1uUszrkiSJEk1ZagXAO1bNuOUfXtUtn1g\nVpIkqXgY6lWp6hCcR1+dx6q15RlWI0mSpJoy1KvSof060a9LGwCWr1nPP/7zbsYVSZIkqSYM9aoU\nEQw7eOOc9X8dNyfDaiRJklRThnptYtjgXSgrCQBenv0BU+Yvy7giSZIkfRRDvTaxc7sWnLRP98r2\n3S95t16SJKmhq3Ooj4jOEXFRRPw9IqZHxKqIWBoRoyPiSxFRq2tERO+I+FNEzIuINRExKyJ+ExE7\nbeOcvSLivohYEBGrI2JqRPwwIlrV9fs1RecP6VP5+e+vvMOHa9ZnWI0kSZI+SiHu1A8DbgWGAGOB\n3wAPAvsAtwH3RUTUpKOI2A0YD3wRGAf8GpgBfBMYExGdqzlnCPBv4Czgn8BvgWXAD4CnI6JFXb5c\nU3R4/8703zn3wOyKNet55LV5GVckSZKkbSlEqH8TOAPonVI6P6X03ZTS/wcMBN4GzgHOrmFf/wt0\nBb6RUjorpfRfKaVjyYX7PYH/V/XgiCgF7gBaA+emlD6bUrqa3C8YDwJHAlfU+Rs2MRHB+UN2rWwP\nf2m2b5iVJElqwOoc6lNKz6aUHk0pVWy2fT7wh3xz6Ef1k79LfyIwC7h5s93XAR8CF0REmyrbjwYG\nAc+nlB6pcu0K4Dv55ldq+pcCbXTOQb1oUZb78Zg0bxmv+YZZSZKkBqu+H5Rdl1/XZFD2Mfn1U9X8\ngrAceIHcHfnDquw6Nr9+YvPOUkozyP0VYVegfy1qFtCxdXNO269nZfvul2ZnWI0kSZK2pd5CfUSU\nAZ/PN7cI3dXYM79+cyv7p+XXe9TxnGpFxPjqFnLDiJqk8w/b+MDso6/PY+nKdds4WpIkSVmpzzv1\nN5B7WPYfKaUna3B8h/x6a+M8NmzvWMdzVEMH7tKRvXq0B2D1ugoenDA344okSZJUnXoJ9RHxDeBK\nYApwQX1co9BSSoOrW8h9hyYpIja5W3/3WB+YlSRJaogKHuoj4jJy00q+ARyTUlpcw1M33FXvsJX9\nG7YvqeM5qoUzD+hFm+alALy18EPGzqzpP6ckSZJ2lIKG+oi4HLgRmEgu0M+vxelT8+utjX8fkF9X\nHT+/PeeoFtq2KOOsA3tVtv88xgdmJUmSGpqChfqIuJrcfPKvkgv0C2rZxcj8+sTN30IbEe3IzTm/\nEnipyq5n8+tPVFNPf3Jhfza5F1hpO33usI1z1j8xaT7vLl2VYTWSJEnaXEFCfURcS+7B2PHAcSml\nRds4tllEDMzPS18ppfQW8BTQF/jaZqf9EGgD/Dml9GGV7c8Bk4GjIuKMKtcoAX6ab/4hORC8Tgb1\naM+Qfp0AKK9I3P3SnIwrkiRJUlVlde0gIi4EfgSUA6OAb1TzrqdZKaU78597kQvis8kF+KouBV4E\nfhcRx+WPG0JuDvs3ge9XPTilVB4RXyR3x/6BiHgAmAMcBxxMbm77X9f1Owq+eGTfyvH0fxk3h8uO\n3Z2WzUozrkqSJElQgFAP9MuvS4HLt3LMc8CdH9VRSumtiDiY3C8JnwBOAd4l9+DtD1NKH1RzztiI\nOITc3fwTgXbkfmH4EXBDSmlNrb6NqnX8oG706tiKd5asYvGHa3n0tXkMO3iXrMuSJEkSBQj1KaXr\ngetrcfwsYItb+VX2vw18sXrNGiQAACAASURBVJY1vAEMq805qp2y0hI+d9iu/PSJ3Ayfd744i3MH\n96aav8pIkiRpB6vPl0+pkTnvkF1oUZb7kZk0bxnjZ2/xhxNJkiRlwFCvGtupTXM+WWV6yztenJVd\nMZIkSapkqFetXHhE38rPT0x0ektJkqSGwFCvWhnUoz2H9d84veXwl3wZlSRJUtYM9aq1L1S5W//X\ncW+zel15dsVIkiTJUK/a2zC9JVA5vaUkSZKyY6hXrZWVlnDB4btWtm8fPRNf2itJkpQdQ722y3mH\n7EKr/Btlp8xfzgvT38+4IkmSpKbLUK/t0rF1c4Yd3LuyfeuoGRlWI0mS1LQZ6rXdvvSxfmx4oexz\nby5k6vzl2RYkSZLURBnqtd127dyGk/bqXtm+zbv1kiRJmTDUq04uPqpf5eeHX53HgmWrM6xGkiSp\naTLUq04G79qJg/p0BGBteQV3jZmVaT2SJElNkaFedXbxx/tXfh7+0hxWrl2fYTWSJElNj6FedXbi\n3t3p06k1AEtXreOB8XMzrkiSJKlpMdSrzkpLgi99bOPY+ttGzaS8wpdRSZIk7SiGehXEsIN706FV\nMwDmLF7J02/Mz7giSZKkpsNQr4Jo3byMzx3Wp7J9y/MzSMm79ZIkSTuCoV4Fc+HhfWlemvuRemXO\nEl6asTjjiiRJkpoGQ70Kpmv7lpwzuFdl+3//NT3DaiRJkpoOQ70K6pKjdqMkcp9HTVvEf+YuzbYg\nSZKkJsBQr4Lq26UNp+zbo7L9++e8Wy9JklTfDPUquK8O3a3y8+MT5/PWwhUZViNJktT4GepVcHv3\n7MDQPXcGICW45bm3Mq5IkiSpcTPUq15cOnT3ys9/f+Ud3l26KsNqJEmSGjdDverFof06cfCuOwGw\nrjxx6/MzM65IkiSp8TLUq95ceszGsfV/HTeHxR+uzbAaSZKkxstQr3pzzJ5dGdi9HQCr1pVz54uz\nsi1IkiSpkTLUq95ExCYz4dz5wkyWrV6XYUWSJEmNk6Fe9erUfXvQt3NrAJatXs//ebdekiSp4Az1\nqldlpSV87ZiNM+HcNnomK9asz7AiSZKkxsdQr3p31oG92KVTKwCWrFzHXd6tlyRJKihDvepds9IS\nLqt6t37UDD70br0kSVLBGOq1Q5x9UG9675S7W//BynX8+aXZGVckSZLUeBjqtUM022xs/a3Pz2Dl\nWu/WS5IkFYKhXjvMOQf1plfH3N369z9cy90vzcm4IkmSpMahIKE+Is6NiBsjYlRELIuIFBHDa9nH\nF/LnbWsp3+ycvh9x/D2F+H4qjOZlJZvMW3/L82+xam35Ns6QJElSTZQVqJ9rgP2BFcBcYOB29PEq\n8MOt7Ps4cCzw+Fb2vwY8VM32idtRh+rRsIN7c/PI6by7dDWLVqzl7rGzuejj/bMuS5IkqagVKtRf\nQS7MTweOBkbWtoOU0qvkgv0WImJM/uMft3L6qyml62t7Te14LcpKuXToblz78CQA/vDcDM4fsiut\nmpdmXJkkSVLxKsjwm5TSyJTStJRSKkR/VUXEvsBhwDvAY4XuXzvepw7Zhe7tWwKwaMUa7hozK9N6\nJEmSil0xPCj75fz69pTS1gZg94yISyLie/n1fjuqONVei7JSvn7cxplw/vDcWyxfvS7DiiRJkopb\noYbf1IuIaAV8DigHbtvGoSfkl6rn/gu4MKVUoylWImL8VnZtz/MB+gjDBu/CH557i7cXr2LJynXc\nPnomlx+/R9ZlSZIkFaWGfqf+U0BH4ImU0tvV7F8J/DcwGNgpv2wY0z8UeCYi2uyYUlUbzctKuPy4\njSH+9lEz+eDDtRlWJEmSVLwaeqjfMPTmlup2ppQWpJR+kFKakFJakl+eB04ExgK7AxfV5EIppcHV\nLcCUQnwRbemsA3ux286537mWr1nPLc/PyLgiSZKk4tRgQ31E7A0cQW5WnX/U5tyU0no2Dtc5qsCl\nqUBKS4JvnbBnZfvOF2eyYPnqDCuSJEkqTg021FOzB2S3ZWF+7fCbBuzkfbozqEd7AFavq+B/R76V\ncUWSJEnFp0GG+ohoCVxA7gHZ27ezm8Pya8d0NGAlJcFVJ24cW/+XsXN4Z8mqDCuSJEkqPjs81EdE\ns4gYGBG7beOwYeQeen18Kw/IbujroIjY4jtExHHkXogFMLxOBaveHTuwKwfs0hGAteUV3PTstIwr\nkiRJKi4FmdIyIs4Czso3u+fXh0fEnfnPi1JKV+U/9wImA7OBvlvpcsPQm629QXaDXwEDIuJFcmPv\nAfYDjs1/vjal9GJNvoOyExF8+6Q9Of+2sQDc9/JcLv54f/rv3DbjyiRJkopDoeapPwC4cLNt/fML\n5AL8VdRARAwCPkbNHpD9M/BJ4BDgZKAZ8B5wH3BTSmlUTa6p7B2xW2cO79+ZMTPep7wi8fMnp/L7\nzw3OuixJkqSiUJDhNyml61NKsY2lb5VjZ22+bbO+Juf37/JRD8imlG5PKZ2WUuqbUmqbUmqRUuqT\nUvq0gb64RAT/dfLG93w9PnE+E+Z8kGFFkiRJxaNBPiirpmn/XTpy6n49Kts3PD6FlFKGFUmSJBUH\nQ70alG+fuCdlJQHAuJmLGTl1QcYVSZIkNXyGejUofbu04bND+lS2f/r4VMorvFsvSZK0LYZ6NThf\nP3YAbZqXAjD1veX8bcLcjzhDkiSpaTPUq8HZuV0LLj6qf2X7V0+/yep12/NSYUmSpKbBUK8G6aKP\n96dL2+YAvLt0NXe9OCvbgiRJkhowQ70apLYtyvjmcQMq2zePnM6SlWszrEiSJKnhMtSrwTrv0D70\n7dwagGWr1/PbZ6ZlXJEkSVLDZKhXg9WstIT/OnlQZfvPY2bz1sIVGVYkSZLUMBnq1aCdtHc3hvTr\nBMD6isRP/jE544okSZIaHkO9GrSI4NrT9iJy76Pin5MX8ML0RdkWJUmS1MAY6tXg7dOrA2cf2Luy\n/d8j3vCFVJIkSVUY6lUUvvOJPWnVLPdCqinzl3P/y29nXJEkSVLDYahXUejWviVfOXq3yvYvnnqT\nFWvWZ1iRJElSw2GoV9G4+Kh+dG/fEoBFK9bw+39Nz7giSZKkhsFQr6LRunkZ3/nEnpXtW0fN5O3F\nKzOsSJIkqWEw1KuonHVAL/br3QGAtesr+PFjb2RckSRJUvYM9SoqJSXBdafvVdl+ctJ7jJq2MMOK\nJEmSsmeoV9EZvGsnzj6oV2X7+kcmsXZ9RYYVSZIkZctQr6L0XycPpG2LMgDeWvghd704K9uCJEmS\nMmSoV1Hq2q4llx8/oLL9m3++yYJlqzOsSJIkKTuGehWtC4/oy+5d2wLw4dpybnh8SsYVSZIkZcNQ\nr6LVrLSE60/fu7L9t1feYfzsxRlWJEmSlA1DvYraxwZ04eR9ule2f/DwJMorUoYVSZIk7XiGehW9\n7586iJbNcj/Kk+Yt455/z8m4IkmSpB3LUK+i13un1lw6dPfK9s+fnMoHH67NsCJJkqQdy1CvRuHL\nR/Vnl06tAFiycp0PzUqSpCbFUK9GoWWz0k0emr335bcZN9OHZiVJUtNgqFejcdygbpy0d7fK9vf+\n/h/fNCtJkpoEQ70alevP2Js2zUsBmL5gBbeOmpFxRZIkSfXPUK9GpUeHVnzrxD0r2797Zhqz3/8w\nw4okSZLqn6Fejc6Fh+/K3j3bA7BmfQXXPjyJlJy7XpIkNV6GejU6ZaUl/M8n9yUi137+zYWMeP3d\nbIuSJEmqR4Z6NUr779KRzx+2a2X7RyPeYOmqdRlWJEmSVH8M9Wq0rjxpT7q2awHAwuVr+MWTUzOu\nSJIkqX4Y6tVotW/ZjOuqzF0/fOxsJsz5IMOKJEmS6kdBQn1EnBsRN0bEqIhYFhEpIoZvRz+z8udW\nt8zfxnlHRMQ/ImJxRKyKiNcj4vKIKK3bN1OxO2Xf7gzdc2cAUoLvPPA6a9aXZ1yVJElSYZUVqJ9r\ngP2BFcBcYGAd+loK/Kaa7SuqOzgizgQeBFYD9wKLgdOBXwNHAsPqUIuKXETw32fuw0m/eZ6Va8uZ\nvmAFNz07nSurTHspSZJU7AoV6q8gF+anA0cDI+vQ15KU0vU1OTAi2gO3AuXA0JTSy/nt1wLPAudG\nxHkppXvqUI+K3C6dWnP1JwZy3SOTAPj9v97i5H16sFd+2ktJkqRiV5DhNymlkSmlaWnHTwZ+LrAz\ncM+GQJ+vZzW5vx4AfHUH16QG6ILDduWQvjsBsL4i8Z0HX2N9eUXGVUmSJBVGQ3xQtkVEfC4ivhcR\n34yIY7YxNv7Y/PqJavY9D6wEjoiIFh910YgYX91C3YYSqYEoKQluOGc/mpflfuQnvrOMP46akXFV\nkiRJhdEQQ3134M/A/yM3tv5ZYFpEHF3NsRsGRr+5+Y6U0npgJrkhRv3rp1QVk912bssVx+9R2f7N\nP6fx1sJqH9WQJEkqKg0t1N8BHEcu2LcB9gVuAfoCj0fE/psd3yG/XrqV/jZs7/hRF04pDa5uAabU\n8juoAbv44/3Yt1fux2bt+gqufuB1Kip29KgxSZKkwmpQoT6l9MOU0rMppfdSSitTShNTSl8BfgW0\nAq7PtkIVu7LSEn56zn6UlQQAL8/+gP8bMyvTmiRJkuqqQYX6bfhDfn3UZts33InvQPU2bF9S8IpU\ntPbq2Z5Lh+5W2f7Zk1N5e/HKDCuSJEmqm2IJ9Qvz6zabbZ+aX++x2XYiogzoB6wHfCJSm/jasbsz\noGtbAFauLeeq+19zGI4kSSpaxRLqD8uvNw/nz+bXn6jmnKOA1sCLKaU19VWYilOLslJ+Pmx/8qNw\nGDtzMXe8OCvTmiRJkrbXDg/1EdEsIgZGxG6bbR8UEZvfiSci+gI35ZvDN9v9ALAIOC8iDq5yTkvg\nx/nm7wtUuhqZA3bpyKVDd69s//SJKUxfsDzDiiRJkrZPQd4oGxFnAWflm93z68Mj4s7850Uppavy\nn3sBk4HZ5Ga12eDTwJUR8Xx+33JgN+BUoCXwD+AXVa+bUloWEReTC/f/ioh7gMXAGeSmu3wAuLcQ\n31GN0zeOG8CzUxbwxrvLWLu+gm/d9xoPfvUImpUWyx+xJEmSCnen/gDgwvxyUn5b/yrbzq1BHyOB\nEeSC/GeBbwFHA6PzfZyWUlq7+UkppYfyxz0PnAN8HViXP/+8DN5yqyLSvKyEX3/6AJrnQ/zrc5fy\nvyPfyrgqSZKk2inInfqU0vXUcLrJlNIsIKrZ/hzw3HZe/wXglO05V9qzezuuPHEPfvJ47pUENz47\njWMHdmXf3lubVEmSJKlhcYyBBFz08f4c0ncnANZXJL5136usXleecVWSJEk1Y6iXgNKS4BfD9qd1\n81IApi1YwS+fmvoRZ0mSJDUMhnopb9fObfj+qYMq27eNnslLM97PsCJJkqSaMdRLVXz20D4cvcfO\nAKQE37r3VZauXJdxVZIkSdtmqJeqiAh+du5+dGzdDIB5S1fz3b+/jpMoSZKkhsxQL22mW/uW/PSc\n/Srb//jPfO5/eW6GFUmSJG2boV6qxkl7d+f8IX0q29c9Mom3Fq7IsCJJkqStM9RLW3HNqXuxe9e2\nAKxaV84373mFtesrMq5KkiRpS4Z6aStaNS/ld+cdWPm22YnvLHOaS0mS1CAZ6qVt2Ktne/7r5IGV\n7Vuen8HoaYsyrEiSJGlLhnrpI3zxyL4M3XPnyva37nuV91esybAiSZKkTRnqpY8QEfz83P3p0rY5\nAAuWr+Gq+1+josJpLiVJUsNgqJdqYOd2LfjFsP0r2yOnLuSW52dkWJEkSdJGhnqphobu2ZVLjupf\n2f7FU1MZN3NxhhVJkiTlGOqlWrjqpD0ZvOtOAJRXJL7+1wkscny9JEnKmKFeqoVmpSXc9NkD2al1\nMwDeW7aGK+591fH1kiQpU4Z6qZZ6dGjFrz59QGV71LRF3DxyeoYVSZKkps5QL22HY/bsyqVDd6ts\n//qfb/LiW85fL0mSsmGol7bTt07Yg0P7dQKgIsE373mVhcsdXy9JknY8Q720ncpKS7jxMwfSuU1u\n/vqFy9fw9b9OYH15RcaVSZKkpsZQL9VBt/Yt+c15BxCRa780YzE/fWJKtkVJkqQmx1Av1dHHB+zM\nt47fo7J966iZPPLavAwrkiRJTY2hXiqArx2zO8cP6lbZvvqB15kyf1mGFUmSpKbEUC8VQElJ8KtP\n70//Lm0AWLWunEv+PJ6lK9dlXJkkSWoKDPVSgbRv2YxbLhhM6+alAMx+fyWX3/uKL6aSJEn1zlAv\nFdCAbu34xbD9K9sjpy7kN89My7AiSZLUFBjqpQI7Zd8eXHJ0/8r2756ZxtNvvJdhRZIkqbEz1Ev1\n4Nsn7snHdu9S2b7i3ld5873lGVYkSZIaM0O9VA/KSkv43WcOpFfHVgCsWLOei+56mcUfrs24MkmS\n1BgZ6qV60qlNc279/MGVD87OWbySrw4fz9r1vnFWkiQVlqFeqkd79WzPrz99QGV77MzFXPfIJFJy\nRhxJklQ4hnqpnp20d3e+fdKele2/jpvDXS/Oyq4gSZLU6BjqpR3g0qG7cdYBPSvbPxrxBs+/uTDD\niiRJUmNiqJd2gIjghnP2Y/9dOgJQkeBrf5nAWwtXZFyZJElqDAz10g7Sslkpt14wmO7tWwKwfPV6\nvnTnv50RR5Ik1VlBQn1EnBsRN0bEqIhYFhEpIobXso/OEXFRRPw9IqZHxKqIWBoRoyPiSxGxRa0R\n0Td/ra0t9xTi+0mF0rV9S2678GBaNsv9OM96fyVf/r+XWb2uPOPKJElSMSsrUD/XAPsDK4C5wMDt\n6GMY8HvgXWAkMAfoBpwN3AacHBHDUvXThrwGPFTN9onbUYdUr/bp1YHffPoAvnr3BFKCl2d/wJX3\nv8aN5x1ISUlkXZ4kSSpChQr1V5AL89OBo8mF8tp6EzgDeCylVDmRd0R8DxgHnEMu4D9YzbmvppSu\n345rSpn4xD49+P4pg/jxY5MBeOz1d+m9Uyu+e/KgjCuTJEnFqCDDb1JKI1NK07ZyF72mfTybUnq0\naqDPb58P/CHfHFqHMqUG5Usf68eFh+9a2b7luRkMf2l2hhVJkqRiVag79fVtXX69fiv7e0bEJUBn\n4H1gTErp9R1SmbSdIoIfnL437yxZxT8nLwDgBw9PpFfHVhwzsGvG1UmSpGLS4Ge/iYgy4PP55hNb\nOewEcnfz/19+/VpEjIyIPrW4zvjqFrbv+QCpRkpLgt995kD27dUB2DjV5cR3lmZcmSRJKiYNPtQD\nNwD7AP9IKT252b6VwH8Dg4Gd8suGMf1DgWcios2OK1WqvdbNy7j9CwfTq2MrAFauLeeLd/6btxev\nzLgySZJULBp0qI+IbwBXAlOACzbfn1JakFL6QUppQkppSX55HjgRGAvsDlxUk2ullAZXt+SvLdWr\nru1acucXD6Fdy9yIuIXL1/D5P41j0Yo1GVcmSZKKQYMN9RFxGfBb4A3gmJTS4pqem1JaT24aTICj\n6qE8qeAGdGvHrZ8/mOZluf9Zzlz0IV+849+sWLO1R0kkSZJyGmSoj4jLgRvJzTN/TH4GnNpamF87\n/EZF47D+nfndeQewYbr6/7yzlK/8eTxr1vtyKkmStHUNLtRHxNXAr4FXyQX6BdvZ1WH59YyCFCbt\nIJ/Ypwc/Pmvfyvbo6Yu48r7XqKjY7hljJUlSI7fDQ31ENIuIgRGxWzX7riX3YOx44LiU0qKP6Oug\niNjiO0TEceReiAUwvABlSzvUZ4f04coT9qhsj3j9XX746CTq8CoISZLUiBVknvqIOAs4K9/snl8f\nHhF35j8vSildlf/cC5gMzAb6VunjQuBHQDkwCvhGRGx+qVkppTurtH8FDIiIF8m90RZgP+DY/Odr\nU0ovbvcXkzJ02bG7s2jFGu4ak3sh1V1jZtOlbQu+ftyAjCuTJEkNTaFePnUAcOFm2/rnF8gF+KvY\ntn75dSlw+VaOeQ64s0r7z8AngUOAk4FmwHvAfcBNKaVRNahdapAigutO35v3P1zLiNffBeCXT79J\nu5ZlfOHIfh9xtiRJakoKEupTStcD19fw2FnAFrfga9NHlXNuB26vzTlSMSkpCX75qf1ZsnIdo6fn\nRqNd/+gbtG5exqcO2SXj6iRJUkPR4B6UlbSpFmWl3HLBYA7q07Fy23/97XUefW1ehlVJkqSGxFAv\nFYE2Lcq444uHsnfP9gBUJLji3lf55xvvZVyZJElqCAz1UpHo0KoZf/7SEAZ0bQvA+orEpX+ZwOhp\n25wkSpIkNQGGeqmIdGrTnOEXDWHXzq0BWLu+gov/72VenlXjFy5LkqRGyFAvFZlu7Vty90VD6NGh\nJQCr1pXzxTv+zStzPsi4MkmSlBVDvVSEeu/UmrsvGkKXti0AWL5mPZ+/fRyvvr0k48okSVIWDPVS\nkeq/c1uGX3Qondo0B3LB/oLbxxrsJUlqggz1UhEb2L09d180ZGOwX50L9q8Z7CVJalIM9VKRG9Qj\nF+x3at0MyAX7zxnsJUlqUgz1UiMwqEd7/nLxYVsE+9fnGuwlSWoKDPVSI1FdsD//trHOiiNJUhNg\nqJcakdxQnM3u2N82lpdmvJ9xZZIkqT4Z6qVGZq+euWC/4eHZD9eW84U7xvHcmwszrkySJNUXQ73U\nCO3Vsz33XXIYXdvl5rFfva6Ci+96macmzc+4MkmSVB8M9VIjtXvXdtx3yeH06tgKgLXlFXz17gk8\n/Oo7GVcmSZIKzVAvNWJ9u7Thvq8cTt/OrQEor0hcfu+r3PfvtzOuTJIkFZKhXmrkenVsxX2XHM6A\nrm0BSAm+8+Dr3DZqRsaVSZKkQjHUS01A1/YtufeSw9m7Z/vKbT9+bDI3PD6FlFKGlUmSpEIw1EtN\nRKc2zfnLxYdxSN+dKrf94bm3uPrB11lfXpFhZZIkqa4M9VIT0qFVM/78pSEcP6hr5bb7Xp7LV4ZP\nYPW68gwrkyRJdWGol5qYls1K+cPnBnPu4N6V2/45+T0uuH0sS1ety7AySZK0vQz1UhNUVlrCz8/d\nj0uO7l+57d+zPuDTt4zhvWWrM6xMkiRtD0O91ERFBN89eRDXnDqoctuU+cs55/cv8tbCFRlWJkmS\nastQLzVxF328P7/61P6UlQQAcz9Yxdn/+yJjZ7yfcWWSJKmmDPWSOPug3tx64cG0alYKwNJV67jg\n9nE89Ipvn5UkqRgY6iUBcMyeXbn3ksPo0rYFAGvLK7j83le58ZlpzmUvSVIDZ6iXVGm/3h156GtH\nsEe3tpXbfvn0m3z7gddZu9657CVJaqgM9ZI20Xun1tz/lSM4cvfOldseGD+XL9wxzikvJUlqoAz1\nkrbQoVUz7vjCoQyrMpf9i2+9z7m/f5G3F6/MsDJJklQdQ72kajUvK+Fn5+7HVSfuUblt2oIVnHnz\nC86MI0lSA2Ool7RVEcFlxw7gt+cdQPPS3P+5WPzhWs6/bSx/GTsn4+okSdIGhnpJH+nMA3rxl4uH\n0KVtcwDWVyS+9/f/8IOHJ7Ku3AdoJUnKmqFeUo0c3LcTD1/2Mfbu2b5y2/+Nmc3nbx/HBx+uzbAy\nSZJkqJdUY706tuKBrxzBqfv1qNw2Zsb7nHHzaKbOX55hZZIkNW2Gekm10qp5KTd95sBNHqB9e/Eq\nzv7fF3hy0vwMK5Mkqeky1EuqtQ0P0N5ywWBaNy8F4MO15Vzy5/Hc8PgU1jvOXpKkHaogoT4izo2I\nGyNiVEQsi4gUEcO3s6/eEfGniJgXEWsiYlZE/CYidtrGOXtFxH0RsSAiVkfE1Ij4YUS02v5vJemj\nnLR3d/526RHs0mnj/9T+8NxbXHD7OBatWJNhZZIkNS2FulN/DXAZcADwzvZ2EhG7AeOBL/7/7d13\neFxXnf/x93dGvVu25SbbcZNLHMexE8fEcUsjvUASYDcQQg2wpCwQWHYXEn6bpYc0smEpCQSWAA7B\ngUAIqY7tVPfETlzlJtmWrN7LnN8f90oayxpbkiXNjPx5Pc88d+acc8vcoxl975lzzwHeAH4E7ARu\nBV41s6FdrHM28CZwNfAccB9QBXwD+IeZJff2eETk+KaNzOLP/3IuS6YOb097dedhLr9/JWt2l0fx\nyERERE4efRXU3w4UAFnA505gOw8BecAtzrmrnXNfc86dhxfcTwXuDi9sZkHgESANuNY590/Oua8C\nZwNPAAv8YxORfpSTlsQvbjyL2y6YgpmXdqCqgQ//76v8cnUhzrnoHqCIiMgg1ydBvXPuRefcNncC\n/7n9VvqLgELgx52yvwnUAh81s/Sw9MXAdGCFc+6psOMJAXf4L282awszRKS/BALGbRcU8MjHzyI7\nNRGA5lbHN596h9t+t566ppYoH6GIiMjgFUs3yi71l8/6QXk751w1sAqvRX5+WNZ5/vKZzhtzzu0E\ntgLjgYl9frQi0qUlU/P4yxfPZeaYjvHsl68v4soHV2nYSxERkX4SS0H9VH+5NUL+Nn9ZEJbWm3W6\nZGZrunoA0463rogcaWxuGstuPocPnTm2PW37oRqufHAlv31jj7rjiIiI9LFYCuqz/WVlhPy29JwT\nXEdEBkBKYpDvXjuL731wFimJ3ldNY0uIf/vjJr7423VUNTRH+QhFREQGj4RoH0CscM7N7Srdb62f\nM8CHIzJoXH/WWGaPy+Ff/m8tWw/WAPCXjcVs3FfJg/90BrPydc0tIiJyomKppb6tVT07Qn5besUJ\nriMiA6xgRCbLv3AuH5k3rj1tT1kdH/yf1fzslZ3qjiMiInKCYimof89fRur/PsVfhvef7806IhIF\nqUlBvv2B03jgI2eQmez9SNjc6vivp7fwiUffpKRak1WJiIj0ViwF9S/6y4vM7IjjMrNMvDHn64DX\nwrJe8JcXd96YmU3EC/Z3401gJSIx4IrTR/P0LQuZld/xA9uL75Xw/ntX8Ow7B6J4ZCIiIvFrwIN6\nM0s0s2n+uPTtnHM7gGeBU4AvdFrtLiAdeMw5VxuW/jKwBVhkZleG7SMAfNd/+fCJjJ8vIn1v3FBv\ndJxPL5zQnlZW28RnuJyoaAAAIABJREFUHlvD157YSG2jxrQXERHpCeuLeNfMrgau9l+OBN6P1zr+\nip9W6pz7sl/2FGAXsNs5d0qn7UwCVuPNKrscL2A/G28M+63AOc65w53WORuvxT4RWAbsAc4HzsQb\n2/5851yvf9c3szVz5syZs2bNmt5uQkSOYeW2Ur78hw0cqGpoTxs/NI17rp/N3PFDonhkIiIiA2vu\n3LmsXbt2baQBXI6lr1rqZwM3+o/3+2kTw9Ku7c5G/Nb6M4FH8YL5LwGTgPuA+Z0Den+d14Gz8C4C\nLgJux7tB9lvAhScS0ItI/zt3yjCeuW0hl80a1Z62+3Ad1z28mnuefY/m1tAx1hYRERHoo5b6wUwt\n9SIDwznHn9bv5xt/eofqsO43s/Kz+cF1p1MwIjOKRyciItL/YqGlXkTkhJgZ15yRz99uW8jZE3Lb\n0zfuq+Ty+1fy4xe306JWexERkS4pqBeRmJI/JI3/+/R8/u2SaSQFva+optYQ3//7e1zz0GrePVAV\n5SMUERGJPQrqRSTmBAPGZxdP4ulbzuX0sR0zzm7aX8kVD6zkgee3qa+9iIhIGAX1IhKzpozI5Imb\n38fXLplGUoL3ddXc6vjhP7Zy9Y9XsblIrfYiIiKgoF5EYlxCMMDNiyfx11vOZXZYq/07RVVc+eBK\nvvfMuzQ0t0bxCEVERKJPQb2IxIXJeZk88blz+Pql00j2W+1bQo6HXtrB++9dwcptpVE+QhERkehR\nUC8icSMYMD6zaBJ/vXUh807pGCFn9+E6bvj569z+u/UcrtHUFCIicvJRUC8icWfS8Awe/8x8vv2B\n08hKSWhPf3Ldfs6/52V+/9ZeNAeHiIicTBTUi0hcCgSMj8wbx3NfWswVp49uT6+oa+aOZRv5yE9f\nY9vB6igeoYiIyMBRUC8icS0vM4UHPnIGj9x0FvlDUtvTX9tZxiX3vcJ//WUz1Q3NUTxCERGR/qeg\nXkQGhaVT83j29kV8dtFEggEDvBtpf7ZyF+f98GWeXLdPXXJERGTQUlAvIoNGWlIC/3bpdJ6+5Vzm\nTei4kbakupHbf7eB63/yqsa2FxGRQUlBvYgMOtNGZvG7z8znvg/PZkRWcnv6m4XlXP7AK3xz+dtU\n1qlLjoiIDB4K6kVkUDIzrpo9hue/tITPLppIgt8lJ+Tgl6/uZukPX+Kx13bT0hqK8pGKiIicOAX1\nIjKoZSR7XXKeuW0R504e1p5eVtvEf/7pbS6+7xVeePeg+tuLiEhcU1AvIieFyXkZPPbJeTx8wxzG\n5HSMkrP9UA2fePQtPvrzN9TfXkRE4paCehE5aZgZF88cxfNfWswdF08lI7lj4qqV20u57IFXuGPZ\nBg5WNUTxKEVERHpOQb2InHRSEoN8fslkXvrKEv757HH43e1xDn7/1j6WfP8l7n1uK7WNLdE9UBER\nkW5SUC8iJ61hGcncfc1pPHPbIpZMHd6eXt/cyr3PbWPx91/kkVW7aGxpjeJRioiIHJ+CehE56RWM\nyOTRm+bx2CfnMW1kZnt6aU0Td/15M+f94GX+8NZeWkO6mVZERGKTgnoREd/CKcN5+paFfO+DsxiV\nndKevr+inq8s28j7713B3zYVa6QcERGJOQrqRUTCBAPG9WeN5cUvL+E/LptObnpSe972QzV87jdr\nufLBVazYWqLgXkREYoaCehGRLqQkBvnUwomsuGMpt19QcMRIOZv2V/KxX7zB9T95lZXbShXci4hI\n1CmoFxE5hozkBG69YAor7ljKpxdOICmh42vzzcJybvj561z78Ku8rJZ7ERGJIgX1IiLdkJuexL9f\nNoOXv7KEj8wbR0LbOJjAmt3l3PiLN7jmodW8+O4hBfciIjLgFNSLiPTAqOxUvv2B09rHuE8MdgT3\n6/dWcNOjb3L1j1fx/JaDCu5FRGTAKKgXEemF/CFp3H3Nabz8laV87H3jSQp2fJ1u2FfJJ3/5Fpfe\nv5Ll6/fT0hqK4pGKiMjJQEG9iMgJGJ2TyreumsmKO5by8XNOOaLP/ZbiKm59fD1LfvASv1xdSH2T\nJrESEZH+oaBeRKQPjMxO4c4rT2XlHUv5xIIJpCYG2/P2ldfzzafeYcF3X+D+57dRUdcUxSMVEZHB\nSEG9iEgfystK4RtXzGDV187jtgumMCQtsT2vrLaJe/6xlXO+8wLf+vNm9lfUR/FIRURkMFFQLyLS\nD3LTk7jtggJWfe087rxiBmNyUtvz6ppa+cWqXSz63ot84TdrWbO7TDfViojICUk4fhEREemttKQE\nPr5gAv88fzxPbyzm4Zd38O6BagBaQ46nNxXz9KZiTs/P5hPnTuCSmaOO6JcvIiLSHfrPISIyABKD\nAa4+Ywx/u3Uhj9x0FgsmDz0if8O+Sm59fD0Lv/cCP35xO2W16ncvIiLdp5Z6EZEBZGYsnZrH0ql5\nvHugikdWFvLk+v00tXjDXh6sauT7f3+P+5/fxlWzR3PD/PHMys+J8lGLiEisM/XjPDYzWzNnzpw5\na9asifahiMggdbimkf97fQ+/em03JdWNR+XPys/mhrPHc8Xpo0lNCnaxBRERGQzmzp3L2rVr1zrn\n5vZ03T7rfmNm+Wb2CzMrMrNGMys0s3vNbEg3119iZq4bj7Gd1jtW2df66v2JiPSXoRnJfPH8Kaz6\n6nn86EOnM3NM1hH5G/dVcscTGzn7v5/jrj+/w/ZDNVE6UhERiVV90v3GzCYBq4E8YDnwLjAPuBW4\n2MwWOOcOH2czhcBdEfJOAz4AvO2c29tF/m7g0S7S9x334EVEYkRSQoBrzsjn6tljWLunnF+/toen\nNxW3d82pamjhkVWFPLKqkPkTc/no/FO46NQRJAZ1e5SIyMmur/rUP4QX0N/inHugLdHM7gFuB+4G\nbj7WBpxzhcCdXeWZ2W/9pz+NsHqhc67LdUVE4o2ZMXd8LnPH5/Kfl89g2Zq9/Ob1Pew+XNde5rWd\nZby2s4xhGUlcc8YYrj9zLFNGZEbxqEVEJJpOuE+930q/Ha+lfZJzLhSWlwkUAwbkOedqe7H9YXgt\n7iFgtHOuolO+A152zi3p7Xs4zv7Vp15Eoi4UcqzcXspvXt/Nc1sO0Ro6+rt79tgcrjsznytOH01W\nSmIXWxERkVh2In3q+6Klfqm/fDY8oAdwzlWb2SrgImA+8Hwvtn8jkAz8qnNAHybHzD4BjAQqgTXO\nOfWnF5FBIxAwFhUMZ1HBcIor63n8jb387s29HKhqaC+zfm8F6/dW8P/+splLZo7iurn5zJ84lEDA\nonjkIiIyEPoiqJ/qL7dGyN+GF9QX0Lug/tP+8ifHKHM68PPwBDPbAHzUObepOzsxs0hN8dO6s76I\nyEAZlZ3K7RcWcMv5U1ixrYRlb+3j2c0HaG71Wu8bmkM8uW4/T67bT/6QVK6d6/XTP2VYepSPXERE\n+ktfBPXZ/rIyQn5beo8HWjazxXgXDW8751ZHKHYP8ATeRUUDXhD+VeBa4AUzm+2c29/TfYuIxLpg\noGPM+7LaJpav38/v39rHluKq9jL7yuu597lt3PvcNk4fm8PVs0dz+azRDM9MjuKRi4hIX4v1yac+\n4y//N1IB59yXOiW9BVxnZsuADwJfxrtZ95gi9V3yW/DndOtoRUSiJDc9iZsWTOCmBRN4e38lf3hr\nL39aX0RlfXN7mQ17K9iwt4L/enoLCyYP45ozRnPRjJGkJ8f6vwIRETmevvgmb2uJz46Q35YeqT98\nl8wsFy8orwce68VxPeyvv6gX64qIxK2ZY7KZOSabf7t0Os9tOcif1hXx0nuHaPFvrm0NOVZsLWHF\n1hJSE9/mwhkjuGr2aBZOGU5SgobHFBGJR30R1L/nLwsi5E/xl5H63EfSdoPsL49xg+yxlPhLdSIV\nkZNSSmKQy2d53W3Ka5t4elMxy9fv583C8vYy9c2tPLWhiKc2FJGZksCFM0Zw2WmjOHfKMJITNHut\niEi86Iug/kV/eZGZBboY0nIBUAf0dDSathtkI3a9OY75/nJnL9cXERk0hqQnccP88dwwfzx7y+p4\nakMRy9fvZ+vBjtlpqxta+OPa/fxx7X4vwJ8+gktPG8XCAgX4IiKx7oSDeufcDjN7Fm+Emy8AD4Rl\n34XXUv6T8DHqzWyav+67XW3TzBYC0zn2DbKY2Sxgi3OuuYv0u/2Xv+7xmxIRGcTG5qbxhaWT+fyS\nSWwprmb5+v38ZWMx+yvq28tUN7Twx3X7+eO6/WQmJ3DBjBFcMnMkiwqGk5KoAF9EJNb01d1RnwdW\nA/eb2fnAFuBsvDHstwL/3qn8Fn8ZafDk494g6/tX4AozewXYCzTijX5zMRDEm4H2t5FXFxE5eZkZ\nM0ZnMWN0Fl+7ZBob91Xy103FPL2pmH3lYQF+Y0v7EJmpiUEWThnGhTNGcN60PIZmaBQdEZFYcMIz\nyrZvyGws8C28gHoo3kyyTwJ3OefKO5V1AM65o4J6MxsCFAGOLmaQ7VT2auBjwCwgD0gBDuONgPNT\n59xTffC+NKOsiJxUnHNs2l/J05uK+eumYvaW1XdZLmAwd/wQLpwxggtnjGSCxsEXETkhJzKjbJ8F\n9YOVgnoROZk553inqIqnNxXz93cOsLOkNmLZyXkZXDhjBBdMH8HssTkENZOtiEiPnEhQr8GJRUQk\nIjNrHyLzqxdPY0dJDc9tPsg/Nh9kzZ5ywtuFth+qYfuhGv7npR3kpiexcMowlkwdzqIpw9VNR0Sk\nnymoFxGRbps0PINJizP47OJJlNY08sKWQzy7+SArt5fQ0Nw++Jk/w20Ry9cXYQazxmSzeGoeiwuG\nqxVfRKQfKKgXEZFeGZaRzPVnjeX6s8ZS39TKyu2l/GPzAV54t4TSmsb2cs7Bhn2VbNhXyf3PbyMn\nLZGFU4azpGA4CwuGkZeZEsV3ISIyOCioFxGRE5aaFPRvmB1BKOTYXFzFy1tLeOm9Q6zdU0FrqKOf\nTkVdM3/eUMSfNxQBUDAig3MmDePcycM4e2IumSmJ0XobIiJxS0G9iIj0qUCgox/+F5ZOprKumZXb\nS3npvUO8vLWEQ9WNR5TferCGrQdreHR1IcGAcXp+NgsmD2PB5GGcMS5HE1+JiHSDgnoREelX2WmJ\nXDZrFJfNGoVzXiv+S++VsGJrCWv3lNPc2tGK3xpyrN1Twdo9FTzwwnZSEgPMmzCU900cyrwJuZw2\nJpukhEAU342ISGxSUC8iIgPGzDh1dDanjvZa8euaWnizsJzV20tZtaOUd4qqjhhRp6E5xIqt3gUA\nQGpikDnjc5h3ihfknzEuRzPcioigoF5ERKIoLSmBxQXDWVwwHIDy2iZe3XmYVdtLWbW9lMLDdUeU\nr29uZdX2w6zafhiAxKBxen4O8ybkMm9CLnPHD1GffBE5KSmoFxGRmDEkPYlLTxvFpaeNAmBfeR2r\ndxzmjV1lvLGrjD1lRwb5za2Ot3aX89buch56aQcBg+mjspgzbghzxucwZ9wQxuWmYaYhNEVkcFNQ\nLyIiMSt/SBrXn5nG9WeOBaC4sr49wH99VxnbD9UcUT7k4J2iKt4pquKx13YDMCwjidljO4L8WfnZ\npCXp35+IDC76VhMRkbgxKjuVq2aP4arZYwAorWnkrUIvwH9jVxmbi4/sk++VaeK5LQd5bstBAIIB\nY/qoTOaMG8IZ43KYlZ/DhKHpBDQhlojEMQX1IiISt4ZlJHPxzFFcPNPrrlPV0Mz6PRWs3VPO2j0V\nrNtTTnVDyxHrtIYcb++v4u39VfzqVa81PyM5gZljspiVn8NpY7KZlZ+tbjsiElcU1IuIyKCRlZLI\nooLhLPJvvA2FHDtKaljXHuiXs+1QzVGt+TWNLby2s4zXdpaFbSvBC/Lzs5k1JpvT8rMZk5OqQF9E\nYpKCehERGbQCAWPKiEymjMjk+rO8fvmV9c1s2OsF+Rv3VbJxXwWlNU1HrVvV0MLK7aWs3F7anpab\nnsT0UZnMGJXFdP8xOS+DxKDGzheR6FJQLyIiJ5Xs1CNb851zHKhqaA/wN+6rZNP+Sirqmo9at6y2\n6YghNQGSggEm52UwfVQWM0ZntQf9OWlJA/aeREQU1IuIyEnNzBiVncqo7FTef+pIwAv095XXe4H+\n/go2+YF+5/75AE2tITYXV7G5uIon1nakj85OYfqoLApGZlIwIoMpeZlMzsvQZFki0i8U1IuIiHRi\nZozNTWNsbhqXzfJuwg2FHHvL69hSXMXmoio2F1ezpbiK/RX1XW6jqLKBosoGnn/3UNh2YVxuGlPy\nvEC/YEQmU0ZkMGm4gn0ROTEK6kVERLohEDDGD01n/ND09tF2ACrrmtlyoKo92N9yoIqtB2poag0d\ntQ3nYPfhOnYfrmsfYhMg0Bbsj/CC/cl5GUwYlsHE4elkaYZcEekGBfUiIiInIDstkfkThzJ/4tD2\ntObWEDtLann3QBVbD1az9WAN2w5Ws7us7qiRd8CbNKvwcB2Fh+v4x+aDR+QNy0hioh/gTxiWzsTh\nGUwYls643DSSEnSDroh4FNSLiIj0scRggKkjM5k6MvOI9IbmVnaU1LDtYE1HsH+omj0Rgn3wJs8q\nrSnjjcKyI9KDAWNcbpoX6A9L5xQ/0B8/NI3ROakakUfkJKOgXkREZICkJAY5dXQ2p47OPiK9vskP\n9g95gf6uklp2ltZQWFrXZTce8CbR2lVay67SWl7olBcMGKNzUhifm87Y3LT2YH9cbhrjhqapS4/I\nIKSgXkREJMpSk4LMHJPNzDFHBvutIUdRRT07SmrYVVrLzpJaf1lDUWVDxO21hhx7y+rZW9b1Tbw5\naYmM928EHpebxpghqYzOSSU/J5UxQ1JJS1J4IBJv9KkVERGJUcFAxyg8S6YemVff1NreUr+zpIbd\nZXXsOVzHnrI6DlRFDvgBKuqaqairZMO+yi7zc9ISGZOTypgcP9j3g/4xftA/ND1JM+uKxBgF9SIi\nInEoNSnIjNHehFedNTS3sq/cG2VnT5m33FtW5wX+ZXU0tXTdpaeNF/Q3805RVZf5yQmB9oB/RFYK\nI7OTGZmV4j9PYWRWCkMzkgkGFPiLDBQF9SIiIoNMSmKQyXmZTM7LPCovFHIcqm70g/1a9pXXs7+i\nnv3l9RRV1lNUUU9za4S7dn2NLSF2ltays7Q2YplgwMjLTPYCfT/Yb7sAGOFfAORlJpORnKBWf5E+\noKBeRETkJBIImNeanp3CvAm5R+WHQo7Smkb2tQX6FV7QX1RR334B0NXMup21hhzFlQ0UH6PvP0BK\nYoBhGckMz0w+ajk8I+mI1+rrLxKZPh0iIiLSLhAw8rJSyMtKYc64IV2WqWpopqiinuKKBg5UNXCg\nsoGDVUc+L69r7tb+GppD7Cv3LhiOJy0p2BHkZyQzNCOJ3PQkhqQlMTTDW+amJzEkPYmh6UmapVdO\nKgrqRUREpEeyUhLJGpnItJFH9+dv09DcyqGqRi/Qr2rgYKW/rOq4ACipbqSh+dj9+8PVNbW2z8jb\nHamJQT/IT/QCfz/gz03rCPxz0pLITk0kOy2RnNRE0pKC6g4kcUlBvYiIiPS5lMQg44Z64+JH4pyj\ntqmVkupGSmsau1yW1DRRWt1ISU3jcW/w7ay+udW7X6Di+L8CtEkImBfkpyaSlZpITlpi++suH35+\nTmoSKYkBXRBI1CioFxERkagwMzKSE8hITmDCsPRjlnXOUdXQ0hHsVzdSXtfE4ZomyuuaKKttOur1\n8W747UpLyHG4tonDtU09XjcpGCAzJYGMlIT295WZkuilJSe052Umty0T28tmpXQ8T0rQbMDScwrq\nRUREJOaZdbSgTxqecdzybb8ClNU0UVbXRHmtF+iX1R75uryuicr65vZHT7oDddbUGur1BUG4pIQA\nWX6An56cQFpSkLSkBNKTvWX766QgqUnB9jLpbXnJXl5acgJpiUHSkoMkBfUrwmCnoF5EREQGnfBf\nAY7VBaizxpZWL8Cvaz4i2G97VNQ1U9U5zV/2tHtQJE0tIUprmiitObGLg3AJAfMuAJISSEsOkpYU\nJCUhSEpi2yNAaqfnyf7rVD+t7Xly2PPO+ckJuniIFgX1IiIiIr7khCB5mUHyMlN6vG5DcyvVDS3U\nNLZQ09BCdUMz1f7zmsYjX4eXq2po9p43eumtoZ53GzqelpCj2t9vfwsP8JMSAiQFAyQnBL3nCQGS\n/Yf33PsVISksLSk8LyFAcjBAcmIgrNyR2+rYR4DEYIDEhACJQSMxECBwEk2ApqBeREREpA+0tXoP\nz0zu9TacczQ0h6hubKa6oYW6xlbqmlqoa2qltqnjdW1TR3pdo58Xllbb2EJ9Uyu1/vOWfrhQiKSh\nOXRC3Zj6UjBgXoAf9AL/hLDn3gWAkRDwXyd4eW35Y4ak8vVLp0f7LXSbgnoRERGRGGHmdZNJTQrS\nxYTAvdbUEvKD/Jb2wN8Lvlupb26lobmVxuZQ+/OGsOeNLa3Ut5Vve94SojFs3bbyfdUFqa+0hhyt\nIderi4xpIzMV1IuIiIhI7GjrrpKdltiv+wmFHI0tHQF+U0uIxpZWGltCNLWGaGz2lm3pHWW8ZVOr\n97zLvLb01q7SvXWbW0O0tLr2MiciMRhfoxD1WVBvZvnAt4CLgaFAMfAn4C7nXHk3t/ESsPgYRVKd\nc0fNN21mM4A7gSVAFrAbeBz4jnOu+4PTioiIiEivBQIdvzREm3NeK32zH+S3BfzNrR0XAM0tHXnh\nFwTNrSEykuOr7btPjtbMJgGrgTxgOfAuMA+4FbjYzBY45w73YJN3RUg/6u4OMzsbeAFIBJYBe4Hz\ngG8A55vZ+c65xh7sW0RERETinJmREDQSgpBK9C8y+ltfXYI8hBfQ3+Kce6At0czuAW4H7gZu7u7G\nnHN3dqecmQWBR4A04Crn3FN+egD4PfBBf//f6e6+RURERETizQl3FvJb6S8CCoEfd8r+JlALfNTM\njj1VXO8sBqYDK9oCegDnXAi4w395s2nAVBEREREZxPriDoCl/vJZP5hu55yrBlbhtaTP7+4GzexD\nZvY1M/tXM7vEzCKNDXWev3ymc4ZzbiewFRgPTOzuvkVERERE4k1fdL+Z6i+3RsjfhteSXwA8381t\nPt7p9SEz+4Jzblkv9l3gP3Yca4dmtiZC1rRjrSciIiIiEm190VKf7S8rI+S3ped0Y1vLgSuAfCAV\nL6D+tr/u78zs4n7ct4iIiIhIXIqpsXqccz/qlPQe8HUzKwIewAvwj+pq00f7nttVut+CP6c/9iki\nIiIi0hf6oqW+rTU8O0J+W3rFCezjZ3jDWc42s/D51QZi3yIiIiIiMa0vgvr3/GVBhPwp/jJSv/fj\n8iecqvZfho+i0+/7FhERERGJdX0R1L/oLy/yx4dv57eqLwDqgNd6uwMzmwoMwQvsS8OyXvCXnfva\nY2YT8YL93cDO3u5bRERERCTWnXBQ75zbATwLnAJ8oVP2XXgt648552rbEs1smpkdMaqMmU0ws9zO\n2zez4XgTTAE87pwLn1X2ZWALsMjMrgxbJwB813/5sHPO9ea9iYiIiIjEg766UfbzwGrgfjM7Hy/Q\nPhtvDPutwL93Kr/FX4ZPCrUYeNjMVuK1rJcB44BL8frGv0XHhFIAOOdazewmvBb7ZWa2DNgDnA+c\niTdGfuebb0VEREREBpU+CeqdczvM7EzgW3hdYS4FioH7gLucc+Xd2MwavPHp5wJnAFl43W02Ab8H\nfuKca+pi36+b2Vl4vwpcBGTidbn5FvAd51zjCb49EREREZGY1mdDWjrn9gI3dbOsdZG2Cfh4L/e9\nGbiuN+uKiIiIiMS7vrhRVkREREREokhBvYiIiIhInFNQLyIiIiIS50yjPR6bmR1OTU3NnT59erQP\nRUREREQGsS1btlBfX1/mnBva03UV1B+Hme3CG4mnMAq7bxvL/90o7Fu6pjqJTaqX2KM6iU2ql9ik\neok90aqTU4Aq59yEnq6ooD6GmdkaAOfc3Ggfi3hUJ7FJ9RJ7VCexSfUSm1QvsSce60R96kVERERE\n4pyCehERERGROKegXkREREQkzimoFxERERGJcwrqRURERETinEa/ERERERGJc2qpFxERERGJcwrq\nRURERETinIJ6EREREZE4p6BeRERERCTOKagXEREREYlzCupFREREROKcgnoRERERkTinoD4GmVm+\nmf3CzIrMrNHMCs3sXjMbEu1ji3dmdq2ZPWBmr5hZlZk5M/v1cdY5x8z+amZlZlZvZhvN7DYzCx5j\nncvN7CUzqzSzGjN73cxu7Pt3FP/MbKiZfcrMnjSz7f45rjSzlWb2STPr8ntK9dL/zOy7Zva8me31\nz3GZma0zs2+a2dAI66heBpiZ3eB/lzkz+1SEMj0+x2Z2o5m94Zev9Ne/vH/eRXzz/0+7CI8DEdbR\nZ2UAmNn5/v+XA35MVWRmfzezS7soG9d1osmnYoyZTQJWA3nAcuBdYB6wFHgPWOCcOxy9I4xvZrYe\nOB2oAfYB04DfOOduiFD+KuAJoAH4HVAGXAFMBZY5567rYp1/AR4ADvvrNAHXAvnAD51zX+7jtxXX\nzOxm4H+AYuBFYA8wAvgAkI13/q9zYV9WqpeBYWZNwFpgM3AISAfmA2cCRcB859zesPKqlwFmZmOB\nTUAQyAA+7Zz7WacyPT7HZvYD4Et435PLgCTgw0Au8EXn3IP99Z7ikZkVAjnAvV1k1zjnftCpvD4r\nA8DMvgd8Be/v+G9AKTAcmAs855y7I6xs/NeJc06PGHoAfwcc3pdmePo9fvrD0T7GeH7gXRxNAQxY\n4p/TX0com4UXyDQCZ4alp+BdeDngw53WOQXvC+EwcEpY+hBgu7/O+6J9HmLpAZyH98UZ6JQ+Ei/A\nd8AHVS9RqZuUCOl3++fsIdVLVOvHgOeAHcD3/fP1qRM9x8A5fvp2YEinbR32t3dKf72veHwAhUBh\nN8vqszIwdfJp/7w8CiR1kZ842OpE3W9iiN9KfxHel8OPO2V/E6gFPmpm6QN8aIOGc+5F59w253/y\njuNavCv6x52CSGZmAAAGkElEQVRzb4VtowH4D//l5zqt8wkgGXjQOVcYtk458N/+y5t7efiDknPu\nBefcn51zoU7pB4CH/ZdLwrJULwPEP6dd+b2/nBKWpnoZeLfgXRTfhPf/oSu9Ocdtr+/2y7WtU4j3\nvynZ36f0jj4r/czMkvEaH/YAn3HONXUu45xrDns5KOpEQX1sWeovn+0iwKkGVgFpeD9/S/87z18+\n00XeCqAOOMf/8ujOOn/rVEaOr+1LtyUsTfUSfVf4y41haaqXAWRm04HvAPc551Yco2hvzrHqpXeS\n/fsbvm5mt5rZ0gh9sfVZ6X8X4gXpfwRCZnaZmX3Vr5f3dVF+UNRJwkDuTI5rqr/cGiF/G15LfgHw\n/IAc0cktYn0451rMbBdwKjAR2NKNdYrNrBbIN7M051xdPxzzoGFmCcDH/JfhX5qqlwFmZl/G66+d\njdef/ly8gP47YcVULwPE/2w8htcK+fXjFO/ROfZ/CR6D1w+8uIvtbfOXBb07+kFtJF69hNtlZjc5\n514OS9Nnpf+d5S8bgHXAzPBMM1sBXOucK/GTBkWdqKU+tmT7y8oI+W3pOQNwLNK7+ujuOtkR8qXD\nd/C+iP/qnPt7WLrqZeB9Ga8L4G14Af0zwEVh/xBB9TKQvgGcAXzcOVd/nLI9Pcf6P9Q7jwDn4wX2\n6cBpwE/w+l3/zcxODyurz0r/y/OXX8Hr274QyARmAc8Ci4A/hJUfFHWioF5EYo6Z3YI38sa7wEej\nfDgnPefcSOec4QUsH8BrrVpnZnOie2QnHzM7G691/ofOuVejfTzicc7d5d8fdNA5V+ece9s5dzPe\nIBepwJ3RPcKTTlt82wJc6Zxb6Zyrcc5tAq7BGw1ncYSuOHFLQX1sOd5VXVt6xQAci/SuPrq7TqQr\n+5OeP0TYfXjDKC51zpV1KqJ6iRI/YHkSrxvgUOBXYdmql37md7v5Fd7P/f/ZzdV6eo71f6hvtd3s\nvygsTZ+V/td27taF38QK4HeFafv1d56/HBR1oqA+trznLyP1VWwbaSJSn3vpWxHrw//nOgGvFWBn\nN9cZhfez7D71eeyamd2GN+bv23gBfVeTtqheosw5txvvoutUMxvmJ6te+l8G3rmaDjSET3CE1z0K\n4Kd+Wtt46T06x865WmA/kOHnd6b/Qz3T1kUtfNQ6fVb6X9v5inTx2TaqU2qn8nFdJwrqY8uL/vIi\n6zSLppllAgvw7sB+baAP7CT1gr+8uIu8RXgjEa12zjV2c51LOpWRMGb2VeBHwHq8gP5QhKKql9gw\n2l+2+kvVS/9rBH4e4bHOL7PSf93WNac351j10nfaRqsLDwb1Wel/z+P1pZ/ROZ7ytd04u8tfDo46\nGchB8fU4/gNNPjWQ53oJx598qoSeTUYxgRibjCIeHnhdCRzwFpB7nLKql4GpkwIgu4v0AB2TT61S\nvcTGA6/PdleTT/X4HKPJp3p67qcD6V2kn4I3WpADvh6Wrs/KwNTLcv+83N4p/SIghNdanz2Y6sT8\nA5AY4U9AtRrvzu3leEMnnY03hv1W4Bzn3OHoHWF8M7Orgav9lyOB9+O1oLzip5W6sGmd/fLL8D64\nj+NNG30l/rTRwPWu04fIzL4I3E+sTBsd48zsRrwZ/1rxut501f+w0Dn3aNg6qpd+5neF+jZey+8u\nvPM2AliMd6PsAeB859zmsHVUL1FiZnfidcH5tHPuZ53yenyOzeyHwL/i3VC4DEgCPoR3L8UXnXMP\n9tubiTP+uf8S3njmu4FqYBJwGV5Q+FfgGhc2AZI+K/3PzPLx4qmxeC336/AC8avpCNKfCCsf/3US\n7SspPY5+4P0BPgIU+38gu4F7CWsx0aPX5/ZOvA9zpEdhF+sswPtSLgfqgU3A7UDwGPu5AngZ78u9\nFngTuDHa7z8WH92oEwe8pHoZ8HqZCTyI1x2qFK8/aaV/zu4kwi8qqpeo1Vfb5+hTEfJ7fI6Bj/vl\nav31XgYuj/Z7jbUH3oXub/FG66rAmzSvBPgH3lwbFmE9fVb6v26G4zUW7caLp0qBJ4F5g7FO1FIv\nIiIiIhLndKOsiIiIiEicU1AvIiIiIhLnFNSLiIiIiMQ5BfUiIiIiInFOQb2IiIiISJxTUC8iIiIi\nEucU1IuIiIiIxDkF9SIiIiIicU5BvYiIiIhInFNQLyIiIiIS5xTUi4iIiIjEOQX1IiIiIiJxTkG9\niIiIiEicU1AvIiIiIhLnFNSLiIiIiMQ5BfUiIiIiInFOQb2IiIiISJz7//m6gSykUp8TAAAAAElF\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 378,
              "height": 258
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CujEd28wk334",
        "colab_type": "code",
        "outputId": "49e47936-a9db-4e5c-aca8-5062447b1371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "  enc.eval()\n",
        "  enc.to(device)\n",
        "  time_embedding = time.time()\n",
        "  \n",
        "  z = enc(X)    \n",
        "  # std = torch.exp( z_var/2 ).cuda()\n",
        "  # eps = torch.ones(std.shape).cuda()\n",
        "  # z_sample = eps.mul(std).add_(z_mu)\n",
        "  z = z.cpu()\n",
        "  for i in range(len(X)):\n",
        "    plt.scatter(z[i][0], z[i][1], c=colors[int(labels[i][0].item())])\n",
        "  print(f'done time elapsed = {time.time()-time_embedding:.2f}s')\n",
        "  plt.xlabel('Latent space dimension 0')\n",
        "  plt.ylabel('Latent space dimension 1')\n",
        "  plt.title('Encoding Visualized wrt ground truth labels')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done time elapsed = 63.44s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzwAAAIqCAYAAADhDk/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAx5JkiRJA8uAR5IkSdLA+v+ytMzL0Oi/8QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 414,
              "height": 277
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUZB_BDZlWe0",
        "colab_type": "code",
        "outputId": "16fbfb1e-8f91-4488-f14f-3c57c2cbafc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred = torch.argmax(z.type(torch.LongTensor), dim = 1)\n",
        "a = 1 - y_pred.type(torch.ByteTensor).cpu()\n",
        "labels = labels.cpu()\n",
        "accuracy = torch.mean((y_pred==labels).type(torch.FloatTensor))\n",
        "print(f'accuracy = {(accuracy/len(X)*100):.3f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy = 0.005%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRKi5iEfoQ0o",
        "colab_type": "code",
        "outputId": "9e291bd7-f4ae-4f48-9d05-a0ea85b89c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "1/torch.mean(a.type(torch.FloatTensor))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10002.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmwwBFVF4c0x",
        "colab_type": "code",
        "outputId": "53555a86-94e7-4fba-d56f-86a7253bf1ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.mean(y_pred.type(torch.FloatTensor))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9999)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPCZaR71oD30",
        "colab_type": "code",
        "outputId": "88e892c3-00d6-4517-f172-a8d59c39775c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "  # enc.eval()\n",
        "  # enc.to(device)\n",
        "  time_embedding = time.time()\n",
        "\n",
        "  # z = enc(X)    \n",
        "  # std = torch.exp( z_var/2 ).cuda()\n",
        "  # eps = torch.ones(std.shape).cuda()\n",
        "  # z_sample = eps.mul(std).add_(z_mu)\n",
        "  for i in range(len(X)):\n",
        "    plt.scatter(z[i][0], z[i][1], c=colors[int(y_pred[i].item())])\n",
        "  print(f'done time elapsed = {time.time()-time_embedding:.2f}s')\n",
        "  plt.xlabel('Latent space dimension 0')\n",
        "  plt.ylabel('Latent space dimension 1')\n",
        "  plt.title('Encoding Visualized wrt directly predicted outputs')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done time elapsed = 61.51s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzwAAAIqCAYAAADhDk/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkgaWAY8kSZKkgfX/A4nKl00XK50bAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 414,
              "height": 277
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqNVuC0R4bEa",
        "colab_type": "code",
        "outputId": "7ea5d0f6-ad24-4f53-e57e-4d53f0f367a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10002, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laVnANzpoghv",
        "colab_type": "code",
        "outputId": "1e675e5c-a45b-44ee-ad14-c21223e5e52a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "kmeans_auto =  KMeans(n_clusters = 2, random_state = 42)\n",
        "km = kmeans_auto.fit(z)\n",
        "kmeans_pred_label = km.labels_\n",
        "with torch.no_grad():\n",
        "  # enc.eval()\n",
        "  # enc.to(device)\n",
        "  time_embedding = time.time()\n",
        "\n",
        "  # z = enc(X)    \n",
        "  # std = torch.exp( z_var/2 ).cuda()\n",
        "  # eps = torch.ones(std.shape).cuda()\n",
        "  # z_sample = eps.mul(std).add_(z_mu)\n",
        "  for i in range(len(X)):\n",
        "    plt.scatter(z[i][0], z[i][1], c=colors[int(kmeans_pred_label[i].item())])\n",
        "  print(f'done time elapsed = {time.time()-time_embedding:.2f}s')\n",
        "  plt.xlabel('Latent space dimension 0')\n",
        "  plt.ylabel('Latent space dimension 1')\n",
        "  plt.title('Encoding Visualized wrt kmeans predicted outputs')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done time elapsed = 60.27s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzwAAAIqCAYAAADhDk/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdebwkVXnw8d/DDDAwwjAsitHAgAsg\nyg4iKlwBlYiIUUgwKPKaaPTN5gIxCSqocY/yaowacRkXIggqaMQNxgEUUcCAYBBlGTZxgYFhh5nh\nef841d6anu6+3ffWvX3n3t/387mful11Tp3TVdXV9XSdcyoyE0mSJEmaidYbdgUkSZIkabIY8EiS\nJEmasQx4JEmSJM1YBjySJEmSZiwDHkmSJEkzlgGPJEmSpBnLgEeSJEnSjGXAI0mSJGnGMuCRJEmS\nNGMZ8EiSJEmasQx4JEmSJM1YBjySJEmSZiwDHkmSJEkzlgGPNIkiYmlEZEQc2zZ/pJq/bDg1m3oz\n4T33eg8RsbhadtLU12wwVT0zIhYNuy5TISKOrd7v0mHXRTNLRCyrjq2Rtvkz7piLiJOq97R42HWR\nBmXAo8bVLvz6+Xv9sOur3mpfcndGxIZ95jm0to93nOw6auaKiN2qY/DYYddFGpbqx5aTIuLFw67L\numK6b7OIeHFVv5Fh12U2MODRZFoJ/HaMv/uGVrvhuh+4Brhu2BXpw+eBBDYDDuszzzHV9CeZ+Yvq\n/3XpPY/HbZT3d/uwKzLD7AacCBw75HpIg1hBOR/c1ND6Riifg2l58T5NjTC9t9mLKfUbGXI9ZoW5\nw66AZrSLMnNk2JWYjjLzJ8A6cecjM6+PiB8Az6YEMmf2Sh8RC4AXVS8/V1vPOvOexyMz/xn452HX\nQ9LwZebXgK8Nux6SCu/wSOpHK3A5JCK2HCPtnwHzgIeB0ya1VpIkSWMw4NG0Uu/kHxEbVe1br4mI\nByLidxFxWkQ8aYx1bBERb4+IyyLiroi4PyJ+WeXteGs7Ih4TER+MiF9U6VdExE8i4k1j9VuJiEMi\nYkmV5+6IuDgiXjFGnl6d35vYBi+MiO+31emV7evvtY42ZwAPAOsDLxsjbas52zcyc3mf73m96v1+\nPyLuiIiVEfH7iPh5RHwmIg5pSz9mh+BeHWwj4skR8bZqv90QEQ9Wx8rF1T7faIz32Km8joMWDNCf\nbaTDOreKiPdExJURcW9E3BcRV0XEuyJi8x51WS8i/i4irqiOm99HxDci4hmDvq9qfRtUn4uMiJ07\nLP9G7X08psPyH7Ufc+37MCKOjojzq/2fUdq3J/DZKssB/Wyzcb6/V1TH3CMR8bra/D/s02obvCUi\nrq62xU0R8ZGIWFhLv2dEfDUiflNt90tijP4D1Xr/NiIujIjlEfFQRNxYHfc7dcmzYUQcGRGfr/bx\n7dUxfGNEnBoRe/Yo7w+d7CNi84j4UPUZeCgibo2IUyLisV3yDvQ5HUvb9p0X5bz9ixg9130pIp7c\nJe+Yx09b+kdFxL9U+2RFtb1+Ve3DPx6jnkdHOTfcW+2jJRFx6Bh5+jlH7RQRn4jy/XR/lHPQlVWd\n9qzSLKo+BydW2V7Z4XOwqMO6D4uIs6tj8eFqe34jIp4/Rr13qLb776r98IuIODH67L85xrqfEBH/\nGRHXV9v/zoi4ICL+KiLmdMnTcVCItjRrbIdBtlkrbZWeiHhmRPx3dVzfHxGXR/l8drxe7rUPOq2/\nmjdSvX5lNevE9vq1rWO7iPh4dZw8UNXrxijf5f8cY/8IKYDM9M+/Rv+AxZQ+H0vHkXdplffvgZ9W\n/z9I6f+R1d8dwBO65H82pQ9FK+1DVfpVrXkd8uxTpWnluZtycd96fTnw6C7lHV9L9whwJ7C6ev3B\n2vs5ti3fSDV/2SRsg7f0qNPJ3erUx745tcp3SY8021VlJnDYAO/51FqdE7ir2net1xe3pT92rGMM\nOKlKs7jDsktr636g2p6P1OZdAmzSIV+v97C4WnZS2/zf9PirH3cjbfme1bb8obbj8iZghw71mAuc\nVUu3sjoGWv+/pLZs0QD7f0mV53Vt89errT+BI9uWz6/KTWC7TvsQ+Ej1/2pgeTV9cbWNVlTLHu6w\n/fbrs+5djxfgb6p9vxJ4eZd9+m7ggtrxUt8Pl1DuaB5O+Zw+Qjl+65/BP+tSr8dSzi+ttKsp55/6\nsfmSDvle2Lb+5W11Wgm8okuZy6o0L6/9f19V91b+G4CFE/2c9rFfWtv3PcCPGD3OV9TWeR+wf699\n2u34qaXdqfZeW9vn3trr5cAzu9Txo237505GzxV/X1tv++e36zFXLf87at9LVX3qn6OlVbo/phzr\nrfo+wNqfgz+urXd94Itt+2lF2+v3danT/tX2rudr7d+LKJ+DjufUPvb1C1nzGL2L8pluvf4eML/H\n8TrSY91rnM8G2WbAolr+lzJ6rrqz9n9SmifOHavsDsv/sP7avP2qOrS2x73t9aul3YM1zwkPtx0n\nCRwy6P6YjX9Dr4B/M++PZgKeOylfus8H5lAuqp4N3Fwt/3KHvE+ondj/B3gOMKdathHwXOArbXkW\nAr+u8vwM2LuaPwc4gvJFmMD3OpT3LEa/+L4AbF3N3wx4X+2knowv4BnPNjiwdhL8DFWgBiwA3tmr\nTn3sm+fV1r1jlzQnVst/2/7l0O09U75kk/Ll/3qqQAMIygXhK4F/a8tz7FjHGL0Dnv8A/hLYtjZv\nQ8qgDNdU+f6jQ75e+20xHQKeMbbpl6o8NwNb1uZvy+iX2seAJ1b7fz3gqcB3qmU/pzrGa3lPYPTi\n7Dhg42r+dsC3WPNifNEAdW1tz9Pa5u9ezW99KX+0bflzq/k3ddmH91A+R28DNquWbVo7dsfc133U\nveM6atvqQeDwHvv0LsqgFIdW+2AOJcBpvef3Vmk+zeh5YCtGA89fs/bnYX3gJ9Xyc4FnAOtXyx5L\n+XEiKRegT2jLOwJ8mHI+2Lg2f5tavgeAbTq8p2WMnl/+B3hGNX8upe9d67h7/0Q/p33sl/r2vQ94\nRW0b7AZcVi3/DW0B2ADHzwLKeTSBLwO7MPq9sD2jQdxvWvlrZRzN6GflA7X1P4bSzPdhRgOEkX7P\nUcCRtfWeAexUW7Z5Ve4H+z2ftaVr7f9fVeXMr+ZvAryO0WP2ZW35FlLO21lt911rx+kx1fu8q586\ndKjTExgNPpZS/VBDOee+htFg+1M9jteRHuvveD7rZ5uxZsBzF+UcuV21bD7lR83WD4b/0m/Zndbf\n4/g/qUf9Wj80XQzsXpu/MbBXtb+fMcj+mK1/Q6+AfzPvr/Yh7vSLbPvfpm15l1Z57wee2GHdL2X0\nAmWDtmVfrpZdQ4df57vU9a2Mfvlv3WF5/SL/wLZl51XzlwDRIe+nanmPbVs2wtgBz3i2wfnVsu90\nqdPHutWpj221HnBLlffdXdJcWy0/ucOyju8Z+Mdq/rcGqMuxTCDgGWPd21F+2buP2sVkH/utddyf\n1Gc5/1Tbz3u2LWv9QvueLnk3AK6o0hxRmz+f0QuatepBucD4ee0YWDTAdnlOlee2tvmvb9WVcmFw\nZdvyf62Wf6HLPux6PPW7r8dzvFAuYJNyIXZQl3yLa3U8oMPyt9aWL+mwvL4/9m9b9lfV/AuoLvI7\n5P8EHYLIPt7vp6t8J3ZYtozRC/wtOix/U7X8+rb5A39O+6hnffse3WH5lozesX/LOI+f1vH3Xz3S\nfKtKc1xtXjB6PlvcIU9Q7kq06jDSz3FLCSBuGatOHco7qVtdammeRAn+fkftrk9bmqOq9VzV5Vi+\nndqPL7XlL6+91651GON4vJa2c2q1/DXV8kdo+85jagOeq4ANe2z7Fe3171Z2p/X3OP5P6lG/VsuO\np4/nM+bf6J99eDSZ1qf8Etbrr9sxeGZmXtth/tcpH/4NKb96A6V9NvCn1cu3ZeY9fdbxiGr6qcz8\nTfvCzPwupakFlM74rfI2p1wAQmkekB3W/e4+69DNoNtgS8qvsFB+ne1Up/eNtzKZ+QjlQhzg6IiI\n+vKIeCbllzwoQ1n36+5q+uhu7aSnUmbeQAkKNqb8yty4qv3/u6qXf5mZl9WWbUz5ZfYR4ENd6vgw\no6PlPbe26HmUX3Ifovzy157vIeDfxlntiyk/Ymzd1q/igGr6NcoFw84RsUWH5ed3We9qurzPyRCl\nH8oplLtfdwHPzczzxsj2o8zsVP9za/+/p31hZt5H2W5Q7szVvbKafjgzV3Yp99Rq+twuy7v5RjV9\nZo80n8zMOzrMP6uabhcR82vzJ/NzeiPwX+0zM/N24D+rl0e0L6+Mdfy0tvMHe6RplV3fzrsxej7r\ntG+T8Z3jDwIeR6n38ePI38sxlEDs9My8uUuaMynnh51jzb5are17SrXd251K2U8Dqb4nXlq9PDkz\n7++Q7FPArVXdu+3nqfDB6hzZ7kOUHxg3pZxjp1Lrc9exX536N/SLC81o52dmjPF3V5e8l3SaWV0Y\n/K56ubC2aC9Kk4wEvt1P5SJiA0YvQr7fI+mSarpHbd7ulJPzI8APutT1ekpTpfEadBu0Ls4fobS3\n7pT3Rib2XIjF1XQb1n52QGuwgisz838GWOd5lAvpPYClEfHyiPijCdSxLxHx3Kpz7nUx2iG/1WF0\n1ypZ4/WI8iDW/6Kcf9+bmV9qS7In5Q5OAFdWnY7X+qNcsENpr97SOkYvz8wVXarQLfDoKTMfYPSY\nPKB6L0FpVnUPpb/Z+VW996+Wb0TpI9er3Gu7XGBNhvUpzQj/ivIZGsnMH/XOAsCVXeb/rvb/VV3S\n/Laa1gc3mMvodvnPHvv4q1WatTrVRxlw4K0RcVGUjvqrasdvazjkXsdvx/ML5cKzZbPa/5P5OT2/\nyw80MHrcPLU6Z7frevxEGYzg8dXLc3ps5w9XaTp9ln6bmdd0qdtFlCZ+g9i3ml6Rmbf2TDm4/arp\nK3u811sonwOo3m+1XVuDkXT8nFb754Jx1Gl7SrNC6PI9W/2YtrR6uUenNFNkaaeZmXk3pfknTH39\nzqmmn4+I90bEvhGxfs8c6sjn8Gi66nWH5sFqWv/Qt0aGWtHjQq/d5owG/b2+eG6pplvV5rX+X1H9\nitvNrXS4WOnToNugNVLLiuritJtfUwKWgWXmLyLiJ5SLtWOovsCijODTugP2uS7Zu63zV1FGxvoo\n5eL52dU6l1GC108OGECNKSI+Quk03LKS0l+r9Uv75pRtO58GRcRmwNmUXwr/m9KHpF3rl7xg9Lju\nZePa/63j8tc90k/kIut8yl2DA4BTKD8YbAF8OzNXRcT5lO16AOWie19K8HZbZv6qyzp/P4H6DGq/\n2v9HZOYVfea7rcv81a1/MnOsNPXP6uaU7QJl+41ljVEDI+IplB9i6sfHPYx2gt6AEmD1On47nl8y\n88Hazdv1a/Mn83Pa65hsLZvDaD+Tul7HT/1X8Uf3UY+BPkuZ+VBE3A5s3ce6W1r7rKkHkta13u8m\n1d9YWu93c8r2hebPHfXvzUG/Z6daP8fhVNfveGAHyrnrzdXfgxHxI0r/r8VjfN+r4h0eqZg37Aqs\nQ1oBzUur5ldQOjtvRrm4O7Vjrh4y8zOUvjOvpwQEd1DaPr8WuCwi/mWCdf6DiPgTykX5akrb7CdS\n2m1vkZlbZ+bWwI9byRssdz3K3YUnA1dT+iw80iFp67y8oo87pJFT+3Df1i+8B7RNzx9jea9fhlf3\nWNa0K4H/rf7/2BCHc61/9+7ez35uy/9ZyoXzT4FDKH0WN83Mx1TH75FVusaOX5jaz+kAeh0/9e28\nsI/tvGiS6zrZWu/3DX2eO5ZOcf38nh1Q1ez0WZTmlh+h3GnagNKk/mPAVRHx+O5rUIsBj2aK1q9+\nCyJiQc+Uo5ZTmn9B7zserZNJ/ZfE1v8Lahf9nUx606yaVrOOBdH7OTITbQt8GqVpyyaUoYNhtDnb\ndzr1hepHZv42Mz+cmS+m/Iq2D+UuQQDvjIhdaslbzUh6fYF2Ow5aF4Ofysy3Z+Z1HZrT9HNnZVDv\no1yc3gm8qGom0UnrWN50gGO5pXVc9jruJnJM/pCy7R8fEdszGtAsBcjM31MCil2qu1lj9d+Zassp\nfSiuodyd+l7UnqMzhe5g9EJ9oLutEbEN5bOxmnIcfScz721LNhnHLzDw57Rf/RyvrSGhB1G/GzTo\nXe0xP0tVU7BBg+ZWnbYdMN8g6x70vbaG8obmzx31781Bv2dhjHP9OM6RvfTz3tvr19pu3b6LJly/\nLM7NzH/IzD0ox9xfU/bb9nTor6m1GfBopriUcmIM4E/6yVB1/G61u39Oj6QHVtOf1ub9D6XpyHqU\nX1/WEhHbMc6mY+N0eTVdjzWb7vxBdbE0oS/aLA8TbXWKPiYitqJcyMOAzdl6lJGZeQklOLmFtbdz\nq+9Xr1+29u4yv5WnY/ObiNiW2mAQTYiIoyl9blYDR2XnwSha6sfyQA9yZPQY3S0iNu2S5oAu88dU\nXVi3ttsIo8/tuLSW7ALK/jqY0f4KEwl4Wj9KNHK3ogrIDwKuo/R7+27DF0391GElo9usr/NVzR8u\nDHv0ATl4XBUbUB+f0371OiZby66qztmD1O8GRoOAQbdz67P0mOjy8FPKeXbQrgGtQSx2iYjHDZCv\nn89Bqz/aQOeNarv+vHq5f6c0VX+9jsvGcD2j5+uO37PV3e+R6uVP2xaPda7vdp6Hwc8dHY/DiNiE\n0b47w6wfAJl5Z2Z+EmjdUR33OX02MeDRjFBdiLU66r69OkH1ozXS1bHR4eniEfE8yvMxoAx73Spv\nOaODGfxj+4hllX/qsw6NqDruXli9PK5LsqZGBWoFNgdThrGdSznxf33QFXXpiAxAZq5mtF9N/Unf\nrU7kj4sOT5WPiGfTfYSqVh+vp3VZ/m6abcq2F2UUIoDjs4z811WWEQa/Ur18R69jOSLmRhmhsOW7\nlFF9NgT+oUP6DSj7ayJawctrKf0ifpiZqzos/0fKr56/z8z/Zfxad8I265lqAFWgcCBlyNu9gG+1\nbcepsLiaHhsRu/ZK2HYXqnX8PiYi1uqXEhFPA/6ikRquud7xfE77tSgiXtahzM0pQxZD6a8wHour\n6XG9Aowo6sfY5ZRhlKH0m1grPeM7x59H6Q8yhzI0er/6+Rx8nvJD3E4R8de9VtbhzmZr+7662u7t\njqI0XxxIdfe8NfjGP3RpEfFXlJHrkrX3c+tcf3h7pmofrLVvagY9d7ypy3H+esq57G7KObbf+m1Y\n5R1X/aKMKNkroG713RnPZ27WMeDRTPIvlI64TwYuiIjnVL8cEREbRcShEXFOW56PUjokbwR8u7o4\nJSLmRMRLKc23AM7NzCVteU+inKAPAhZHxGOqvAsi4t2UL+p+B1Boyjuq6SER8anWBVFEbBoRb6c8\nVb6JOn2LMkLVHEaDqNMz88HuWbp6d0ScGREvrn/RRsRjqsEFtqNs5++1lmUZbe4n1cvF1UUeEbF+\nRBxJGVq3W/OX1nr+OiJe1fqCi4htIuJzwMt65B1I1Ufka5Qvy8WZ2W/Tg3+iNFd4MnBRRBzSGpmn\nujB7UkS8EfgF5YId+MMwyO+vXp4YEW9sNW+MiEVVXcY7iEZLqz9O65fL9rs357ctH8/ITnWtX56f\nEhFPn+C6/iAzb6IEPbdQftT45hjNU5v2acqv/fOAJRHx6vpduYjYOiKOrgaCqAevV1d1DuD0iHhi\nlX79iHgJ5fhub+LWhIE/pwNYAZxSvd+51Xp3oTxPbCvKueZj46z3eyl3GbakfJb+rN7kt/rcv4by\ny32riW7rQv2k6uWrIuJ9rYCoOtd/hnL8dBpmuavq7l7rR4eXRcSXo4zc2KrP5tWx8JG2rK3PwbMi\n4kld1v2/jDZv+lhEvCdq/TsiYpOIeF5EfJG1A4v/oGznLYHvVNu/dVy9nDJIyXi/O95NuRP8R5TP\n2Q7VujeMiFdT+qYAfDozr2vL2/qh8dCIeHNUQ6VX57MvUUa17GbMbdZmG+Br1bqJiI0j4k2MHgfv\ny7WH1W7V79UR8X+qIIeI2JkywlqvZnKt+h0SHX5wpQxuc21EnBART4uIOdW614uIgxh9tMF3+nhv\nymnwMCD/ZtYfgz149MNteZdWeY/tsf5ldHkQGeWWeetJ4UkZzex2ShOhbg//2odycdnKczejox0l\n5QGPj+5Sl+Nr6R6p1tMq64Pd3g/9PXh0vNvgxB51+gCjDyd9Wbf197mfT66Vk4zxtOdu7xn4f23r\nWcHowxpbf52ecP10Rh/KlpRg9yFGhyZvPXBwcVu+DShNP1r5VrUdM28d535bTNtD5GrpszoOe30W\n9mtb396UX4Jb+R+u1vEQa26bA9ryzaUEfK3lK2vvbyXwktqyRePY763BKVrr2K9Dml/Wlv9dl/Uc\nWy1f2keZ59fWdwfl+F8G7NtnnbuWRXlY46+r5ecC83rt07a8i1r16lF213VQ7pD9oPbeVlfv717W\n3McntuX707Z9cHftuLiR0YdEdjpOl9Hl3FFLs9bxwTg/p2Psl9a2eQ8l+Guds1fU1nkfbQ9tHcfx\n80RK37L6Z/521jx/JPDKDnk/2pav1fczgb/vtj3Hqh/wxrZ9eA9rnoeWtqVfn9EHobYeLrqs+nt8\nLd0c1nzAdGtf3VWrdwLf71CnA9q2yV3V/kjKENzvocM5tc99fRhrfq/eSTmntV6fC8zvkvcrtXSt\nvlxZ1bX+cPBFg24z1nzw6Esp58hW/VbWlp0FzO1Qt/UZPXZb59jW8XsH5c5Px3MEJbi8o/a+bmvV\nr1q+Wdt+fLhKv6o277r6/vev+593eDSZ+nnwaKNt5zPz+5QhHN9H6Z+zivIL6nWUX4Ne1CHPT4Cn\nUC7gf1nVexWljf3xlCcc/649X5X3A5S24d+nXKTMrfIdk5kTbTo0Lpn5dspJ9gLKxcJcyjM3Xp6Z\nxzO6zbs9A6lf9f46v8r+nmfSycmUC4ezKds/KLfobwZOp1zsrPWAv8z8MaW/wDco72Vulf944FC6\nPB8jS3v1gxn95feRKu33gMMy853jfB9j2YLen4U1mlJk6RuxI6XJxkWU42szypf8pZRfRQ/Itgdi\nZmle9lLKNv1Z9d5WA9+s0n+VCcjy7KyfVS/vp/PzXOp1mugdHihB2seAG4BHUfqhbUsDoz5lGS77\nQEpfj4Mov/BOSROR6rxyAHA05dfg3zM6nPAvKE2U/oxyrNbzfa2q8/coF8rrUwKdf6M8I+wWmjeu\nz2mfHqL8OPAOyvvYgLItTgP2yMwJHUNZ+sztDvxfyrn6Tsp5cBXlWP4k5ZzxxQ55/5YSQP64qmdQ\nju8XZmb7XZhB6vShqk6fpVzkrk+5gP0Z5blAb2hLv5JyfH6B8kPIQkY/B3Nr6VZn5v+lnBu/SNme\nG1I+KzdRmh3/LR0e8FmdS3an7M/fV/mWUe5wHFi9//G+329QmhGfUq1zY8r54weU1hDPz+6PeHgZ\nZQj/ayj7bCUlCNo3ezQR7neb1dJ/hfKj6Tcp58xVlB88/w54Sa7ZdLdexnMpPyYuo3yf3EcJ5ves\n8ner3+1VeV+lbO+tavWD8oPCCyk/NvyE0fPDfZTz7gnAbpk5GZ/3GSeqKFLSLFA1B7iD8kW2XWYu\nG26NJM1WEbEYeCXw9sw8abi10WxUNV+7ASDXHv5dM4h3eKTZ5e8pwc6vDHYkSdJsMOhwipKmuYj4\nEKVZxLcy87fVvK0pzTlaw1h+cEjVkyRJmlIGPNLMsw9V+++IeJDS6bQ+7OUXKG3WJUmSZjwDHmnm\neRelo/PTga0pnbx/R+no/pmqY6YkSdKs4KAFkiRJkmYsBy2QJEmSNGMZ8EiSJEmasQx4JEmSJM1Y\nBjySJEmSZiwDHkmSJEkzlsNSzzARcQOwKbBsyFWRJEnSzLYIuDsztxt2RXox4Jl5Nt1oo40232mn\nnTYfdkUkSZI0c1199dU88MADw67GmAx4Zp5lO+200+aXXXbZsOshSZKkGWzPPffkpz/96bJh12Ms\n9uGRJEmSNGMZ8EiSJEmasQx4JEmSJM1YBjySJEmSZiwDHkmSJEkzlgGPJEmSpBnLgEeSJEnSjGXA\nI0mSJGnGMuCRJEmSNGMZ8EiSJEmasQx4JEmSJM1YBjySJEmSZiwDHkmSJEkz1qwMeCJiv4g4JyKW\nR8QDEfGziHh9RMwZcD3Z4+/iDul3i4iTIuKHEXFbRDwcEbdGxJciYo/m3qEkSZIkgLnDrsBUi4jD\nga8ADwKnA8uBw4CTgWcCRw64yhuBxR3m39Jh3ieApwOXAV8F7gV2A44CjoiIP8/Mrw5YviRJkqQu\nZlXAExGbAqcAq4GRzLy0mv9WYAkl6DgqM08bYLXLMvOkPtOeCrw8M69tq9fRwBeBT0bEf2fmwwOU\nL0mSJKmL2dak7QhgK+C0VrADkJkPAm+pXr5usgrPzH9vD3aq+acCvwK2AJ42WeVLkiRJs82susMD\nHFhNv91h2QXA/cB+EbFhZj7U5zo3i4hXAVsDK4DLMnOt/jt9WFlNV40jryRJkqQOZlvAs0M1/WX7\ngsxcFRE3ADsD2wNX97nOXYFP12dExBXAKzLzyn5WEBH7Ak8BbgWu6jPPZV0W7dhPfkmSJGk2mG1N\n2hZU0xVdlrfmb9bn+j5EGehgK2ATYG/gTEoQtCQiHjfWCiJic+Dz1cs3ZObqPsuWJEmSNIZ17g5P\nRCwDth0gy6mZ+fLJqEtmvqlt1qXAkRFxJvBS4DjgDd3yR8R84GzgScD7M/OMAcres8s6LwMc4lqS\nJEliHQx4gOsoQ0r369e1/1t3cBZ0Slibf9eglWrzCUrAs3+3BFWw803gWcCHMvPNEyxTkiRJUpt1\nLuDJzIMmkP0aYC/gyZRn4fxBRMwFtqMMGnD9BMoA+H01nd9pYURsQgl2nk25s2OwI0mSJE2CdS7g\nmaAlwNHAIcCX2pbtD2wMXDDACG3d7FtN1wqcImIBZZS4fYF3ZeZb2tPMFPfd93PuvPM8Vq26m7lz\nN2XhwoOYP3/nYVdLkiRJs8hsC3jOBN4HHBUR/1578Og84F+rNB+vZ4iIjYFtgPsz86ba/F2AqzNz\nZVv6XYB3VS+/2LZsIfBdyl2mEzPzHU29senkzjvPY9myd7BixQVrLVuwYH8WLXobCxdO5EadJEmS\n1J9ZFfBk5t0R8WpK4LM0Ilin2FIAACAASURBVE4DlgMvogxZfSZwelu2fYDvA+cDI7X5bwQOi4gL\ngZuBhyhDQh8CzAFOYe27SF+lBDvXAetFxEkdqnlWZl4+zrc4dLfd9mmuueY1wCMdl69YcQFXXHEw\nj3rUHixa9Da23PLwqa2gJEmSZpVZFfAAZOZZEXEAcAJlYIF5wLWUAOYjmZl9ruosYFNgF8oDTecB\ndwDfAk7JzK93yLNdNX0CcGKX9S4D1smA5847z+sZ7NTde+9PueqqFzNnzgK23fYEttnm+MmvoCRJ\nkmadWRfwAGTmD4EX9Jl2KRAd5p9FCXoGKXfRIOnXNcuWvYN+gp261atXcP31/8jNN5/Mbrt9zz4+\nkiRJatRse/CoJsl99/28Y5+dfq1ceRuXXPJULrhgPnfeeV6DNZMkSdJsZsCjRjQVpDzyyP1cccXB\nnH/+htx++9mNrFOSJEmzlwGPGrFq1d2Nri/zYa666sUsXRpcffWxja5bkiRJs4cBjxoxd+6mk7bu\n3/72cwY+kiRJGhcDHjViKp6r0wp8rr32TZNeliRJkmYGAx41Yv78nVmwYP8pKeuWWz7E0qXh4AaS\nJEkakwGPGrNo0duYykPqiisOZunStUYMlyRJkv7AgEeNWbjwIHbY4ZNM9WG1dGkY+EiSJKkjAx41\n6rGP/Ut23fW7LFhwwJSXbeAjSZKkdgY8atzChQex++5L2Xvvq9hkk72nvHwDH0mSJLUY8GjSzJ+/\nM3vu+RO23/79wNwpL9/AR5IkSQY8mnTbbHM8IyMrmTv3MUMpf+nS4Pzz5w+lbEmSJA2XAY+mzLOe\n9Rs23/wFQyk7837v9kiSJM1CBjyaUrvs8k1GRpKNN951KOXbzE2SJGl2MeDRUOyzz+WMjCQbbLDN\nUMo38JEkSZodDHg0VPvtdyMjIwlsMJTyDXwkSZJmNgMeTQsjIw9Vo7kNh4GPJEnSzGTAo2mjjOaW\nDGMI6xYDH0mSpJnFgEfTzsjIyirwGZ6lS4PLLnv6UOsgSZKkiTPg0bQ1MpJDG8Ya4J57fuLdHkmS\npHWcAY+mtdYw1gsWjAytDjZzkyRJWncZ8GidsPvu36+auQ3vkDXwkSRJWvcY8GidMjKyelr07zHw\nkSRJWjcY8GidNDKSBj6SJEkakwGP1mnTJfC5887zhloHSZIkdWbAoxlhZCTZdddzh1b+FVcc7N0e\nSZKkaciARzPGwoUHTYu7PQY+kiRJ04cBj2acadHM7bzgh6cb+EiSJA2bAY9mrKEGPutBBFz68Sj/\nSJIkaSgMeDTjDSXwCXh4C3jMErj5TylBz4IFU1sHSZIkGfBo9pjywGcO3P5MePxZcO8i4O67vdsj\nSZI0xQx4NOtMZeCzYje4f1uYf2NtZtjMTZIkaaoY8GjWmqqg5849IBJWr9+2wMBHkiRp0hnwaFab\nirs9c1dAAnNWdklg4CNJkjRpZmXAExH7RcQ5EbE8Ih6IiJ9FxOsjYs6A68kefxf3kT8i4nu1PHPH\n/640EZMV+Gz9TXjMedBXOGPgI0mS1LhZd4EdEYcDXwEeBE4HlgOHAScDzwSOHHCVNwKLO8y/pY+8\nfws8p6rLvAHL1SRoBT1NPDx0s8tghw/1GezURUAO9zlCkiRJM8WsCngiYlPgFGA1MJKZl1bz3wos\nAY6IiKMy87QBVrssM08aR112AN4H/BtwFLDtoOvQ5Gki8Fn0eYhHxpm5dafHwEeSJGlCZluTtiOA\nrYDTWsEOQGY+CLylevm6ya5E1XTtC8D1wImTXZ7Gb7xN3Ta+ATb7Wem7MyE2c5MkSZqQWXWHBziw\nmn67w7ILgPuB/SJiw8x8qM91bhYRrwK2BlYAl2XmWP133gLsDjwjMx8KL2invZGRHOhuz8LLyrSx\nPesdH0mSpHGZbQHPDtX0l+0LMnNVRNwA7AxsD1zd5zp3BT5dnxERVwCvyMwr2xNHxN7ACcB763eZ\nBhURl3VZtON416ne+m3mNv9aePxXJ6kSBj6SJEkDmW0Bz4JquqLL8tb8zfpc34coAyD8kjLwwI7A\nmylN55ZExG6ZeWsrcURsRGnK9nPgHYNVXdNFPfDZ7MewXtVPZ/71sPW5MH/ZFFTCgQ0kSZL6ss4F\nPBGxjME6+J+amS+fjLpk5pvaZl0KHBkRZwIvBY4D3lBb/n7K3aO9M7PbU1n6LXvPTvOrOz97TGTd\n6s/ISMII3LNdsNFvYO6DU1wB7/ZIkiSNaZ0LeIDrKHdT+vXr2v+tOzgLOiWszb9r0Eq1+QQl4Nm/\nNSMiDgD+BjgpM6+Y4Po1jWxyQxVwDKsvloGPJElSV+tcwJOZB00g+zXAXsCTgTX6wFQjp20HrKKM\nnjYRv6+m82vzdqf0YX97RLy9S76V1QAGu2fm5ROsg6Za5nBHVDPwkSRJWss6F/BM0BLgaOAQ4Ett\ny/YHNgYuGGCEtm72rab1wOkq2gY3qPlz4FHAZygjGd8xwfI1LDnkuz2tsl/wAvjmN4dXB0mSpGli\ntgU8Z1Ie9nlURPx77cGj84B/rdJ8vJ4hIjYGtgHuz8ybavN3Aa5u74tTzX9X9fKLrfmZeS5wbqdK\nRcTBlIDnrzNz1fjfnqaNYQc+55zjwAaSJEnMsoAnM++OiFdTAp+lEXEasBx4EWXI6jOB09uy7QN8\nHzgfGKnNfyNwWERcCNwMPEQZpe0QYA5wCmvfRdJsM+zAx2ZukiRplptVAQ9AZp5VDSBwAmVggXnA\ntZQA5iOZfV8ZngVsCuxCeaDpPEpTtG8Bp2Tm15uuu9ZhBj6SJElDMesCHoDM/CHwgj7TLqUMNtA+\n/yxK0NNEfRY1sR6tAzLh0ENLk7NhiICnPhWuXOuZuJIkSTPSesOugDTrfPObw73TctVVJfA577zh\n1UGSJGmKGPBIw5I53MDn4IOHO5qcJEnSFDDgkYZt2IFPBGy66fDKlyRJmkQGPNJ0MczA5557SuCz\n//7DKV+SJGmSGPBI000m7LPPcMq+8EL790iSpBnFgEeajn784+H371l//eGVL0mS1BADHmk6G2Yz\nt1WrbOYmSZLWeQY80rpgmIGPzdwkSdI6zIBHWpcMM/A5+GDYccfhlC1JkjROBjzSuigTXvCCqS/3\nmmvK3Z5DD536siVJksbBgEdaV33zmyXwWW8IH+NzzoH58+HnP5/6siVJkgYwZVdKEbF5RGwzVeVJ\ns8bq1cNp5nb//fDUp8Lee9u/R5IkTVtT+dPwB4Hrp7A8aXYZVv+eSy8t/XuOO27qy5YkSRrDVLeF\niSkuT5p9hhX4fPCDDmEtSZKmHfvwSDNVJuyww9SWeeGF8PznT22ZkiRJPcwdb8aIuGnALAvHW5ak\ncfrFL8p0gw1g5cqpKfO734UPfACOP35qypMkSeph3AEP8Phx5BnSA0SkWe7hh8t0s81gxYrJL+8d\n7zDgkSRJ08JEmrT9Frg8M9fr5w/4fEN1ljRed91VmrrNmze55dx7L5x99uSWIUmS1IeJBDz/Azwl\nIvq9S+TdHWm6eOCByR/Y4PP+xiFJkoZvIgHPFcD6wM59pneENmm6yYRzz52cdU9F0zlJkqQxTCTg\n+SrwEfq/c/Me4MAJlCdpMhx0UAl8jjii2fUuWNDs+iRJksZh3IMWZOYlwCUDpL8GuGa85UmaZGec\nUab77Qc/+tHE13fMMRNfhyRJ0gT5HB5Ja7roonLH50UvGv86FiyAww9vrk6SJEnjZMAjqbOzzy6B\nz1lnwRZbDJb3hBMmp06SJEkDMuCR1Nvhh8Ptt8Pzntdf+mOP9Rk8kiRp2jDgkdSf73wH3v9+eNSj\nOi9fsKAs/+xnp7ZekiRJPYx70AJJs9Dxx5e/s88uz9lZsaIEOsccY58dSZI0LRnwSBrc4Ycb4EiS\npHWCTdokSZIkzVgGPJIkSZJmrMabtEXExsBCYE6n5Zl5U9NlSpIkSVInjQU8EfEK4M3ATj2SZZNl\nSpIkSVIvjQQfEXEs8BlgNXAhcDOwqol1S5IkSdJ4NXW35TjgTuBZmXl1Q+uUJEmSpAlpatCCJwJn\nrCvBTkTsFxHnRMTyiHggIn4WEa+PiI79jnqsJ3v8Xdwj34YR8aaIuCQi7o6I+yLilxHxuYjYauLv\nUJIkSRI0d4dnOfBQQ+uaVBFxOPAV4EHgdErdDwNOBp4JHDngKm8EFneYf0uX8rcGvgs8DfghcAql\nKeA2wPOBDwC/H7AOkiRJkjpoKuD5b2AkIiIzs6F1Ni4iNmU0wBjJzEur+W8FlgBHRMRRmXnaAKtd\nlpkn9Vn+esCXgR2AF2XmN9qWBw4VLkmSJDWmqYvrfwY2BD4REY9qaJ2T4QhgK+C0VrADkJkPAm+p\nXr5uEst/MfBs4OT2YKeqR2bm6kksX5IkSZpVmrrDcwZwP/BXwF9ExK+Auzqky8w8qKEyx+PAavrt\nDssuoLyH/SJiw8zst4neZhHxKmBrYAVwWWZ267/zF9X0SxHxGOCFwKOB3wDfzcxb+yxTkiRJUh+a\nCnhGav/PB3brkm7Yzd12qKa/bF+Qmasi4gZgZ2B7oN8BGHYFPl2fERFXAK/IzCvb0u5dTfcB/h+w\ncW3Zyoh4R2b+az+FRsRlXRbt2E9+SZIkaTZopElbZq7X599Ao6BNggXVdEWX5a35m/W5vg9RBjrY\nCtiEEtCcSQmClkTE49rSP7qafpwy0MH2VVkvpQzr/c7qmUaSJEmSGtDUHZ4pExHLgG0HyHJqZr58\nMuqSmW9qm3UpcGREnEkJYo4D3lBb3gowz83Mv6nN/2pErAS+TukPtbiPsvfsNL+687NHX29AkiRJ\nmuHWuYAHuI4ypHS/fl37v3UHZ0GnhLX5nfofDeITlIBn/7b5d1Hu8nytQ55zgIeBJ0fEgszsdhdK\nkiRJUp8aDXgi4ijKwAW7U4KHu4HLgE8PONRzVxMc9OAaYC/gyVW9/iAi5gLbAauA6ydQBow+R2d+\nh/IfTYeAKjNXR8TdwJbARnRvdidJkiSpT4304YniC8CplJHQNqVc9G8CHAScGhGnNlHWBC2ppod0\nWLY/ZRCBiwYYoa2bfatpe+B0bjV9anuGatS2LYF7gdsnWL4kSZIkmnsOz18DRwM/BQ4G5mXmY4F5\n1evLgKMi4rUNlTdeZ1KCiaMiYq/WzIiYB7RGR/t4PUNEbBwRO0bENm3zd4mI9dsLiIhdgHdVL7/Y\ntvgzlKGv/yYitq/lmQN8oHp5RmauGvidSZIkSVpLU03aXgUsA/bPzAdaM6uHaC6JiAOAq4C/pPRv\nGYrMvDsiXk0JfJZGxGnAcuBFlCGrzwROb8u2D/B94HzWHH77jcBhEXEhcDPwEGVI6EOAOcApwJfa\nyr8lIv4v8Fng8oj4WlX+CGUo718C/9jQ25UkSZJmvaYCnqcA/1kPduoy84GIOItyJ2ioMvOsKgA7\ngTKwwDzgWkoA85HM7PdZQWdRmu7tQmnGNw+4A/gWcEpmfr1L+Z+LiBuBf6IEWvOBmyh3eN6dmRMd\nMEGSJElSpamAJ4EYI81Yy6dMZv4QeEGfaZfSoe6ZeRYl6BlP+UuBpePJK0mSJKl/TfXhuRp4SURs\n1GlhNf/FwP82VJ4kSZIkjampgOczwDbABRFxUDXEMxExJyKeQ+kDs22VTpIkSZKmRFNN2v4TeDbw\nMuC7wCMRsRzYnBJUBfDlzBzagAWSJEmSZp9G7vBkcTRlaOollIdmbl5NlwBHZ+ZRTZQlSZIkSf1q\n6g4PAJn5JdqGYpYkSZKkYWmqD48kSZIkTTsGPJIkSZJmrHE1aYuIR4BHgKdk5i+r1/08sDMzs9Fm\ndJIkSZLUzXiDjwsoAc79ba8lSZIkadoYV8CTmSO9XkuSJEnSdGAfHkmSJEkz1qT2p4mILYD9KU3f\nzs3M1ZNZniRJkiTVNXKHJyJeFxE/jojNa/P2BH4BnAmcA1wUEfObKE+SJEmS+tFUk7Y/p4zAtrw2\n7wPAQuCzlIBnb+C1DZUnSZIkSWNqKuB5EvCz1ouI2BI4APh0Zv5VZh4GXAL8RUPlSZIkSdKYmgp4\ntgB+V3v9zGr6tdq8C4FtGypPkiRJksbUVMCzHNiy9voAyoNJL6rNS2BeQ+VJkiRJ0piaCniuBg6L\niC0iYjPgKOCSzLy7lmYR8JuGypMkSZKkMTUV8HwYeCxwC3Az8BjgY21p9gWuaKg8SZIkSRpTI8/h\nycyvR8RrgddUs07NzC+2lkfECPAo4DtNlCdJkiRJ/WjswaOZ+Ungk12WLaUMUS1JkiRJU6apJm2S\nJEmSNO00docHICLmADtQ7ubM6ZQmMy9oskxJkiRJ6qaxgCci3gq8AVgwRtKOgZAkSZIkNa2RgCci\n/hF4O7AC+AJlpLZVTaxbkiRJksarqTs8rwZuBfbIzN83tE5JkiRJmpCmBi34Y+Asgx1JkiRJ00lT\nAc9vaXgABEmSJEmaqKYCni8Dz42IDRtanyRJkiRNWFMBz4nAbcCZEbFdQ+uUJEmSpAlpqhnaVcD6\nwB8BL4iIFcBdHdJlZj6hoTIlSZIkqaemAp71KMNQ31SbFx3SdZonSZIkSZOikYAnMxc1sR5JkiRJ\nalJTfXgkSZIkadqZlIAnIhZGxB9PxrolSZIkqV+NBTwR8aiI+GBE/Aa4HbihtuzpEXFOROzRVHkT\nERH7VfVZHhEPRMTPIuL1ETFnwPVkj7+Lu+TZNCL+JSIuj4i7ImJFRFwZEe+MiK2aeYeSJEmSoKE+\nPBGxAPgBsDNwOSXg2amW5Erg2cDLgJ82UeZ4RcThwFeAB4HTgeXAYcDJwDOBIwdc5Y3A4g7zb+lQ\n9gLgJ8CTgUuBz1aL9gfeAhwbEXtl5m8HrIMkSZKkDpoape0ESrBzbGZ+PiJOBN7WWpiZ90fE+cBB\nDZU3LhGxKXAKsBoYycxLq/lvBZYAR0TEUZl52gCrXZaZJ/WZ9jWUYOezmfmqtrotBl4J/DXwjgHK\nlyRJktRFU03aXgJ8JzM/3yPNjcDjGipvvI4AtgJOawU7AJn5IOUOC8DrJrH87avpNzos+3o1tVmb\nJEmS1JCm7vA8ntJMrJd7gQUNlTdeB1bTb3dYdgFwP7BfRGyYmQ/1uc7NIuJVwNbACuCyzOzYfwf4\neTU9FPha27IXVtNz+yk0Ii7rsmjHfvJLkiRJs0FTAc89wKPHSLMdpW/PMO1QTX/ZviAzV0XEDZSm\nedsDV/e5zl2BT9dnRMQVwCsy88q2tJ+i9GP6y4h4GvDDav6zgacAJ2Tm2X2WK0mSJGkMTQU8lwAv\njIhNMvOe9oUR8VjgBcB/N1TeeLXuMK3osrw1f7M+1/chyp2tX1IGQdgReDOl6dySiNgtM29tJc7M\nByPiQODDlL46+9TWdSZwVp/lkpl7dppf3fmZFqPhSZIkScPWVB+eDwNbAOdERH10NqrXZwDzgI9M\ntKCIWDbGcNDtf1+caJndZOabMvOizLw9M+/NzEsz80hKELQlcFxb3bcAvgO8GDiqSrNl9f+zgR9H\nxD5IkiRJakQjd3gy8zsR8XbgROAqYCVARNwOLAQCeHNmXtRAcddR7qb069e1/1t3cLr1JWrNv2vQ\nSrX5BPBSynDTdR8EDgAOz8yv1+afHhEPUu7wvB8YmWD5kiRJkmiuSRuZ+faIuAD4e2Bfyh2fBM4B\nTs7MJQ2VM5Ghra8B9qIMDb1Gp/+ImEvpZ7QKuH4CZQD8vprOb5vfGpjg+x3ytOZ1bKomSZIkaXCN\nBTwAmfl9Ol/MTxdLgKOBQ4AvtS3bH9gYuGCAEdq62beatgdOG1bTrSgDPdS1hqN+eIJlS5IkSao0\n1YdnXXEmZaS4oyJir9bMiJgH/Gv18uP1DBGxcUTsGBHbtM3fJSLWby8gInYB3lW9bO8/dGE1PTEi\n1qvlmQO8vXp53mBvSZIkSVI3jd7hAYiIoDyTZq1gACAzb2q6zH5l5t0R8WpK4LM0Ik4DlgMvogxZ\nfSZwelu2fSh3rc5nzb41bwQOi4gLgZuBhyijtB0CzAFOYe27SG8G9gOOAfaMiFYzv4Mow1LfDvzL\nhN+oJEmSJKDBgCcijgT+CXhqj/Vmk2WOR2aeFREHACdQBhaYB1xLCWA+kpnZ56rOAjYFdqE80HQe\ncAfwLeCUtkEJWmVfGRG7UwKf51KGpk5KwPRR4L31YawlSZIkTUwjwUdE/A1lyOlVlIdp3lr9Py1l\n5g8pzwXqJ+1Syihz7fPPYoDn5tTy3QC8dtB8kiRJkgbX1N2WNwC/A/arLuglSZIkaeiaGrTgccAZ\nBjuSJEmSppOmAp6bGR1yWZIkSZKmhaYCns8BfxIRmzS0PkmSJEmasKYCnvcClwDnRsQBBj6SJEmS\npoNGAp7MXA38B/BEYAlwV0Ss7vA3bUdukyRJkjTzNDUs9eGUh3bOAW4Afs00HpZakiRJ0uzQ1LDU\nJwH3A4dm5g8aWqckSZIkTUhTfXh2AL5ksCNJkiRpOmkq4LkdeLihdUmSJElSI5oKeL4CPDci1m9o\nfZIkSZI0YU0FPG8B7gTOiIhFDa1TkiRJkiakqUELrgTWB54OHBYRdwErOqTLzHxCQ2VKkiRJUk9N\nBTzrUYahvqk2Lzqk6zRPkiRJkiZFIwFPZi5qYj2SJEmS1KSm+vBIkiRJ0rRjwCNJkiRpxhpXk7aI\nOKb692uZeU/t9Zgy8/PjKVOSJEmSBjXePjyLgQQuBu6pve4lqjQGPJIkSZKmxHgDnldRgpfbqtf/\np5nqSJIkSVJzxhXwZObittefa6Q2kiRJktQgBy2QJEmSNGMZ8EiSJEmascY7Stv14ywvM/MJ48wr\nSZIkSQMZ76AF67H2qGwbAI+t/l8N3A5sCcyp5t0GPDzO8iRJkiRpYONq0paZizJzu9YfsCtwK2WY\n6ucA8zLzscA84EDgx8AtwC7NVFuSJEmSxtZUH553AZsBI5l5fmauBsjM1Zm5lBIEbV6lkyRJkqQp\n0VTA86fA2ZnZsclaZj4InA28pKHyJEmSJGlMTQU8WwDrj5Fm/SqdJEmSJE2JpgKe64AjImJBp4UR\nsRA4Ahjv6G6SJEmSNLCmAp5PAH8E/CQijomIRRGxUTV9JWXQgq2B/2ioPEmSJEka03iHpV5DZn40\nIp4E/B3w2Q5JAvj3zPxYE+VJkiRJUj8aCXgAMvMfIuI04FXA7sACYAXwU2BxZl7UVFmSJEmS1I/G\nAh6AzPwR8KMm1ylJkiRJ49VUH551SkTsFxHnRMTyiHggIn4WEa+PiDnjXN8REfGdiLg9Ih6MiJsi\n4uyI2LdL+hdGxNKIWBER90bEj6u+TpIkSZIa1OgdnnVBRBwOfAV4EDgdWA4cBpwMPBM4coB1zQU+\nB/wF8KtqfSsoAzQ8A9gTuLgtz98C/w7cAXwReJgygt3iiHhaZh43gbcnSZIkqWZWBTwRsSlwCrAa\nGMnMS6v5bwWWUIbWPiozT+tzlW+nBDvvAt6WmY+0lbd+2+tFwL9Rgqy9MnNZNf8dwCXAmyLiK1XT\nQEmSJEkTNNuatB0BbAWc1gp2ADLzQeAt1cvX9bOiiNgaOA64ODPf0h7sVOtd2TbrVcCGwEdbwU6V\n7k7g3dXL1/b3ViRJkiSNZVbd4QEOrKbf7rDsAuB+YL+I2DAzHxpjXUcAGwCnRcRGwKHAE4F7gB9k\n5hUDlv+ttjSSJEmSJmi2BTw7VNNfti/IzFURcQOwM7A9cPUY69q7mm4M/ALYpr4wIr4CHJOZ9/dZ\n/m0RcR/w+IjYuC3fWiLisi6Ldhyj3pIkSdKsMduatC2opiu6LG/N36yPdT26mr4TWAbsATwK2Be4\nFHgp0P6g1X7LX9BluSRJkqQBNHqHp+qkfxCwE/CozHxnNX8esClwe6e+LgOWsQzYdoAsp2bmyydS\nZhetYHE5cFhm3l29/nFEvIhyF+cVEXFCZt7adOGZuWen+dWdnz2aLk+SJElaFzUW8ETEIcCnKUMy\nB5CUux8AuwE/BF4OfGmCRV1HGVK6X7+u/T/WHZTW/Lv6WG8rzXm1YAf4Q/O0H1OCv72AVsCzAtiy\nKueOHuV3uwMkSZIkaQCNBDwRsRdwFnA78AZgH+BlreWZeXHVP+ZPmWDAk5kHTSD7NZQA5MnAGn1g\nqmfqbAesAq7vc13QPTi6s5pu1JZny6r8NYaejojHAvOBW8bqvyNJkiSpP0314XkrZYSzvTLzI5SH\ncLa7BNi1ofLGa0k1PaTDsv0pAxBc1McIbQDnVtOndlm+czW9oc/y/6QtjSRJkqQJairgeSZwVmb+\npkeam4HHNlTeeJ1JuQt1VHVXCvhDH6N/rV5+vJ4hIjaOiB0jYo1R2IALgcuBZ0XEn7bleTWlH9O1\nlAEMWj4LPAT8bfUQ0lb6hcC/VC8/Ma53JkmSJGktTfXheRQlkOhlY4Y8Klxm3l0FI2cCSyPiNMqg\nAy+iDBl9JnB6W7Z9gO8D5wMjtXVlRLyymv+ViPgGZaCCnSl3a+4DXpmZq2t5boiI44GPAJdGxOnA\nw5Rn+jwe+GBmrtHUTZIkSdL4NRWA3MpoE65udqO/vjGTKjPPAg6gPGj0pcDfASuBNwJHZWYOsK6f\nUUZE+zzluTyvB3YHTgX2zMyLOuT5d0qA9XPgGOA1wG+AYzPzuPG/M0mSJEntmrrD8y3gtRHxrMz8\nQfvCiPgTYD/gvQ2VNyGZ+UPgBX2mXUoZda7b8huAYwcs/xvANwbJI0mSJGlwTd3heQ9ltLLvRsT7\ngKcARMSh1eszgNuADzVUniRJkiSNqZE7PJl5a0Q8D/gycHxt0dcpd0euA16SmWP185EkSZKkxjT2\n4NHM/GlE7AAcCjwD2ILyAM2LgbMzc1VTZUmSJElSPxoLeACqEcm+Xv1JkiRJ0lANdZhoSZIkSZpM\njQQ8EfGWiFgZEX/UZfnjIuLhiHhzE+VJkiRJUj+ausNzGLA0M3/daWFm3kp5eOeLGypPkiRJksbU\nVMDzROB/x0jzv1U6SZIkSZoSTQU8GwH3j5HmQWCThsqTJEmSpDE1FfDcAuw7Rpp9gVsbKk+SJEmS\nxtRUwPNtYP+I+PNOaSwodQAAIABJREFUCyPiKOAA4FsNlSdJkiRJY2rqOTzvA44G/qsKer5NuZvz\nOOBPgBcBy4H3NlSeJEmSJI2pkYAnM2+NiOcDZ1BGYju8tjiAZcCRmXlLE+VJkiRJUj+ausNDZl4a\nEU+mDFG9L7AZcBdwMfCNzFzZVFmSJEmS1I/GAh6AKqj5avUnSZIkSUPV1KAFkiRJkjTtNHqHJyI2\nBPamDFawYac0mfn5JsuUJEmSpG4aC3gi4lXA+4GF3ZIACRjwSJIkSZoSjTRpi4hDgE8BtwHHUYKb\ns4ETgO9Vr88AXtVEeZIkSZLUj6b68LwJuAPYLzNPruZdnpnvzcxDgFcDLwGua6g8SZIkSRpTUwHP\nHpShp+/ptO7M/DTwQ8odH0mSJEmaEk0FPPMpzdlaHgQ2bUtzKfD0hsqTJEmSpDE1FfD8Btiq9vo2\n+P/t3XmcXFWZ8PHfw74ngCDjgsAoi8GFTRER0LyjggI6REUcARcc920cV2TVdxQd8UVnnBEXQNCg\noCCKggTDOqAgiKKCQDIo4IKBhC1A4Hn/OKfITaWqu7q7ku6u/n0/n/rc1D3brZObm3rqnHsu27Tl\nmQas2qf2JEmSJGlY/Qp4rmfZAOcSYGZEvAAgIrYHXl3zSZIkSdJK0a+A50fA8yPiCfX9ccAjwNyI\n+CvwS2B94BN9ak+SJEmShtWvgOe/KQ8bvRMgM38DzKQEQncC5wN7Z+a5fWpPkiRJkobVlwePZubD\nwJ/b9l0BvLwf9UuSJEnSaPRrhEeSJEmSJpy+jPC0RMQWwOuBHSirsi0ErgFOzcx5/WxLkiRJkobT\nt4AnIv4F+CSwOhCNpFcAh0fERzLzc/1qT5IkSZKG05eAJyJeC3wGuAs4AZhLeTbPZsALgXcDn4mI\n2zLz9H60KUmSJEnD6dcIz79Qgp0dM/N/G/tvAC6KiJOBq4EPAAY8kiRJklaKfi1a8HTg223BzmPq\n/TvfAWb0qT1JkiRJGla/Ap57gLuHyXMXsKhP7UmSJEnSsPoV8JwPvKRbYkQE8OKab9xFxG4RcW5E\nLIiIByLiuoh4b0SsOsr6ZkXEeRFxZ0QsjohbI+LsiNi1Ld+zI+KoiLgsIu6IiIci4raI+FZE7Nif\nTydJkiSppV8BzweBDesX96c0EyJic+CbwPSab1xFxP7AxcAewPeALwJrAMcDs0dY12oRcRplut6W\nlPuTPgdcAGwN7NRW5L+AI4E1ge/WNn8NHAhcGRH/OLpPJUmSJKmTfi1acBplSturgQMi4lbgz8Dj\ngc2BVYHrgG+WwZ7HZGbO7NMxDCsiNgBOBB4B9srMq+r+jwMXArMi4sDM7DXwORo4iLIc9xGZ+Whb\ne6u35T8N+KfMvKkt3+uAU4EvR8QPMvOhEX40SZIkSR30K+DZq63Oreqr6VkdymWf2u/VLGAT4JRW\nsAOQmYsj4nBgDvA2ehjpiYjNKKvOXZGZh3fKk5kPt73/Qpd8p0XEkcDTgGdQVrSTJEmSNEZ9CXgy\ns19T41a0F9XtjzukXQzcD+wWEWtm5oPD1DWLMhVudkSsDbwMeCplAYdLM/OXIzy2VnC0ZITlJEmS\nJHXRrxGeyWKbur2xPSEzl0TEPMrS2VsBvx2mrl3qdh3gd5Spe4+JiDOBgzPz/uEOqi5u8HTgNso9\nPcOKiG6jQNv2Ul6SJEmaClb4yExEbBgR667odno0rW4Xdklv7Z/eQ12b1u2xwHxgR2A9YFfgKuAA\n4D+HqyQiNgJOqW/fl5mP9NC2JEmSpB70JeCJiJkRcVxEbNjYt2lEXATcCSyIiM/1qa35EZEjeJ3a\nj3Y7aPXdAmDfzLwmM+/LzCuB/YB7gddHxBOH+CzrAmdT7t05LjO/02vjmblTpxdltEmSJEkS/ZvS\n9i5g+8xsLjv9WeAFwE2UkY/3RMQVmfntMbZ1M7B4BPlvb/y5NYIzrVPGxv7hHqLazDMnM5d5oGpm\n3hERVwIzgZ0pU9WWUYOdHwK7A5/LzA/10KYkSZKkEehXwPMs4KLWm3oT/yzgJ5n5kohYH/gV8FZg\nTAHPGJexvoESgGxN20poEbEa5Vk6S4BbeqwLugdHd9Xt2u0JtT9+SAkIjzPYkSRJklaMft3DsynL\njqQ8F1gLOAkgM+8BfsDSRQPGy4V1+9IOaXtQFiC4vIcV2qA8XBRg+y7pM+p2XnNnREwDzqcEO580\n2JEkSZJWnH4FPA+y7EjGCyjP2Lm4sW8RsFGf2hutMyj3FB0YETu3dkbEWsAn6tsvNQtExDoRsW1E\nLLMKG3AJcC2we0S8sq3MYcB2lOl8VzX2b0gJlHYFjuz2/B5JkiRJ/dGvKW3zWPqMGygrlP0+M5v3\nrjyZEmyMm8xcVIORM4C5ETGbsujAfpTRpzOA09uKPQf4KWXK3l6NujIiDqn7z4yIcyjLXc8A9gbu\nAw5pW3Xtu5QpdTcDq0TEUR0O86zMvHaMH1WSJEkS/Qt4TgY+X2/Ufwh4BnB0W55nsvS+l3GTmWdF\nxJ7AxyiB2VqUkZj3AydkZo6grusiYkfgSODFwD6UoO404NjMbP+8W9bt39cyncynjBxJkiRJGqN+\nBTxfokzTeg0QwDnAp1uJEbE9JQg6ok/tjUlmXkYJTnrJO5fymbqlzwMO7bGuLXrJJ0mSJKk/+hLw\nZObDwEER8dbyNu9py/InYAfK6IUkSZIkrRT9GuEByj0yXfbfyTjfvyNJkiRp6unXKm2SJEmSNOEY\n8EiSJEkaWAY8kiRJkgaWAY8kSZKkgWXAI0mSJGlgGfBIkiRJGlh9CXgi4paIePcwed4REbf0oz1J\nkiRJ6kW/Rni2AKYPk2c68JQ+tSdJkiRJw1qZU9rWBx5aie1JkiRJmuJWG23BiNi8bdf0DvsAVgU2\nBw4AnNImSZIkaaUZdcADzAey8f499dVNAO8fQ3uSJEmSNCJjCXhOoQQ8ARwMXAdc2yHfI8DfgDmZ\nef4Y2pMkSZKkERl1wJOZh7b+HBEHA9/LzGP6cVCSJEmS1A9jGeF5TGb6PB9JkiRJE46BiiRJkqSB\n1ZcRHoCI2Ah4I/AcYEPK6mztMjNn9qtNSZIkSRpKXwKeiNgWmAtsQlnEoJscIk2SJEmS+qpfU9o+\nC2wKfBrYClg9M1fp8Oo06iNJkiRJK0S/prS9APhhZn60T/VJkiRJ0pj1a4QngN/0qS5JkiRJ6ot+\nBTxXA9v0qS5JkiRJ6ot+BTzHAPtExF59qk+SJEmSxqxf9/A8GTgbOD8ivkUZ8bm7U8bMPKVPbUqS\nJEnSkPoV8JxEWXI6gNfXV/sS1FH3GfBIkiRJWin6FfC8oU/1SJIkSVLf9CXgycyT+1GPJEmSJPVT\nvxYtkCRJkqQJp19T2gCIiE2AA4DtgHUz882N/VsCv8rMB/rZpiRJkiR107eAJyLeBJwArMXSBQre\nXJMfD/wP8Bbgq/1qU5IkSZKG0pcpbRHxD8CXgRuBVwJfaqZn5q+B64FX9KM9SZIkSepFv0Z4PgTc\nAeyZmYsiYocOea4Dnten9iRJkiRpWP1atGBn4AeZuWiIPH8ENutTe5IkSZI0rH4FPGsA9w2TZzrw\nSJ/aG5OI2C0izo2IBRHxQERcFxHvjYhVR1nfrIg4LyLujIjFEXFrRJwdEbsOUy4i4icRkfXV10Uk\nJEmSpKmuX1+w5wM7DZPnucANfWpv1CJif+BMYDFwOrAA2Bc4Hng+8KoR1LUacDJwEPD7Wt9CykjW\n8yh9csUQVbwTeGE9lrVG+FEkSZIkDaNfAc/ZwAcj4lWZ+Z32xIh4A/BM4GN9am9UImID4ETKSNNe\nmXlV3f9x4EJgVkQcmJmze6zyaEqw80ngiMx8tK291Yc4lm2ATwOfBQ4EnjLCjyNJkiRpGP2a0nYc\ncCvwrYg4nbo4QUS8s77/MmUE5At9am+0ZgGbALNbwQ5AZi4GDq9v39ZLRRGxGfAB4IrMPLw92Kn1\nPtyl7GrAN4BbgCNH9AkkSZIk9awvIzyZeVdE7AmcwrJTwk6o20uAgzJzuPt8VrQX1e2PO6RdDNwP\n7BYRa2bmg8PUNYty79LsiFgbeBnwVOAe4NLM/OUQZQ8HdgCel5kPRsRIPoMkSZKkHvXtJvnMvBXY\nKyKeSRnh2ZhyP8sVmXl1v9oZo23q9sb2hMxcEhHzgBnAVsBvh6lrl7pdB/gdsHkzMSLOBA7OzPvb\n9u9Cmdr3qeYo00hFRLc+3Xa0dUqSJEmDpu+rgmXmdZRn7kxE0+p2YZf01v7pPdS1ad0eC1xGeajq\njcD2wBeBA4B7gUNbBepI0DcoD2E9ZgTHLUmSJGkU+nIPT0TcEhHvHibPOyLilj60Nb+xjHMvr1PH\n2mYXrb5bAOybmddk5n2ZeSWwHyXYeX1EPLFR5jjK6NEh3e7v6VVm7tTpRRltkiRJkkT/Rni2YPhR\nken0ZyWymynLOPfq9safWyM40zplbOy/u4d6W3nmtD9wNTPviIgrgZmUh7LeVu9xegdw1DD390iS\nJEnqk5X5oMv1gYfGWklmzhxD8RsoAcjWwDL3wNSV07YEllBWT+ulLugeHN1Vt2vX7Q5AAEdHxNFd\nyjxcFzDYITOv7eEYJEmSJA1h1AFPRGzetmt6h30Aq1Ju6D+A3gKJFelC4HXAS4FvtaXtQVmA4OIe\nVmgDuAD4OOWenU5m1O28uv018NUueV8DrAd8DUjgbz20L0mSJGkYYxnhmU/5ct7ynvrqJoD3j6G9\nfjiD8rDPAyPiC40Hj64FfKLm+VKzQESsQwnY7q8r0bVcAlwL7B4Rr8zM7zXKHAZsB9wEXAWQmRdQ\ngqTlRMT/oQQ8/5yZS8b8KSVJkiQBYwt4TqEEPAEcTFmZrdM0rEcoIxZzMvP8MbQ3Zpm5qAYjZwBz\nI2I2ZdGB/ShLVp8BnN5W7DnAT4GLgL0adWVEHFL3nxkR51BWaZsB7A3cR1mc4JEV+qEkSZIkdTXq\ngCczD239OSIOBr6XmRN+qeXMPKsuIPAxyjS7tSgjMe8HTsjMHKp8W13XRcSOwJHAi4F9gDuB04Bj\nM/OGocpLkiRJWrH6smhBZvZleeuVJTMvowQnveSdSxnF6pY+j8azdkZ5PFuMpbwkSZKkziZVoCJJ\nkiRJI9HXZakjYhfgJcATgTU7ZMnMfFM/25QkSZKkbvoS8ER5eMxJwD9Rpn+1FjNoycZ+Ax5JkiRJ\nK0W/prS9E3g98A3Kgz0D+DywG/BR4B5gNrBVn9qTJEmSpGH1a0rbIcANrZXbyoAPd2fmFcAVEXEe\ncAXwE+DrfWpTkiRJkobUrxGebYEL2/Y9Fkxl5jXAD4C396k9SZIkSRpWP1dpW9j4833ARm3pv6cE\nRpIkSZK0UvQr4LmNsjJbyy3ATm15nkYJhCRJkiRppehXwPMzlg1wfgQ8JyI+HhEzIuIdwP6U+3gk\nSZIkaaXoV8BzJrBqRGxZ3x8H/C9wNHAd8AXgbuDDfWpPkiRJkobVl1XaMvMs4KzG+wURsQNwGPD3\nwHzglMy8ox/tSZIkSVIv+rUs9XIycyHw2db7iFgrIjbIzEUrqk1JkiRJaurnKm3D+RKwYCW2J0mS\nJGmKW5kBD0Cs5PYkSZIkTWErO+CRJEmSpJXGgEeSJEnSwDLgkSRJkjSwDHgkSZIkDSwDHkmSJEkD\na9TP4YmIR/p5IJIkSZLUb2N58OholpjOMbQnSZIkSSMy6oAnM50OJ0mSJGlCM2iRJEmSNLAMeCRJ\nkiQNLAMeSZIkSQPLgEeSJEnSwDLgkSRJkjSwDHgkSZIkDSwDHkmSJEkDy4BHkiRJ0sAy4JEkSZI0\nsAx4JEmSJA0sAx5JkiRJA8uAR5IkSdLAmpIBT0TsFhHnRsSCiHggIq6LiPdGxKqjrG9WRJwXEXdG\nxOKIuDUizo6IXbvkXzMi/iUifh4RiyLivoi4MSJOjohNxvbpJEmSJLWsNt4HsLJFxP7AmcBi4HRg\nAbAvcDzwfOBVI6hrNeBk4CDg97W+hcBmwPOAnYAr2spsBpwPPAO4DDgReATYHHgJ8Bngr6P9fJIk\nSZKWmlIBT0RswNIAY6/MvKru/zhwITArIg7MzNk9Vnk0Jdj5JHBEZj7a1t7qbe9XAb4NbAPsl5nn\ntKUHU3TUTZIkSVoRptqX61nAJsDsVrADkJmLgcPr27f1UlEdqfkAcEVmHt4e7NR6H27b9QrgBcDx\n7cFOzZ+Z+UhPn0SSJEnSsKbUCA/worr9cYe0i4H7gd0iYs3MfHCYumYBawCzI2Jt4GXAU4F7gEsz\n85cdyhxUt9+KiMcDLwc2Bf4EnJ+Zt43o00iSJEka0lQLeLap2xvbEzJzSUTMA2YAWwG/HaauXep2\nHeB3lHtwHhMRZwIHZ+b9Hco8B/h8LdvycEQck5mf6OWDRMTVXZK27aW8JEmSNBVMtSlt0+p2YZf0\n1v7pPdS1ad0eC8wHdgTWA3YFrgIOAP6zS5kvASdRAqvpNe9dwLERcWgPbUuSJEnqwaQLeCJifkTk\nCF6nrqBDafXdAmDfzLwmM+/LzCuB/YB7gddHxBM7lLkgM9+RmfMyc2Fmfhd4c037SC+NZ+ZOnV6U\n0SZJkiRJTM4pbTdTlpTu1e2NP7dGcKZ1ytjYf3cP9bbyzMnMRc2EzLwjIq4EZgI7A7c1ymwKfK9D\nfecCDwFbR8S0zOw2CiVJkiSpR5Mu4MnMmWMofgMlANkaWOYemPpMnS2BJcAtPdYF3YOju+p27bYy\nm3Yqk5mPRMQi4HG1jAGPJEmSNEaTbkrbGF1Yty/tkLYHZRGBy3tYoQ3ggrrdvkv6jLqd10uZumrb\n4yhT4e7soX1JkiRJw5hqAc8ZlGDiwIjYubUzItYCWqujfalZICLWiYhtI2KZVdiAS4Brgd0j4pVt\nZQ4DtgNuoixg0PI1ytLX74iIrRr5VwU+U99+JzOXjPLzSZIkSWqYdFPaxiIzF9Vg5AxgbkTMpiw6\nsB9lyeozgNPbij0H+ClwEbBXo66MiEPq/jMj4hzKctczgL2B+4BDmg8Szcw/RsTbga8D10bE92r7\newHPruU/2OePLUmSJE1ZU22Eh8w8C9iT8qDRA4B3AQ8D7wcOzMwcQV3XUZajPoXyjJ33AjsApwE7\nZeblHcqcTHkA6uWUQOsdwPqUEZ7nZqbT2SRJkqQ+mVIjPC2ZeRmwT4955wIxRPo84NARtj8XmDuS\nMpIkSZJGbsqN8EiSJEmaOgx4JEmSJA0sAx5JkiRJA8uAR5IkSdLAMuCRJEmSNLAMeCRJkiQNLAMe\nSZIkSQPLgEeSJEnSwDLgkSRJkjSwDHgkSZIkDSwDHkmSJEkDy4BHkiRJ0sAy4JEkSZI0sAx4JEmS\nJA0sAx5JkiRJA8uAR5IkSdLAMuCRJEmSNLAMeCRJkiQNLAMeSZIkSQPLgEeSJEnSwDLgkSRJkjSw\nDHgkSZIkDSwDHkmSJEkDy4BHkiRJ0sAy4JEkSZI0sAx4JEmSJA0sAx5JkiRJA8uAR5IkSdLAMuCR\nJEmSNLAMeCRJkiQNLAMeSZIkSQPLgEeSJEnSwDLgkSRJkjSwVhvvA5AkSZI0QtdfD3PmwKJFsMEG\nMHMmzJgx3kc1IRnwSJIkSZPFnDlwzDFw8cXLp+2xBxxxRAl+9JgpOaUtInaLiHMjYkFEPBAR10XE\neyNi1VHWNysizouIOyNicUTcGhFnR8SuHfJuEBEfjYhrI+LuiFgYEb+KiGMjYpOxfzpJkiQNpK9+\nFV784s7BDpT9L34xfO1rK/e4JrgpF/BExP7AxcAewPeALwJrAMcDs0dY12oRcRrwHWBL4HTgc8AF\nwNbATm35pwE/Bz4JPAx8Hfga8BBwOPCLiHj8aD+bJEmSBtScOfCWt8Cjjw6d79FH4bDDSn4BU2xK\nW0RsAJwIPALslZlX1f0fBy4EZkXEgZnZa+BzNHAQJYA5IjOXOQMjYvW2/G+hBEJfz8w3tuU9CTgE\n+GfgmJF8LkmSJA24Y44ZPthpefRROPZYp7ZVU22EZxawCTC7FewAZOZiyggLwNt6qSgiNgM+AFyR\nmYe3Bzu13ofbdm1Vt+d0qPL7deu0NkmSJC11/fXdp7F1c9FFpZym1ggP8KK6/XGHtIuB+4HdImLN\nzHxwmLpmUabCzY6ItYGXAU8F7gEuzcxfdijTOuteRplO1/Tyur1gmHYBiIiruyRt20t5SZIkTRKj\nnZ42Z44rtzH1Ap5t6vbG9oTMXBIR84AZlJGY3w5T1y51uw7wO2DzZmJEnAkcnJn3N3Z/BXgt8KaI\neAZwWd3/AuDpwMcy8+zeP44kSZIG3qJFK7fcgJlqAc+0ul3YJb21f3oPdW1at8dSApdXUAKp7SkL\nIRwA3Asc2iqQmYsj4kXA/6Pcq/OcRn1nAGf10G6rrp067a8jPzv2Wo8kSZImuA02WLnlBsyku4cn\nIuZHRI7gdeoKOpRW3y0A9s3MazLzvsy8EtiPEuy8PiKe2Dj2jYHzKMHRgcDj6utAyijPlRHRDIIk\nSZI01Y128QEXLQAm5wjPzcDiEeS/vfHn1gjOtE4ZG/vv7qHeVp45mbnMeGFm3hERVwIzgZ2B22rS\nvwN7Avtn5vcbRU6PiMWUEZ7jgL16aF+SJElTwYwZ5aGiI1m4YM89vX+nmnQBT2aOJVS9gRKAbA0s\nc9N/RKxGeZbOEuCWHuuC7sHRXXW7dmNfa2GCn3bI39rXcaqaJEmSprAjjigPFe1laepVVoGPf3zF\nH9MkMemmtI3RhXX70g5pe1AWILi8hxXaYOlqatt3SW+F1PMa+9as205LT7f2PdRD25IkSZpKZs6E\nL3+5BDNDWWUVOPFEp7M1TLWA5wzgTuDAiNi5tTMi1gI+Ud9+qVkgItaJiG0jYplV2IBLgGuB3SPi\nlW1lDgO2A24CrmorA3BkRKzSyL8q5SGmAD4WV5IkSct705vg/PPLdLVO9tyzpL/xjZ3Tp6hJN6Vt\nLDJzUQ1GzgDmRsRsyqID+1GWrD4DOL2t2HMo080uonFvTWZmRBxS958ZEedQVmmbAewN3AcckpmP\nNOr6ELAbcDCwU0S0RpxmUpalvhP4aN8+sCRJkgbLzJnldf315Tk7ixaV1dhmzvSenS6mVMADkJln\nRcSewMcoS0evRRmJeT9wQmbmCOq6LiJ2BI4EXgzsQwlaTgOOzcwb2vL/KiJ2oAQ+/0BZmjqBP1CW\nsv5UZt6GJEmSNJQZMwxwejTlAh6AzLyMEpz0kncuEEOkz6PxrJ0e6psHvLXX/JIkSZJGb6rdwyNJ\nkiRpCjHgkSRJkjSwDHgkSZIkDSwDHkmSJEkDy4BHkiRJ0sAy4JEkSZI0sAx4JEmSJA0sAx5JkiRJ\nA8uAR5IkSdLAMuCRJEmSNLAiM8f7GNRHEfG3tddee6PttttuvA9FkiRJA+y3v/0tDzzwwILM3Hi8\nj2UoBjwDJiLmARsA81dA9dvW7e9WQN1Tgf03evbd2Nh/Y2P/jZ59Nzb23+jZd2PTa/9tASzKzC1X\n7OGMjQGPehYRVwNk5k7jfSyTkf03evbd2Nh/Y2P/jZ59Nzb23+jZd2MzaP3nPTySJEmSBpYBjyRJ\nkqSBZcAjSZIkaWAZ8EiSJEkaWAY8kiRJkgaWq7RJkiRJGliO8EiSJEkaWAY8kiRJkgaWAY8kSZKk\ngWXAI0mSJGlgGfBIkiRJGlgGPJIkSZIGlgGPJEmSpIFlwDNFRMRuEXFuRCyIiAci4rqIeG9ErDrC\netaIiA9GxC8j4v6IWBQRl0bEq4cpd0hE/Cwi7o2IhRExNyJePkT+VSPiffU4H6jHfW5E7DaS4+2X\nPvbfqhHxuoi4JCL+VPvwxoj4ekTM6JB/bkTkMK+vtpU5apj8Lx1rf4zEOPbdXsP0w6eGaMdzL+LZ\n9Vy6LCLuiIiHIuK2iPhWROzYpQ3PvWXLvbz+G15Yr31XRsQhw7Q1omvlitSP/uvhnMiIuLmtzKS/\n7tVjGq/+m/TXvnHsu0l/3avHNC791yg74a59q/WrIk1cEbE/cCawGDgdWADsCxwPPB94VY/1rAGc\nB+wFzAe+Tgma9wFOj4jtM/OIDuU+C/wL8EfgRGAN4EDgnIh4V2Z+sS1/ALOBWcANwBeBjYDXABdH\nxAGZeXbvPTA2/eq/6pvAqyl98V3gHuAZwCHAQRGxd2Ze2Mh/EjC3S13vovTLj7qkn0z5e2p30wiO\nd0zGue9aLqJzH17a4Xg995b6L+C5wNU1/73Asyn/dmdFxGsy87td2pry515EvBP4AvA34FTgIcp5\ndVJEPCMzP9DhmEd0rVyR+th/c4dI2xfYkeWvYScNUW7CX/dg3PuvZVJe+8a57yb1dQ/Gvf8m7rUv\nM30N8AvYAPgL8CCwc2P/WsDlQAIH9ljX+2r+y4F1G/vXA64CHm22UdN2q2VuAjZs7N+i/mNYDGzR\nVua1tcxlwFqN/bvUz/EXYP1J2H+71Py/BtZpS3tDTbuwx7q2qfn/BKzelnZUTdtrgM69EfcdJTBP\n4KgRHLPn3tL97wKe2qGu19X8dwJreO517LstKNe2v9G4vgEbUq6FCTyvrcyIr5WTof+GaGNV4A+1\nrmf2WGbCX/cmQv9N5mvfBOi7SXvdmyD9N2GvfU5pG3yzgE2A2Zl5VWtnZi4GDq9v39ZjXa+s209m\n5n2Nuu4FPgEE8Pa2Mm9tlLmrUWY+8B/AmpQvDU2t4zm8HmerzM8pv1ZsUj/XytDP/tuqbudk5v1t\naa1fzjbpsa631O3XM/PhHsusbBO174biube0nS9k5nK/TGbmacDvgY0poxwT0Xife2+kXNu+WK91\nrfbvAv5vffvWtjKjuVauKP3sv272AZ4EXJGZ1/VYZjJc92Di9t9QJsq1b1z7bpJf92D8z70Je+0z\n4Bl8L6rbH3dIuxi4H9gtItbsoa7N6vaWDmmtfTNH0P6P2vIQEWtRov37gUt6KbOC9bP/rm/VGRFr\nt6W15qleMFwlta2DKb+InDhE1t0j4gMR8aGIeE1EPK6HY+ynidJ3T42Id0bERyPijRHxtE6ZPPeG\nP/caWl82l3RS3y13AAAT7UlEQVRJn+rn3oiue2Mos6L0s/+6aQUvX+4l8yS67sHE6b/JeO2bKH3X\nyUS/7sH499/EvfaN59CbrxX/An5O+Q9ipy7pv67p2/VQV2s4dJ8Oaa+oaQmsXfetW9/f06W+x9X0\nPzf2zaj7ftWlzM41/crJ1n81/+dq/v+l/HLxKeAcyoX0WzSmCg5RR2vqwfld0o9q/F00X4uBY4GY\nCn3H0mkdnV5n0Bg699zr7dyr9exa6/kjsKrnXsdz7681/8Zd6ru3pq9T34/4WjmZ+q9D+SdRvjTe\nTds0wSHKTIrr3kTov8l87Rvvvhui3IS/7k2E/pvI1z5HeAbftLpd2CW9tX96D3X9sG4/1vylMyLW\nBT7ayNeqazRt9/N4+6Gvx5OZ76cM325Cmf73IcqvxL8ETs7GVMEhDPfr1C8pw8pbAWsDTwEOo1yg\nDgc+2cux9sF4991fgQ9Tph+sX8vtDVwDHEC5GbJ5DfTcG0ZEbAScUt++LzMfacviuTey9qe1bQfy\n3OvgTZT7AE7N5acJdjNZrnsw/v03ma994913y5lE1z0Y//6buNe+lRV1+hr9i7LqR7dfazq9Tm2U\nvbHuW+4mvJp+GR1uIuuSdz3g2pr/FsoqLv9Rj28e5R93Ao+v+Z9Q3/+xS32r1/QHG/taN69d2qXM\n02r6DZOw/wI4gfLryIcpv5SsB+zO0l9l3jFMHa3Pv9xNuz20vyNltZSHgMdNtb5r1LVBPX8T2N9z\nr+dzb13KdJcEPu25173v6udMYLUudd5W0/+uvh/xtXKy9F+HsqsAt9byz+ixzEq97g1a/zXKrpRr\n3yD1HSv5ujfZ+48JcO3r9nJZ6snhZsrQaK9ub/y5PZpu19p/93CVZua9EbE7ZTRnFuUXjHuAc4GP\nAL+jfClYMIa2+3a8DROi/yhL2L4LOD4zm89BuDQi9qX8R/SpiDg5y0IQnYz6pt3M/EVE/IyyLOXz\nKFNyhjNIfQdAZi6KiG8CHwP2YOmN5557XfqvjuL+kPIl/3OZ+aEe2nzMFDz3FlKmYkyjrDLUrf2F\nbdtBPPfa7Q08mXLD8696LLOyr3swWP0HrNRr30D03Thd92By999EuPZ1ZMAzCWRm+0IAI3EDZf7t\n1pR15R8TEasBW1KClE4LEXQ6lnspAU9zChsRsRXlV8+rW/8hZeZ9EXEb8MSI+LvMvKOtutYNlDc2\n9t0MPAJsFRGrZWb7zYGdygx3zBOl/1o3OP+0wzH+KSJ+B+xAWXr16vY89TlIh1B+7Rjqpt2h/LVu\n1+0l86D0XQed+sFzr0P/RcT6lP/0XwAcN9L/9Bum0rl3A+U//a2B/2lr/+8offDHrFNCRnmtHNIE\n6r92reDlv3vJPB7XPRic/utghV/7BqHvxuu6B5O+/8b92teN9/AMvtbD8Do96XcPYB3g8sx8cIzt\nHFy33xxB+3u35SHL0omX1+N6QS9lVrB+9l9rVZRuyye39j/UJf2VNc8FmTnii1VErE4ZYofRXexG\naiL1Xbtd6/axfvDcA9r6LyKmAedT+uOTo/1PfwqeeyO67o2hzIqyQv7fiIgnAC+j/Kp7eo/FJtt1\nDyZW/7Wb6Ne+ce+7SXzdg/Hvv4l77RvrnDhfE/tFmbP7V0bwECrKP4htgc071ddh3z8AD1AeGtW+\nWtGKevDocscx0fsP+GDN/2tgWlvaW2vaHbStANPIM6fmOWCI410f2KbD/jUo91sl8FtglUHvO9oe\ngtvY/0+Uh+Q+6Lk3ZP9tyNJ7VI7o4Xg995bu35IJ+vC9ld1/bXk+Xst+YQTHMqmuexOh/5jE174J\n0HeT9ro3Qfpvwl77Vnjn+xr/F2XJ6CWU5QC/AhxHud8mge/QtmQiS5e0nNuhrtspa6V/nrI06/n1\nAno7MKNL+/9e6/sDcHy9CNxZ972zQ/6ox9W6UBwHfLUe/xIaN1tOpv6jTPn7ZU37M2V6xmdY+h/6\nEuAfuxzDU2s/D3nTbr1APAr8DDi5/h19laU3qv4VePZU6DvKjZ83AbOBz1IW2biy5n8YONRzb8j+\n+ylL/xM6qsvr2Y38nnvLlntXTb+Tcs07nqVPJ/9sl2Me0bVyMvRfI30Vlt6M3esN45Pyujfe/cck\nv/aNc99N6uveePdfzT8hr30r7S/A1/i+KDfNnQvcRRmN+RXwPjqMJgx18lP+o/8VsKjW87v6D3yj\nYdo/lPKryX2UhQ4uAl4+RP7V6vH9qrZzVz3+3SZ5/60HHEFZ7e4+yn8+twPfBp4zRPufrnX+2zDH\nuQFlRakrKF8SHqoXvV/Wv6dNp0rfUZYO/km9gD5A+ZXoZuDrwLM894btv/m1rqFeh3ruDfnvdl/K\nte6eWu7nwCHDHPOhjOBaORn6r6bvXdP/ZwTtT9rr3nj2HwNw7RvHvpvPJL/ujWf/NcpMuGtf1EYk\nSZIkaeC4aIEkSZKkgWXAI0mSJGlgGfBIkiRJGlgGPJIkSZIGlgGPJEmSpIFlwCNJkiRpYBnwSJIk\nSRpYBjySJEmSBpYBjyRJkqSBZcAjSZIkaWAZ8EiSJEkaWAY8kiSNUUTMj4j5bfsOjYiMiEPH56hW\nvoiYGxE53schSU0GPJJU1S+nK+TLWkScVOvfYkXUP1mOQRoPEbF2RBwdETdExOKI+EtEfDsithvv\nY5O04q023gcgSdKA+h5wBXDHeB/ISnQwsM54H0RTRKwJ/AR4PnAV8P+AJwOvAl4WES/KzCvH8RAl\nrWAGPJIkrQCZuRBYON7HsTJl5q3jfQwdvJ8S7JwBvCYzHwWIiNOBs4CvRcQzWvslDR6ntEnSKETE\nKyLi1Ii4MSLuq6+rI+LdEbFKW94EDqlv57WmznW452OjiPi3iPhtRDwQEQsjYk5EvLhD+4/dHxIR\nL6z3TtwTEYsi4oftU3V6PYYun3WN+rl+ERF3RcT99Z6VsyPi/7S3U4/lCRHxjTp16IHaNwd1qfud\nEXFuRPxvRDwYEQsi4oKI2HuIY3pSRJwQEb+v9S+IiJ9FxMe75P1iRNxS6/9bRHw/InYZ7rO31RP1\nWK+v06Juq/VO65K/4z08rft9ImK9iDg+Iv5QP8O1EfGKmme1iPhY/XyLI+LmiHjnEMf2ktqHd9bP\neHNEfCYipnfI22p/3Zrn1lrmpoj4UEREhzL71XPxjpr39oi4KCLe3pav4z08EbFKRLw1In4eEffW\nfy8/j4i3tf97qflb59HjIuLLjXavj4g3dOuHDvUE8Nb69oPNoCYzzwYuAZ4O7NlrnZImH0d4JGl0\nPgU8ClwJ3AZMA15EmS6zC/D6Rt6jgVcAz6rpd9f9rS0R8RRgLrAF5UvYj4F1gZcDP46If87MEzsc\nx8uB/YEfAf9F+fK2D7BLRDw9M+/s9RiGcBLwWuDXwCnAA8ATgN2BlwIXtOXfELi81v11YDrwauC0\niHhiZn6mkXejejyXU6Yd/RX4O2Bf4NyIOCwzv9KsPCJ2Bs6rZS8GvkuZRvV04Cjg2EbeHYHza97z\nat7H1b64NCJemZnn9tAHAJ8H3k2ZovZl4GFK3z8XWAN4qMd6AFavn3cj4Oxa/rXAmVEC3LfXen8E\nPEiZfvWFiPhrZp7erCgijqyfewHwA+AvwDOBDwD7RMTzMnNRh/bPo/w9/ghYQumTTwFrUc6XVv1v\nAf4b+BNwDnAnsGlt4w3Af/bweb8BHAT8AfgKkMAra9ndgdd1KDMduIzSr2cAa9Z++FpEPJqZJ/fQ\n7t8DmwM3Zua8Duk/Al5A+bf70x7qkzQZZaYvX758+cqE8iUse8z79x32rQKcXOt5blvaSXX/Fl3q\nm0sJoA5s2z8duJYSZDy+sf/QWt8SYGZbmX+raR8cyTF0Oa5p9biuAlbtkL5xpz4Evg2s0ti/JeUL\n+UPAVo39awJP6tLur2uZtRv71wDm1TYO6lDuSY0/rwbcBCwG9mzL9wRKoHoHsGYP/bBbbfMmYKPG\n/rWA/6lp89vKtP6ODm3bP7/uP6fZNuWLd9bP/HNgeiNtq9p317TV9cJa5vJm/rb2j+/S/rltfbsp\nJUi9G1i9sf9qStC1aYd+eVyH8zjb9r22tvcLYL3G/nXrebXc32XjPPpK87yjBLVLgN/0eP6+rNXX\nXdJn1fTTe/034cuXr8n3ckqbJI1CZt7cYd+jlNEKgJf0WldEPIsypebMzJzdVufdwJGUL9YHdCg+\nOzPntO37ct0+p9djGEICQfnCu9w9Dpn5tw5lHgE+lMtOH5oHnEAZWXh9Y/+DmfnHDvUuBL5GGS1q\nTj3blzIK9v3M/GaHcs26Xkb5hf8LmXlRW77bgeOAzYCZHT5Du9Y0qk9m5oJGPYuBj/RQvpP3ZuaD\njbouoQRzG1L67+5G2i2U0Y7tI2LVRh3vrtvDmvlrmZMowXKn0ROAd2fmA438f6GMNk0DtmnLu4Qy\norWMXDqCOJQ31u2HM/PeRtn7gA/Vt2/uUO5+4P2Z+UijzG8o/bBdRKzXQ9ut6Ybd7qVq7V9u6p+k\nweGUNkkahYjYGPhXyvSxrSi/Vjc9cQTVPa9up0XEUR3SN6nbTkvoXtVh3x/qdsMRHENHmbkoIs6h\nBBrXRsSZlCl3V2bm/V2K3Zqdpw/NpQRvOzR3RsQMSl/uQZnOtlZbuWZf7lq3P+rh8Fv9+pQu/fq0\nut2OMtoxlB3r9qIOaZdSgryRuLtT0AzcThkNu7pD2m2U/7c3q3+G8hkfBl4VEa/qUGYNYJOI2Lgt\nOF2YmTd1yN/p3DkN+HfgNxExm9IHl2XmXzt/tOXsSAmW53ZIu4jSdzt0SPt9Lj8Vr/0Y7+2QLknL\nMOCRpBGqN4L/nPLF9GeU+1oWUH4Fnw68hzJVq1cb1+0/1Fc3nX7RXu4enMxcUu87X3X57KPyGsov\n8Qex9N6OxRFxBvCBzPxzW/729y1/qtvHbvKPiF2BCyn/H80Bvg8sonxBfjblHplmX7Z+ib+N4bX6\ntVMg0DSSkYLlPlvt715GOpq6jTgsqXV2Sl9St6s39m1M6bsjh2lvPaAZ8HS7d6vVxmPnTmZ+rn6+\nt1NGlN4LZERcBPxrZnYKupumAQsyc7l7nBp9t2mHcj0f4xBa/dhxYYnG/l7uZZM0SRnwSNLIvZkS\n7BydmUc1EyLieZSAZyRaX8rek5knjP3w+qtOezoKOCoinkwZiTkU+CfK9LIXtBV5fJeqNqvb5pf5\nw4G1gRdm5txm5oj4CCXgaWp9Me1lBK3Vzv6Z+f0e8vdS1+OBW5oJEbEaZSGE5abmrQQLKfdKbbQi\nG8nMU4BTarC/G2XBgTcC50XEtsOM9iwENoqI1TNzmWlxjb7rNJLTDzfU7dZd0lujfDeuoPYlTQDe\nwyNJI/fUuj2zQ1q35W1bU546/Sp9Rd22Bw79NtQx9CQz/5CZp1HuUboJ2L1O72vaPCK26FB8r7q9\nprHvqZRf/+d2yN+pL1t91XXJ6g55+9Gvv6jbTse0O/0bTRupK4AN67TAFS4z787MczPzMMoiGBtR\nAuChXEP5vtEp3x6UvvtFh7R+uBm4Fdg6IrbskN46jy5cQe1LmgAMeCRp5ObX7V7NnRGxA91vYG9N\nJ9q8PaFOCboE+MeIeGN7eq37GRHRadrPSHQ9hm4iYpOIeEaHpHUp06SWsPxyzKsCn24+X6V+2Xx3\nzX9qI+98yq//z2xr9010XvjhnFpmv4h4bYfjfVLj7dmUL7zviIh9uny+50XEOp3S2pxUtx+LiMdG\nUyJiLcqqeOPl+Lo9MSKe0J5Yn7Wza/v+kYjynKflns3D0mlo3e7lavla3f5bs6/rnz9V3351LMfY\nTWYmZbl2gOPazsn9KcHwb+h8b5akAeGUNklqExEnDZH8dso9O/8KfD4iXgj8njI15uWU57y8pkO5\nObXMifXG/3soN65/saYfRPmV+asR8W7K833uBp5Eed7J9pQb1P8yho823DF08kTgmoj4FXAd5Ybx\nDepn3Qw4ITPvaStzHeUZMldHxPksfQ7PdMpS2c2b9T9PCWwujYhvU6Y/7UwZNTmDsmzwYzLzoXpz\n/vnANyPinymjHGtRFh+YSf2/LTMfjoh/pDxv5ocRcTll1bL7gSdTVn/birJQwpBf2jPzsoj4AvAu\n4Nf1/qXWc3juoixvvdJl5pyI+DAl6Pp9RJxLWeltPeAplBGpSynPSxqt7wH3RsQVlGAzKIHCLpTF\nFdqfw9R+jN+swcWrgesj4izK6n+voEwNPb2OGq4on6Ocr7OAKyNiDiXofxXl7/2NzRUFJQ2g8V4X\n25cvX74myoulz/4Y6jW95n065Qb7vwD3Ub74vZlyT0sCJ3Wo//3AbylLPHd6bsv6wEdrXfdSnr0z\nD/gh8BZg3UbeQ+nwjJe2zzJ3pMfQIf904AhKMHZbLXcHZcWt1wLRqV3Kc25Orf2zmDJlabnn5tQy\nL6cELfdQgrzzWXqfUMfPSPnC+p+1fx6ijF5dCXy0Q95NKSMJv6Z8wb2XEqSeQbkPabUez48A3tno\nv9uB/6Dc+D6/w99nx+PvlLeRNpcuz4JiiOcoUQLEb9djeojyANdrKV/2dx5B+0fVNvZq7HsrJei5\npfbfAso0tQ8C6/dy/JQZJW+nrCp4f31dDbyDxvOahjt/h+uHIf7u1gGOqX/vD9b++Q7w9H5eQ3z5\n8jUxX5GZSJLUDxGRwEWZudd4H4skSeA9PJIkSZIGmAGPJEmSpIFlwCNJkiRpYHkPjyRJkqSB5QiP\nJEmSpIFlwCNJkiRpYBnwSJIkSRpYBjySJEmSBpYBjyRJkqSBZcAjSZIkaWAZ8EiSJEkaWAY8kiRJ\nkgaWAY8kSZKkgWXAI0mSJGlgGfBIkiRJGlgGPJIkSZIGlgGPJEmSpIH1/wH1tfrPnPGVbAAAAABJ\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 414,
              "height": 277
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr-7U1a05xQX",
        "colab_type": "code",
        "outputId": "2dd82361-ea14-4703-d6d3-6c631b66e16b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_accuracy = torch.mean((torch.from_numpy(kmeans_pred_label).view(10002) == labels.view(10002)).type(torch.FloatTensor)).item()\n",
        "print(f'KMeans Accuracy on Encoding by Autoencoder = {train_accuracy*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KMeans Accuracy on Encoding by Autoencoder = 17.44%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QMIeYza6iM-",
        "colab_type": "code",
        "outputId": "5202f424-9b3e-4869-af0d-595e6e6c7c8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.mean((kmeans_pred_label==np.ones(kmeans_pred_label.shape)).astype('float32'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugVAIbty8JjQ",
        "colab_type": "code",
        "outputId": "882a208d-2e74-423b-d3d2-4a15d1e7af41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "kmeans_pred_label.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10002,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D26n7v9b8Sej",
        "colab_type": "code",
        "outputId": "9d0f900e-c3ab-452f-fcbe-52d93cae2c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wrong_pred_list = []\n",
        "for i in range(len(kmeans_pred_label)):\n",
        "  if(kmeans_pred_label[i].item() != labels[i].item()): \n",
        "    wrong_pred_list.append(i)\n",
        "    print(i)\n",
        "print(len(wrong_pred_list))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xTP6Cla9O-0",
        "colab_type": "code",
        "outputId": "7d1b3401-18cd-444a-818a-80132e1fa946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.sum((torch.from_numpy(kmeans_pred_label) == labels).type(torch.FloatTensor)).item()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50020000.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va9oqvvT-buF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zz = (torch.from_numpy(kmeans_pred_label).view(10002) == labels.view(10002))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyPXuvVgBJuY",
        "colab_type": "code",
        "outputId": "878e7cca-cc98-4727-a9e7-1324f57f1793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "kmeans_pred_label.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10002,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMDz1dmoBNkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRuXaEFdA_25",
        "colab_type": "code",
        "outputId": "469ba261-20b0-4a85-cf7f-a91ac2b680b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.mean(zz.type(torch.FloatTensor))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf4fhoRB-mnb",
        "colab_type": "code",
        "outputId": "7f73f5aa-35e0-4ef2-dbf6-454647912422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "wrong_pred_list = []\n",
        "for i,j in enumerate(zz):\n",
        "  if (not j and (kmeans_pred_labels[i].item() != labels[i].item())):\n",
        "    wrong_pred_list.append(i)\n",
        "print(len(wrong_pred_list))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-d96974c8631a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwrong_pred_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkmeans_pred_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mwrong_pred_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrong_pred_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: bool value of Tensor with more than one value is ambiguous"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uRqTRY_ArY4",
        "colab_type": "code",
        "outputId": "56a9f099-77b3-4d36-fb9c-84e0b638588c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "zz.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10002])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tptYy0aAT-G",
        "colab_type": "code",
        "outputId": "edc7ca9f-f597-4ac1-aba4-42e77a36fd97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "for i,j in enumerate(zz):\n",
        "  print(j)\n",
        "  if i >5:\n",
        "    break\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ True,  True, False,  ...,  True, False,  True])\n",
            "tensor([ True,  True, False,  ...,  True, False,  True])\n",
            "tensor([False, False,  True,  ..., False,  True, False])\n",
            "tensor([ True,  True, False,  ...,  True, False,  True])\n",
            "tensor([False, False,  True,  ..., False,  True, False])\n",
            "tensor([False, False,  True,  ..., False,  True, False])\n",
            "tensor([ True,  True, False,  ...,  True, False,  True])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN4KlCLy-tsT",
        "colab_type": "code",
        "outputId": "9145df61-bda1-4dcd-9687-e5e7dc8e4a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = torch.randint(low = 0, high = 2, size = (10002,))\n",
        "b = a.numpy()\n",
        "c = ((torch.from_numpy(b) == a).type(torch.FloatTensor))\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNDr0eH1_bye",
        "colab_type": "code",
        "outputId": "cc9477bd-90cf-424e-a787-547ab75d49bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10002])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqW3OoReAwfS",
        "colab_type": "code",
        "outputId": "20abef31-061a-4aec-ffb2-5a886cb61784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nn.Flatten()(labels).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10002, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOrQHkUYT71O",
        "colab_type": "text"
      },
      "source": [
        "## VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CStULKqT9uZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class encoder_v(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.mu = nn.Sequential(nn.Linear(39, 500),nn.ReLU(),\n",
        "                            nn.Linear(500, 500), nn.ReLU(),\n",
        "                             nn.Linear(500, 2000), nn.ReLU(),\n",
        "                            nn.Linear(2000,2),nn.ReLU())\n",
        "    self.var = nn.Sequential(nn.Linear(39, 500), nn.ReLU(),\n",
        "                            nn.Linear(500, 500), nn.ReLU(),\n",
        "                             nn.Linear(500, 2000), nn.ReLU(),\n",
        "                            nn.Linear(2000,2),nn.ReLU())\n",
        "  def forward(self, X):\n",
        "    z_mu = self.mu(X)\n",
        "    z_var = self.var(X)\n",
        "    return z_mu, z_var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud76pVHxUE_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class decoder_v(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc2 = nn.Sequential(nn.Linear(2,2000),nn.ReLU(),\n",
        "                             nn.Linear(2000, 500), nn.ReLU(),\n",
        "                             nn.Linear(500, 500), nn.ReLU(),\n",
        "                             nn.Linear(500, 39), nn.ReLU())                            \n",
        "  def forward(self, X):\n",
        "    X = self.fc2(X)\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGfaRbXuUeUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAutoencoder(nn.Module):\n",
        "  def __init__(self, enc, dec):\n",
        "    super().__init__()\n",
        "    self.enc = enc\n",
        "    self.dec = dec\n",
        "  def forward(self, X):\n",
        "    z_mu, z_var = self.enc(X)\n",
        "    std = torch.exp( z_var/2 )\n",
        "    eps = torch.randn_like(std)\n",
        "    z_sample = eps.mul(std).add_(z_mu)\n",
        "    X_predic = self.dec(z_sample)\n",
        "    return X_predic, z_mu, z_var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_wme-KqVFRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc_v = encoder_v()\n",
        "dec_v = decoder_v()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vautoencoder = VAutoencoder(enc_v, dec_v).to(device)\n",
        "optimizer = torch.optim.Adam(vautoencoder.parameters(), lr = 0.001)\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeoUbnBoVw1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sensitivity = 100\n",
        "X = np.load(os.path.join(synthetic_path, f'X_sparsity_1_variance_{1/sensitivity:.2f}.npy'))\n",
        "X = torch.Tensor(X)\n",
        "X= X.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9JeoNAYVdUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "  \n",
        "  vautoencoder.train()\n",
        "  train_loss = 0\n",
        "  \n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  X_pred, z_mu, z_var = vautoencoder(X)\n",
        "\n",
        "  recon_loss = criterion(X_pred, X)\n",
        "  kl_loss = 0.5*( torch.sum( torch.exp(z_var) + z_mu**2 - 1.0 + z_var ) ) \n",
        "  loss = recon_loss + kl_loss\n",
        "\n",
        "  loss.backward()\n",
        "  train_loss += loss.item()\n",
        "  \n",
        "  optimizer.step()\n",
        "  return train_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLEP_jveVg9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def test():\n",
        "#   vautoencoder.eval()\n",
        "#   test_loss = 0\n",
        "\n",
        "#   with torch.no_grad():\n",
        "\n",
        "#     X_ped, z_mu, z_var = vautoencoder(images)\n",
        "\n",
        "#     recon_loss = criterion(X, images)\n",
        "#     kl_loss = 0.5*torch.sum(torch.exp(z_var)+ z_mu**2 - 1 + z_var)\n",
        "#     loss = recon_loss + kl_loss\n",
        "\n",
        "#     test_loss += loss.item()      \n",
        "#   return test_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ__1KNEWIFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrTU1UgIVjT9",
        "colab_type": "code",
        "outputId": "4f9e77c0-f487-4224-f66d-18a4a337dd7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_loss_list = []\n",
        "test_loss_list = []\n",
        "time_start = time.time()\n",
        "for e in range(epochs):\n",
        "  print(f'{e+1}th epoch...')\n",
        "  print(f'Training...')\n",
        "  train_loss = train()\n",
        "  train_loss /= len(X)\n",
        "  print(f'Training done. Time Collapsed = {time.time() - time_start: .2f}s')\n",
        "  # print(f'Testing..')\n",
        "  # test_loss = test()\n",
        "  # test_loss /= len(val_data)\n",
        "  # print(f'Testing done. Time Collapsed = {time.time() - time_start: .2f}s')\n",
        "  train_loss_list.append(train_loss)\n",
        "  # test_loss_list.append(test_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  0.20s\n",
            "2th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  0.37s\n",
            "3th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  0.54s\n",
            "4th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  0.69s\n",
            "5th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  0.84s\n",
            "6th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  0.99s\n",
            "7th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  1.14s\n",
            "8th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  1.30s\n",
            "9th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  1.44s\n",
            "10th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  1.59s\n",
            "11th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  1.74s\n",
            "12th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  1.88s\n",
            "13th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  2.03s\n",
            "14th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  2.18s\n",
            "15th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  2.33s\n",
            "16th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  2.47s\n",
            "17th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  2.62s\n",
            "18th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  2.77s\n",
            "19th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  2.91s\n",
            "20th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  3.05s\n",
            "21th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  3.19s\n",
            "22th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  3.33s\n",
            "23th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  3.49s\n",
            "24th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  3.69s\n",
            "25th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  3.88s\n",
            "26th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  4.02s\n",
            "27th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  4.16s\n",
            "28th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  4.30s\n",
            "29th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  4.45s\n",
            "30th epoch...\n",
            "Training...\n",
            "Training done. Time Collapsed =  4.59s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeS5g_d1WLZU",
        "colab_type": "code",
        "outputId": "6813a80c-8946-4249-bf99-935aac2898d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.plot(train_loss_list, label='Training loss')\n",
        "plt.legend(frameon=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1b3be78ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAx8AAAHwCAYAAADHKdLbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4kOSJElSExYfkiRJkpr4D24mU2mtf2gvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 399,
              "height": 248
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IwreqUgWtPA",
        "colab_type": "code",
        "outputId": "9f2be101-f83a-43a5-fa58-59861851c9a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10002, 39])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJFbxcIrXA-1",
        "colab_type": "code",
        "outputId": "b2e9e906-0d1e-48f0-8bcc-ac68211f44b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoding,_ = enc_v(X)\n",
        "encoding = encoding.cpu().detach()\n",
        "encoding.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10002, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f59NbBCjDRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = np.load(os.path.join(synthetic_path, f'labels_sparsity_1_variance_{1/sensitivity:.2f}.npy'))\n",
        "labels = torch.Tensor(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lTAz0OYj58N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT9RYNbRjDLK",
        "colab_type": "code",
        "outputId": "406ba049-d894-4b8f-fc1c-6cbe0791e4e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "for i in tqdm(range(len(encoding))):\n",
        "  plt.scatter(encoding[i][0], encoding[i][1], c=colors[int(labels[i].item())])  \n",
        "plt.title(f'Visualization against the ground truth for Sparsity = 1, variance = {1/sensitivity:.2f}')\n",
        "plt.savefig(os.path.join(synthetic_path,f'v_encoding_ground_truth_Sparsity_1_variance_{1/sensitivity:.2f}.png'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10002/10002 [01:28<00:00, 113.39it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAIPCAYAAAAhPnyDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfZMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 444,
              "height": 263
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCoR1zlYhJpy",
        "colab_type": "text"
      },
      "source": [
        "# DEC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5Ne67BrhLmH",
        "colab_type": "code",
        "outputId": "10a62872-a558-4ef5-a9c4-ab566fcfcb89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "  autoencoder, encoder = autoencoder(dims, init=init)\n",
        "  autoencoder.compile(optimizer=pretrain_optimizer, loss='mse')\n",
        "  fits = autoencoder.fit(X, X, batch_size=batch_size, epochs=pretrain_epochs) #, callbacks=cb)\n",
        "  # autoencoder.save_weights(os.path.join(synthetic_path, f\"ae_sparsity_1_db_{db}.h5\"))\n",
        "  encoding = encoder.predict(X)\n",
        "  # np.save(os.path.join(synthetic_path, f'encoding_sparsity_1_db_{db}.npy'), encoding) \n",
        "  #============#\n",
        "  clustering_layer = ClusteringLayer(n_clusters = 2, name='clustering')(encoder.output)\n",
        "  model = Model(inputs=encoder.input, outputs=clustering_layer)\n",
        "  model.compile(optimizer=Adam(0.01), loss='kld')\n",
        "  k_means = KMeans(n_clusters=2, n_init=20)\n",
        "  y_pred_ae = k_means.fit_predict(encoding) \n",
        "  y_pred_last = np.copy(y_pred_ae)\n",
        "  model.get_layer(name='clustering').set_weights([k_means.cluster_centers_])\n",
        "  #===================#\n",
        "  loss = 0\n",
        "  index = 0\n",
        "  maxiter = 8000\n",
        "  update_interval = 140\n",
        "  index_array = np.arange(X.shape[0])\n",
        "  tol = 0.001 \n",
        "  acc = 0\n",
        "  #=====================#\n",
        "  for ite in range(int(maxiter)):\n",
        "      if ite % update_interval == 0:\n",
        "          q = model.predict(X, verbose=0)\n",
        "          p = target_distribution(q) \n",
        "          y_pred_ae = q.argmax(1)\n",
        "          print(y_pred_ae.shape)\n",
        "          print(labels.numpy().shape)\n",
        "          if labels.numpy() is not None:\n",
        "              acc = np.round(metrics.acc(labels.numpy().reshape(10002,), y_pred_ae), 5)\n",
        "              nmi = np.round(metrics.nmi(labels.numpy().reshape(10002,), y_pred_ae), 5)\n",
        "              ari = np.round(metrics.ari(labels.numpy().reshape(10002,), y_pred_ae), 5)\n",
        "              loss = np.round(loss, 5)\n",
        "              print('Iter %d: acc = %.5f, nmi = %.5f, ari = %.5f' % (ite, acc, nmi, ari), ' ; loss=', loss)\n",
        "          delta_label = np.sum(y_pred_ae != y_pred_last).astype(np.float32) / y_pred_ae.shape[0]\n",
        "          y_pred_last = np.copy(y_pred_ae)\n",
        "          if ite > 0 and delta_label < tol:\n",
        "              print('delta_label ', delta_label, '< tol ', tol)\n",
        "              print('Reached tolerance threshold. Stopping training.')\n",
        "              break\n",
        "      idx = index_array[index * batch_size: min((index+1) * batch_size, X.shape[0])]\n",
        "      loss = model.train_on_batch(x=X[idx], y=p[idx])\n",
        "      index = index + 1 if (index + 1) * batch_size <= X.shape[0] else 0\n",
        "  accuracy_dec_list.append(acc)\n",
        "  # model.save_weights(os.path.join(synthetic_path, f'DEC_model_final_sparsity_1_db{db}.h5'))\n",
        "  encoded_dec = encoder.predict(X)\n",
        "  # np.save(os.path.join(synthetic_path, f'encoded_dec_sparsity_1_db_{db}.npy'), encoded_dec)\n",
        "  # del encoding, loss, idx, index, model,acc,nmi, ari, clustering_layer, k_means, y_pred_last, delta_label, encoded_dec\n",
        "  #===========================#"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "10002/10002 [==============================] - 2s 174us/step - loss: 0.1020\n",
            "Epoch 2/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.0052\n",
            "Epoch 3/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0050\n",
            "Epoch 4/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.0048\n",
            "Epoch 5/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0050\n",
            "Epoch 6/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.0034\n",
            "Epoch 7/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0027\n",
            "Epoch 8/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0026\n",
            "Epoch 9/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.0031\n",
            "Epoch 10/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.0026\n",
            "Epoch 11/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0025\n",
            "Epoch 12/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.0025\n",
            "Epoch 13/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0025\n",
            "Epoch 14/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0027\n",
            "Epoch 15/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.0027\n",
            "Epoch 16/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.0025\n",
            "Epoch 17/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.0025\n",
            "Epoch 18/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0026\n",
            "Epoch 19/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.0026\n",
            "Epoch 20/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.0025\n",
            "Epoch 21/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.0025\n",
            "Epoch 22/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.0025\n",
            "Epoch 23/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0036\n",
            "Epoch 24/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.0031\n",
            "Epoch 25/30\n",
            "10002/10002 [==============================] - 1s 57us/step - loss: 0.0025\n",
            "Epoch 26/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0025\n",
            "Epoch 27/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0025\n",
            "Epoch 28/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0025\n",
            "Epoch 29/30\n",
            "10002/10002 [==============================] - 1s 58us/step - loss: 0.0025\n",
            "Epoch 30/30\n",
            "10002/10002 [==============================] - 1s 59us/step - loss: 0.0030\n",
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 0: acc = 0.98020, nmi = 0.87916, ari = 0.92238  ; loss= 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 140: acc = 0.98170, nmi = 0.88624, ari = 0.92815  ; loss= 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10002,)\n",
            "(10002, 1)\n",
            "Iter 280: acc = 0.98130, nmi = 0.88433, ari = 0.92661  ; loss= 0.0\n",
            "delta_label  0.0009998000399920016 < tol  0.001\n",
            "Reached tolerance threshold. Stopping training.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:127: DeprecationWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnEPkfFOjhNN",
        "colab_type": "code",
        "outputId": "69c75472-6da1-4ec9-e29a-b80dc32494de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(fits.history['loss'], label = 'Loss')\n",
        "plt.legend(frameon = False)\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD4CAYAAAANbUbJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq3pkLE3q1vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}